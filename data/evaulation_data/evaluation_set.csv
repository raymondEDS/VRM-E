unique_id,title_2017,title_2018
91c2b4d7-141e-4362-8d6d-303b3438b6c4,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,A Framework for the Quantitative Evaluation of Disentangled Representations
ced4530d-793e-4abf-9ad5-ef4fb2214a16,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Learning Dynamic State Abstractions for Model-Based Reinforcement Learning
afff834f-1976-4d4e-94f6-03c5d8dc3835,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,Learning to Mix n-Step Returns: Generalizing Lambda-Returns for Deep Reinforcement Learning
0bfc52ef-09e4-4a12-9b8d-b61557497847,A Context-aware Attention Network for Interactive Question Answering,Unsupervised Representation Learning by Predicting Image Rotations
71053412-1893-4511-a3e7-958bc80e697c,A Context-aware Attention Network for Interactive Question Answering,Incremental Learning through Deep Adaptation
dec14cce-e507-4884-be00-357aa06a02ac,A Context-aware Attention Network for Interactive Question Answering,Topic-Based Question Generation
4bac0feb-fa06-4408-8664-0ef9c91b7074,A Learned Representation For Artistic Style,XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings
1e18e268-aee9-484a-a760-b62f85ef6e61,A Learned Representation For Artistic Style,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration
cfaf5698-6632-4cbc-aac8-169850f53233,A Learned Representation For Artistic Style,Wasserstein Auto-Encoders
0765ca0f-e78c-4ec3-ae23-b77d34a1cd36,A Neural Stochastic Volatility Model,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck
e4891846-be64-4a78-8665-b113d0816935,A Neural Stochastic Volatility Model,Representing Entropy : A short proof of the equivalence between soft Q-learning and policy gradients
7e1ffc12-0f3d-4f2f-9a12-6d289a533a9e,A Neural Stochastic Volatility Model,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks
3a0411ef-62a2-4d02-ace9-010a9cc07363,A Simple but Tough-to-Beat Baseline for Sentence Embeddings,Understanding and Exploiting the Low-Rank Structure of Deep Networks
cc104e6d-c2ab-44c5-8dab-67899428928c,A Simple but Tough-to-Beat Baseline for Sentence Embeddings,WSNet: Learning Compact and Efficient Networks with Weight Sampling
759b4f49-7d06-464a-9a1f-f2bf03aaefed,A Simple but Tough-to-Beat Baseline for Sentence Embeddings,Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs
549abedd-47e7-442d-9429-5903d603c85d,Adjusting for Dropout Variance in Batch Normalization and Weight Initialization,Measuring the Intrinsic Dimension of Objective Landscapes
33050ddc-8e0a-40b3-b3f2-780e9edaa1be,Adjusting for Dropout Variance in Batch Normalization and Weight Initialization,BLOCK-NORMALIZED GRADIENT METHOD: AN EMPIRICAL STUDY FOR TRAINING DEEP NEURAL NETWORK
400588c4-c4d0-4c86-8b6e-5856b1023b91,Adjusting for Dropout Variance in Batch Normalization and Weight Initialization,The Kanerva Machine: A Generative Distributed Memory
d25e76c1-53b2-422a-a32c-98d3008edd15,An Empirical Analysis of Deep Network Loss Surfaces,DropMax: Adaptive Stochastic Softmax
6992429a-017b-44ce-843a-0949365b752d,An Empirical Analysis of Deep Network Loss Surfaces,Stochastic Hyperparameter Optimization through Hypernetworks
47db3661-b08d-439a-b740-76d29c960f27,An Empirical Analysis of Deep Network Loss Surfaces,DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer
7af24f61-912d-4def-86e4-89441cc0cd86,An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views,A Framework for the Quantitative Evaluation of Disentangled Representations
c53aaf49-f133-498f-b9a5-1384bcf5fcbe,An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views,Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy
7b575a9e-a6a5-4532-afc8-07e2729ef687,An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views,Generating Natural Adversarial Examples
a06914cb-5ae3-442e-b287-a8525c43bbcd,An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax,Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates
c58d4620-b1f3-4ed8-b173-d363aef380bc,An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax,Learning Independent Causal Mechanisms
adfdf440-cf5a-4063-b373-726abbf0b45c,An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax,Expressive power of recurrent neural networks
550925a7-0e97-425f-97e8-bbf4aaa0a556,Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM,Learning Deep Generative Models With Discrete Latent Variables
81d9ba63-433e-4b7e-b110-70d67d0d8a50,Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM,A Self-Training Method for Semi-Supervised GANs
3007960e-3a55-4d47-b7d9-6a79ffbadc74,Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM,Faster Discovery of Neural Architectures by Searching for Paths in a Large Model
5fc25d18-aee2-454e-a658-bbd9ac5f15f9,BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL,Simple and efficient architecture search for Convolutional Neural Networks
ac425b5c-3943-4372-93f3-ca9b2b8c387e,BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL,Multiscale Hidden Markov Models For Covariance Prediction
a1319504-6d0c-423f-886b-f0b23763544a,BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization
0ee1f74e-1b60-4dab-afab-b61c7ac21177,Beyond Fine Tuning: A Modular Approach to Learning on Small Data,Multi-View Data Generation Without View Supervision
ee1e5652-2f96-4c8f-a3e4-75bafd684841,Beyond Fine Tuning: A Modular Approach to Learning on Small Data,Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates
33648274-a908-4717-b8f2-3a4b718d7ef0,Beyond Fine Tuning: A Modular Approach to Learning on Small Data,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent
22f8c369-12c8-4c0e-abc7-e513ace88523,Calibrating Energy-based Generative Adversarial Networks,Deep Lipschitz networks and Dudley GANs
ddd15f15-7809-42ce-a7e5-073694b75f44,Calibrating Energy-based Generative Adversarial Networks,End-to-End Abnormality Detection in Medical Imaging
1799fcbd-646a-4cf5-bd9f-56fb6805e903,Calibrating Energy-based Generative Adversarial Networks,Unsupervised Deep Structure Learning by Recursive Dependency Analysis
f4318390-db64-4fa2-810b-7a1c48c50df3,Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization,Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning
c1c6cc5c-e7d5-4512-9c25-e088818014b4,Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization,Deep Generative Dual Memory Network for Continual Learning
4f78789c-a586-4913-949c-f56f4b7d0313,Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches
a859ac48-9664-427a-a659-6a48d52b1451,Convolutional Neural Networks Generalization Utilizing the Data Graph Structure,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis
f9f6bef1-3e0e-49a8-a307-6f109d9bed72,Convolutional Neural Networks Generalization Utilizing the Data Graph Structure,Discriminative k-shot learning using probabilistic models
f4ca3e8f-c0aa-4eba-8400-9d372be44e62,Convolutional Neural Networks Generalization Utilizing the Data Graph Structure,Covariant Compositional Networks For Learning Graphs
7e142094-6d87-45f9-85f7-0022b68237ce,Data Noising as Smoothing in Neural Network Language Models,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model
4524b026-4554-4728-9ac1-d49308a44ac8,Data Noising as Smoothing in Neural Network Language Models,When is a Convolutional Filter Easy to Learn?
6c08417e-2b92-47ba-b58b-401455767a4e,Data Noising as Smoothing in Neural Network Language Models,Graph Partition Neural Networks for Semi-Supervised Classification
a3114756-998f-4104-a38b-2edd28e8f716,Dataset Augmentation in Feature Space,Learning Representations and Generative Models for 3D Point Clouds
dafda282-8d50-4a39-98bb-ed873773a31c,Dataset Augmentation in Feature Space,Transfer Learning on Manifolds via Learned Transport Operators
00923ad9-2b8b-47aa-8b03-101fbf752b0f,Dataset Augmentation in Feature Space,Building Generalizable Agents with a Realistic and Rich 3D Environment
007d52d8-f980-42a5-8843-5cf8174e83e5,Decomposing Motion and Content for Natural Video Sequence Prediction,Convolutional Sequence Modeling Revisited
c15c9d94-ae97-466f-a333-ad032129b9cd,Decomposing Motion and Content for Natural Video Sequence Prediction,Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning
e8d882c0-24da-4aa5-97f5-cc9d7542c14a,Decomposing Motion and Content for Natural Video Sequence Prediction,Unseen Class Discovery in Open-world Classification
e54c3caa-b9c4-491d-9aef-66a0fbfc52cc,Deep Generalized Canonical Correlation Analysis,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation
95750e17-e869-4601-b318-945db3a875a9,Deep Generalized Canonical Correlation Analysis,Compact Encoding of Words for Efficient Character-level Convolutional Neural Networks Text Classification
6763c6c0-d977-4f8a-b58e-31e3ee2a3f71,Deep Generalized Canonical Correlation Analysis,Byte-Level Recursive Convolutional Auto-Encoder for Text
075fdb48-21a3-4071-ae4f-9cd12745dbc9,Deep Variational Information Bottleneck,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers
9d3d362b-25bf-4992-97c1-6753d4013f56,Deep Variational Information Bottleneck,Improving Search Through A3C Reinforcement Learning Based Conversational Agent
feccbda0-7fdf-4d9a-925c-a50c0cf892ce,Deep Variational Information Bottleneck,Wasserstein Auto-Encoders
d4d5e57c-7515-41c2-b8b0-4da02b9d28e4,Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks
a78e24d9-c783-45c8-8cfb-e9c511179e01,Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment,POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION
11d3781c-352e-439d-8291-219111e91806,Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control
a26f2884-5e19-44f4-8cd2-fc83b513ef5e,Do Deep Convolutional Nets Really Need to be Deep and Convolutional?,Training wide residual networks for deployment using a single bit for each weight
b105b6b8-7056-4c78-9bfb-5e5ce7d9f2a7,Do Deep Convolutional Nets Really Need to be Deep and Convolutional?,Learning Parsimonious Deep Feed-forward Networks
523953e2-e799-46b8-a0da-75654c4184c0,Do Deep Convolutional Nets Really Need to be Deep and Convolutional?,Incremental Learning through Deep Adaptation
b058b15b-3ffb-4ab9-a83c-107de0f0f304,Dropout with Expectation-linear Regularization,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning
ddffbc4f-be38-426e-8cda-ebc83144db3b,Dropout with Expectation-linear Regularization,ShakeDrop regularization
3819abfb-90af-4175-8831-a580a1bfd5eb,Dropout with Expectation-linear Regularization,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks
6f51c2e8-5fe9-46d6-a1a0-b0a9bba690f0,EPOpt: Learning Robust Neural Network Policies Using Model Ensembles,Towards Neural Phrase-based Machine Translation
043fa034-3d16-442e-a6b2-65f9bf6644a5,EPOpt: Learning Robust Neural Network Policies Using Model Ensembles,Learning to Mix n-Step Returns: Generalizing Lambda-Returns for Deep Reinforcement Learning
81faecbe-e0c7-4e37-a2e3-c8f263d9d3b1,EPOpt: Learning Robust Neural Network Policies Using Model Ensembles,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models
61620e0a-957e-44f5-8449-66113f760bb8,Efficient Communications in Training Large Scale Neural Networks,Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling
d166679f-dd5e-4ff7-9f8c-4b844ee50458,Efficient Communications in Training Large Scale Neural Networks,SMASH: One-Shot Model Architecture Search through HyperNetworks
e145e928-ad9b-4c13-9593-25e43ae395dd,Efficient Communications in Training Large Scale Neural Networks,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING
9894580e-a887-4d91-af28-54e7f4d74cda,End-to-end Optimized Image Compression,Deep Learning with Logged Bandit Feedback
58b9c106-de90-41de-9b16-728f2e98e0ac,End-to-end Optimized Image Compression,Neural Networks for irregularly observed continuous-time Stochastic Processes
59d18750-fd85-4626-b361-8aa99954e796,End-to-end Optimized Image Compression,Learning Sparse Neural Networks through L_0 Regularization
c2f80194-5548-44d9-98b6-0a8cf2b03bd4,Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement,Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?
c64250b7-8b59-4b8d-9a79-52f3b7703c5a,Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement,Towards Building Affect sensitive Word Distributions
274c7816-de98-49ad-bac8-8451c110c616,Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement,Sparse-Complementary Convolution for Efficient Model Utilization on CNNs
c20837f2-bd2f-4cbe-8f07-35067f8ddb56,Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models,Twin Networks: Matching the Future for Sequence Generation
bfcd8ff9-2cc4-4fda-aac2-4c2d0d25c5ab,Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models,DropMax: Adaptive Stochastic Softmax
749e52bc-197a-4f08-ba03-a1f446597c87,Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models,Towards Deep Learning Models Resistant to Adversarial Attacks
f58f3323-008b-481d-b1b3-f9223549a5d4,Exploring LOTS in Deep Neural Networks,On the Use of Word Embeddings Alone to Represent Natural Language Sequences
e6c91cad-be81-470f-b7df-93eb25881abc,Exploring LOTS in Deep Neural Networks,Generating Adversarial Examples with Adversarial Networks
fc2b8231-2b33-41f3-8641-9eaf30828072,Exploring LOTS in Deep Neural Networks,Continuous Convolutional Neural Networks for Image Classification
018b04a8-326c-40aa-b1df-dce589a83b26,Exploring the Application of Deep Learning for Supervised Learning Problems,Training RNNs as Fast as CNNs
c3741972-acc7-4625-9962-48889147bb5a,Exploring the Application of Deep Learning for Supervised Learning Problems,Proximal Backpropagation
3457c73e-7524-4516-a79d-74aaeb179013,Exploring the Application of Deep Learning for Supervised Learning Problems,DeepArchitect: Automatically Designing and Training Deep Architectures
20a6ee5a-aef2-4ffa-abeb-a9980ef70eb5,Fuzzy paraphrases in learning word representations with a lexicon,Comparison of Paragram and GloVe Results for Similarity Benchmarks
2f012df4-7196-41c0-a345-979874986843,Fuzzy paraphrases in learning word representations with a lexicon,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling
2fe18e81-d817-4833-8381-06922b6f5417,Fuzzy paraphrases in learning word representations with a lexicon,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation
bd472ba2-9c94-441e-834b-a64398cee4d1,Generative Adversarial Networks as Variational Training of Energy Based Models,MGAN: Training Generative Adversarial Nets with Multiple Generators
fdbbe07c-1930-4d2a-8d39-fe65e68a7822,Generative Adversarial Networks as Variational Training of Energy Based Models,Certifying Some Distributional Robustness with Principled Adversarial Training
62005544-f57a-4ddb-9b06-b393af2b9f89,Generative Adversarial Networks as Variational Training of Energy Based Models,Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks
d664c1d8-5dfa-4640-bb6b-eb60f68f1b7e,Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,A Hierarchical Model for Device Placement
08cf3977-40ee-4ade-afbc-7a617906a368,Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,Not-So-Random Features
b81addb6-e211-481b-98b2-3f79614edd10,Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,Quantitatively Evaluating GANs With Divergences Proposed for Training
54182d7c-41b3-498d-96e0-312532e8691f,Gradients of Counterfactuals,Online Learning Rate Adaptation with Hypergradient Descent
94866de5-3ed9-4f68-af6b-5068006c94a2,Gradients of Counterfactuals,Learn to Pay Attention
37706265-fa71-400c-98fa-0120cf561514,Gradients of Counterfactuals,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering
3cc17d20-7cb4-4db8-bf6f-29cc17815158,Hadamard Product for Low-rank Bilinear Pooling,LSH Softmax: Sub-Linear Learning and Inference of the Softmax Layer in Deep Architectures
76e3b709-82fe-44a8-9f56-90ae501d81fd,Hadamard Product for Low-rank Bilinear Pooling,Tensor Contraction & Regression Networks
f814d442-70bc-4a90-908f-b1da80dd0ee0,Hadamard Product for Low-rank Bilinear Pooling,Alternating Multi-bit Quantization for Recurrent Neural Networks
4e7afdb2-a560-4002-a510-09d79f678bd8,Here's My Point: Argumentation Mining with Pointer Networks,Generative Models for Alignment and Data Efficiency in Language
257162dd-38a2-4654-8c9b-6a3477e66564,Here's My Point: Argumentation Mining with Pointer Networks,Learning Latent Permutations with Gumbel-Sinkhorn Networks
bf040def-4764-4fdb-8f0d-38f30ef35b6b,Here's My Point: Argumentation Mining with Pointer Networks,Graph Attention Networks
468768ee-df6a-4b58-97ba-46db4528033f,Hierarchical compositional feature learning,Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data
313a2787-de29-4733-a0ad-69d252bbc9af,Hierarchical compositional feature learning,Counterfactual Image Networks
54c6655e-5ddc-4910-a93d-d5b023b74f95,Hierarchical compositional feature learning,Smooth Loss Functions for Deep Top-k Classification
5a67aaa9-e6c6-4fa6-8c1e-f919df3369a9,Improved Architectures for Computer Go,EXPLORING NEURAL ARCHITECTURE SEARCH FOR LANGUAGE TASKS
3336bf42-270b-4e96-b2c8-06d8b4e94389,Improved Architectures for Computer Go,Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?
bd1e6d92-e8ac-436f-8edd-f8d7a115d828,Improved Architectures for Computer Go,On the Information Bottleneck Theory of Deep Learning
8c5226a5-1560-41af-b54d-f54aac3acc3c,Improving Invariance and Equivariance Properties of Convolutional Neural Networks,Generative Models of Visually Grounded Imagination
dfd7df4a-2636-4b1f-a9c3-b8ddff484158,Improving Invariance and Equivariance Properties of Convolutional Neural Networks,Learning Deep Mean Field Games for Modeling Large Population Behavior
f17a1843-e205-4322-9069-8f9a223634c8,Improving Invariance and Equivariance Properties of Convolutional Neural Networks,Tandem Blocks in Deep Convolutional Neural Networks
a52a7fc5-e2fb-4976-a8cb-00080e11da85,Improving Sampling from Generative Autoencoders with Markov Chains,The Variational Homoencoder: Learning to Infer High-Capacity Generative Models from Few Examples
6cba4743-24b5-49d7-beb0-cd841beb4f67,Improving Sampling from Generative Autoencoders with Markov Chains,Directing Generative Networks with Weighted Maximum Mean Discrepancy
c336a7c9-e3e4-49b9-a5fa-c5720e24186d,Improving Sampling from Generative Autoencoders with Markov Chains,Learning Efficient Tensor Representations with Ring Structure Networks
2dacdaa4-109d-420b-ba41-89b0abaffa04,Inductive Bias of Deep Convolutional Networks through Pooling Geometry,Parallelizing Linear Recurrent Neural Nets Over Sequence Length
8be07123-bd08-4935-a23f-b3d6d763b725,Inductive Bias of Deep Convolutional Networks through Pooling Geometry,Model compression via distillation and quantization
26e8dad6-9f2b-4887-8e62-1dba49c4f628,Inductive Bias of Deep Convolutional Networks through Pooling Geometry,Tandem Blocks in Deep Convolutional Neural Networks
e16f5680-f08b-43c2-a31e-9a24b664cfc6,Inverse Problems in Computer Vision using  Adversarial  Imagination Priors,Generalization of Learning using Reservoir Computing
6866ef74-4770-4f79-a25d-d9fc0bd7ec06,Inverse Problems in Computer Vision using  Adversarial  Imagination Priors,Counterfactual Image Networks
520026e0-997f-4ae9-a98d-dc300f0769a7,Inverse Problems in Computer Vision using  Adversarial  Imagination Priors,Counterfactual Image Networks
13e711bf-3af4-49e5-a3a7-249e3334073a,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning
509682b8-38b4-4b27-ba01-4accbb0e33c1,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,Learning Differentially Private Recurrent Language Models
3d0701f1-eaba-444f-a40e-284aaff69101,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,When is a Convolutional Filter Easy to Learn?
f64e7f88-754c-48aa-a9da-7c26b53e968e,Joint Multimodal Learning with Deep Generative Models,The Mutual Autoencoder: Controlling Information in Latent Code Representations
1cb37bc2-b7ae-471a-a648-f96db0836848,Joint Multimodal Learning with Deep Generative Models,Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games
19d83c57-1218-4324-b4a6-d2b203276ca7,Joint Multimodal Learning with Deep Generative Models,INTERPRETATION OF NEURAL NETWORK IS FRAGILE
bf4de371-332e-4b9b-8291-f0cc90d0926e,Learning Continuous Semantic Representations of Symbolic Expressions,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs
df75bf96-5275-4523-bc13-74b7c28748ac,Learning Continuous Semantic Representations of Symbolic Expressions,Neural Networks for irregularly observed continuous-time Stochastic Processes
83d17591-0bc8-48e5-b3c2-06583e13cf3f,Learning Continuous Semantic Representations of Symbolic Expressions,Neural Speed Reading via Skim-RNN
8fa018f0-73bf-4cd5-a97b-a4b44206492a,Learning Graphical State Transitions,Covariant Compositional Networks For Learning Graphs
4b40c91a-de6a-44af-9279-85dc4a17168f,Learning Graphical State Transitions,WHAT ARE GANS USEFUL FOR?
2ff1a565-71db-404d-84d0-8d96d645c429,Learning Graphical State Transitions,WHAT ARE GANS USEFUL FOR?
b58841b0-b227-4859-b934-b0f27a25acc4,Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning,Learning to Write by Learning the Objective
76fcd946-659f-4ee1-b79a-1907ef9dedb5,Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning,META LEARNING SHARED HIERARCHIES
6c1ae733-5a82-4eaa-9acb-4962f1c8ebc9,Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning,Overcoming the vanishing gradient problem in plain recurrent networks
44ff8af3-2c52-48aa-8fbc-0aa09f1208fd,Learning through Dialogue Interactions by Asking Questions,Accelerating Neural Architecture Search using Performance Prediction
0829a7e8-234a-4716-80c1-8f8b35f86ecf,Learning through Dialogue Interactions by Asking Questions,Reinforcement Learning Algorithm Selection
0c624bf8-a1ae-413e-a4a8-cda744833148,Learning through Dialogue Interactions by Asking Questions,Predicting Multiple Actions for Stochastic Continuous Control
f0be5df4-ab4c-46c4-aaba-39d9d2f9ee71,Learning to Compose Words into Sentences with Reinforcement Learning,A Deep Reinforced Model for Abstractive Summarization
d14f0eda-d497-4476-a641-68e0ad5ec158,Learning to Compose Words into Sentences with Reinforcement Learning,Time-Dependent Representation for Neural Event Sequence Prediction
8e79f928-34b8-4392-8e86-801e70360363,Learning to Compose Words into Sentences with Reinforcement Learning,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
e765e84f-f1e1-4426-9a00-594ccbe889ee,Learning to Discover Sparse Graphical Models,Convolutional Sequence Modeling Revisited
3fc1fe99-1972-4d42-9505-5067084e5f05,Learning to Discover Sparse Graphical Models,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes
6794e237-b6cc-4109-85cf-a7f2ef78f13d,Learning to Discover Sparse Graphical Models,CAYLEYNETS: SPECTRAL GRAPH CNNS WITH COMPLEX RATIONAL FILTERS
2976b988-d62a-4095-83f4-39d6755d646a,Learning to Generate Samples from Noise through Infusion Training,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
5fee4c69-ef6d-4798-8a3c-d2b69e609fa4,Learning to Generate Samples from Noise through Infusion Training,Make SVM great again with Siamese kernel for  few-shot learning
144a9f7a-f8de-4f13-bd7f-10313ae85abc,Learning to Generate Samples from Noise through Infusion Training,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models
50137eb3-033f-4453-bd8f-5a7823cedffe,Learning to Perform Physics Experiments via Deep Reinforcement Learning,On the Generalization Effects of DenseNet Model Structures 
e58b6bb7-c56a-404b-9f64-8dd295e3ac45,Learning to Perform Physics Experiments via Deep Reinforcement Learning,Generalization of Learning using Reservoir Computing
47f0ae4b-e1ff-4dd0-be22-5e66c4cebd4d,Learning to Perform Physics Experiments via Deep Reinforcement Learning,Divide-and-Conquer Reinforcement Learning
a6a2102a-74dd-486c-b5db-060bf74f8932,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts",Natural Language Inference over Interaction Space
61fd8088-314d-4c29-af02-0816b72cd8e3,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts",Heterogeneous Bitwidth Binarization in Convolutional Neural Networks
768c06dd-9432-40a7-af78-3eb81891493e,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts",Fraternal Dropout
fc18d311-3ebc-442f-a31f-87d775e296ed,Learning to superoptimize programs,Revisiting Knowledge Base Embedding as Tensor Decomposition
af94f166-75a1-4608-9101-2317d3a90421,Learning to superoptimize programs,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis
6386b7d8-07e3-444f-b7e8-9dc19be8dec3,Learning to superoptimize programs,Faster Reinforcement Learning with Expert State Sequences
866b3e2a-4304-47c0-a9f3-d6a26d134b4b,Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning,AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks
3eadc753-e914-46a2-be79-dba4cc27af04,Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning,Recurrent Neural Networks with Top-k Gains for Session-based Recommendations
6e935aad-88db-4a03-9efe-f36c4266e20b,Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs
d4526410-c1ff-4991-9803-4f812c434a57,Local minima in training of deep networks,Avoiding degradation in deep feed-forward networks by phasing out skip-connections
51878050-baee-468c-b389-c077f2e8810d,Local minima in training of deep networks,Understanding Local Minima in Neural Networks by Loss Surface Decomposition
5091c952-c908-4159-a474-d272670b83f7,Local minima in training of deep networks,Kernel Implicit Variational Inference
aaa8fdc7-df68-4176-a867-b1116efad26f,Making Neural Programming Architectures Generalize via Recursion,SEARNN: Training RNNs with global-local losses
24d6ca84-390d-4908-81c8-fa3937a440ba,Making Neural Programming Architectures Generalize via Recursion,An image representation based convolutional network for DNA classification
0f9621ce-474a-4508-be10-11febd5f38e1,Making Neural Programming Architectures Generalize via Recursion,Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach
fc85e60d-e916-4b50-b1cf-994f20a34998,Making Stochastic Neural Networks from Deterministic Ones,WSNet: Learning Compact and Efficient Networks with Weight Sampling
f5a0f556-67be-4100-941e-de2127ce2a1c,Making Stochastic Neural Networks from Deterministic Ones,Dynamic Evaluation of Neural Sequence Models
82c53deb-2381-4945-8fcd-8d7e3e206e07,Making Stochastic Neural Networks from Deterministic Ones,Adaptive Quantization of Neural Networks
b3dbfce2-b4bc-4f15-add3-89ac644f8283,Memory-augmented Attention Modelling for Videos,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration
3fc05048-727e-47ab-93cb-55f2111c3b7f,Memory-augmented Attention Modelling for Videos,Learn to Pay Attention
4e5ac2d2-0a74-40ff-856b-340d89e3ec9c,Memory-augmented Attention Modelling for Videos,Compositional Attention Networks for Machine Reasoning
e2724c25-1cbf-485a-88d4-5172ec512700,Mode Regularized Generative Adversarial Networks,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN
bbc6b70d-5a5d-4f3a-8112-03bbb929d843,Mode Regularized Generative Adversarial Networks,Boundary Seeking GANs
29fae702-4f64-4485-9b4c-1bc45409b35f,Mode Regularized Generative Adversarial Networks,Learning Approximate Inference Networks for Structured Prediction
261d2927-3000-4ac7-998a-20faca09b793,Multi-label learning with the RNNs for Fashion Search,THE EFFECTIVENESS OF A TWO-LAYER NEURAL NETWORK FOR RECOMMENDATIONS
5031aa2e-6d65-4feb-999a-384d7caae203,Multi-label learning with the RNNs for Fashion Search,NerveNet: Learning Structured Policy with Graph Neural Networks
8a028828-0b74-4f8c-b6ac-12e259f704cd,Multi-label learning with the RNNs for Fashion Search,Intriguing Properties of Adversarial Examples
5fd77319-7035-4c48-964d-cdc8a2c173ec,Multi-modal Variational Encoder-Decoders,The Variational Homoencoder: Learning to Infer High-Capacity Generative Models from Few Examples
955b875f-e127-4998-b54e-d0b8e1e72d8d,Multi-modal Variational Encoder-Decoders,Pixel Deconvolutional Networks
8157048f-b319-464e-8719-d602718dc95d,Multi-modal Variational Encoder-Decoders,Toward predictive machine learning for active vision
37fd8b6c-0758-45ec-b239-8a6a288515b8,Multi-view Generative Adversarial Networks,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning
39e84dac-6caa-4ee4-8790-1a45daced428,Multi-view Generative Adversarial Networks,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation
3a05b329-1045-4ca1-ac0d-1aeac5c543a1,Multi-view Generative Adversarial Networks,AmbientGAN: Generative models from lossy measurements
25b15442-bc44-4402-8ece-e26f30dcf03e,Multiagent System for Layer Free Network,Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update
addaf55c-6783-40a7-b003-6c65ca322185,Multiagent System for Layer Free Network,Lifelong Learning with Dynamically Expandable Networks
d06a618b-3991-4b49-a1f7-4674c4416ee4,Multiagent System for Layer Free Network,Lung Tumor Location and Identification with AlexNet and a Custom CNN
7c631364-4446-4956-902d-4c261fff5147,Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses,Deep Function Machines: Generalized Neural Networks for Topological Layer Expression
7280be1a-19da-47cc-97c8-24cd188902ad,Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses,Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees
5ac6deba-34db-4fff-be2b-80db6328a1e6,Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses,A Deep Reinforced Model for Abstractive Summarization
472d5e84-90d6-4eb9-bcec-ac085ec6f5dd,NEWSQA: A MACHINE COMPREHENSION DATASET,Adversarial reading networks for machine comprehension
1bf410e9-48cf-4f01-9324-2b5b2f9b1ba7,NEWSQA: A MACHINE COMPREHENSION DATASET,Gated ConvNets for Letter-Based ASR
d4fced54-52f0-490e-a191-7caf16658a5e,NEWSQA: A MACHINE COMPREHENSION DATASET,Latent forward model for Real-time Strategy game planning with incomplete information
fcc0c64b-9dc7-4d66-8ddf-395424dda0cd,Neural Architecture Search with Reinforcement Learning,Unsupervised Representation Learning by Predicting Image Rotations
f5057eae-8a0a-499c-9a00-2524646e55d4,Neural Architecture Search with Reinforcement Learning,Multiscale Hidden Markov Models For Covariance Prediction
246e8832-846f-435e-a38b-828b8d9744ef,Neural Architecture Search with Reinforcement Learning,Parametric Information Bottleneck to Optimize Stochastic Neural Networks
f826fa40-944b-407d-84ba-39d0b8052b50,Neural Causal Regularization under the Independence of Mechanisms Assumption,Parametric Adversarial Divergences are Good Task Losses for Generative Modeling
43644c48-09af-4b17-a8be-52a64458f9b1,Neural Causal Regularization under the Independence of Mechanisms Assumption,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs
2443bb6c-8520-40a2-8959-e1dddf294860,Neural Causal Regularization under the Independence of Mechanisms Assumption,HexaConv
c6e8c0bf-e5ac-4bb5-ab31-afc799a613de,Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes,Hierarchical Representations for Efficient Architecture Search
002b934d-8c4e-4717-a6b1-91f89be05d53,Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes,Large Scale Multi-Domain Multi-Task Learning with MultiModel
48ca839a-aaf7-4254-b3c4-16857f96d398,Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection
56ab3e57-5598-4571-a0d8-971210720452,OMG: Orthogonal Method of Grouping With Application of K-Shot Learning,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs
ae184fa5-b7ae-42c8-af40-60b3446e609f,OMG: Orthogonal Method of Grouping With Application of K-Shot Learning,Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design
453264dc-4918-4aa9-a025-faf43b603ac6,OMG: Orthogonal Method of Grouping With Application of K-Shot Learning,Make SVM great again with Siamese kernel for  few-shot learning
8e030072-e646-45bb-a8db-3dd7a72d7fca,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,LatentPoison -- Adversarial Attacks On The Latent Space
1388027d-b213-4431-93f7-48e1a6ebc578,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates
0434961f-8b92-4037-b9fe-70ebef6baca1,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,Video Action Segmentation with Hybrid Temporal Networks
5858c9a4-3aee-442b-baa0-68e0735c0481,On Robust Concepts and Small Neural Nets,Ensemble Adversarial Training: Attacks and Defenses
eaaf2cfa-8d26-4916-91c2-b5913815104e,On Robust Concepts and Small Neural Nets,Loss Functions for Multiset Prediction
3b66fc02-6bd7-4d42-b565-ecbe21d08ecd,On Robust Concepts and Small Neural Nets,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data
fe9df44a-33d8-4380-b66c-ab580f91c84f,Perception Updating Networks: On architectural constraints for interpretable video generative models,Feature Map Variational Auto-Encoders
875d323b-c2b7-4fcb-8ba1-9e034883b0cd,Perception Updating Networks: On architectural constraints for interpretable video generative models,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization
0faf4bf5-9b6b-4dca-a076-2f7c7d816802,Perception Updating Networks: On architectural constraints for interpretable video generative models,State Space LSTM Models with Particle MCMC Inference
037a628c-7562-4d66-a0d6-4d744c261274,Pruning Convolutional Neural Networks for Resource Efficient Inference,Continuous Convolutional Neural Networks for Image Classification
6470f232-5127-4cde-9a45-ba5f85674181,Pruning Convolutional Neural Networks for Resource Efficient Inference,A Semantic Loss Function for Deep Learning with Symbolic Knowledge
34cd688c-f72c-4324-b531-ecc08116a2bb,Pruning Convolutional Neural Networks for Resource Efficient Inference,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect
e0f5ca2c-6ff6-4a20-bf54-c72e3b0dc1ac,Pruning Filters for Efficient ConvNets,Iterative Deep Compression : Compressing Deep Networks for Classification and Semantic Segmentation
7bdbf513-83f9-4bb7-aa6b-c5239d1ddd47,Pruning Filters for Efficient ConvNets,QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension
7390ab71-28f2-4fa8-a4bc-c33f67c6bd6a,Pruning Filters for Efficient ConvNets,Understanding Deep Neural Networks with Rectified Linear Units
0dc44a4d-b9ff-49bc-b150-76a301786b07,Query-Reduction Networks for Question Answering,Small Coresets to Represent Large Training Data for Support Vector Machines
0c847a47-b381-42d5-90c7-6f2b284fcf65,Query-Reduction Networks for Question Answering,Using Deep Reinforcement Learning to Generate Rationales for Molecules
93eb1eba-3876-49f4-bb7d-057ad77f31e7,Query-Reduction Networks for Question Answering,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension
385abbe0-c604-4fa3-8235-b75f42fa3d80,Recurrent Batch Normalization,Comparison of Paragram and GloVe Results for Similarity Benchmarks
043e394f-1112-4329-9e3a-f11eb4046dfd,Recurrent Batch Normalization,Large Scale Multi-Domain Multi-Task Learning with MultiModel
b3f64c0b-7e75-4eeb-a664-d4a3c9807d60,Recurrent Batch Normalization,Challenges in Disentangling Independent Factors of Variation
b65bb574-b85e-45ba-98e8-25226fbadc7c,Recurrent Environment Simulators,Autostacker: an Automatic Evolutionary Hierarchical  Machine Learning System
4aa443ea-63b1-44ee-a60d-5c87bb6b615c,Recurrent Environment Simulators,Dense Recurrent Neural Network with Attention Gate
9fc2611a-b6a2-44d0-a10f-251e02def310,Recurrent Environment Simulators,Learning Dynamic State Abstractions for Model-Based Reinforcement Learning
5a0648bd-ee1f-4d0a-b2e2-a35646f9916a,Recurrent Neural Networks for Multivariate Time Series with Missing Values,Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies
e31436db-8f54-4aa9-9c35-14277adb7507,Recurrent Neural Networks for Multivariate Time Series with Missing Values,Detecting Statistical Interactions from Neural Network Weights
9aebdc05-a9fa-4836-a5db-ac53406e7f7d,Recurrent Neural Networks for Multivariate Time Series with Missing Values,Classifier-to-Generator Attack: Estimation of Training Data Distribution from Classifier
95a8b2dd-e34d-4cd3-8c42-1ba8fd58b7af,Recurrent Normalization Propagation,Shifting Mean Activation Towards Zero with Bipolar Activation Functions
e62e387b-a20b-45ca-b1fa-8058f9f3f28c,Recurrent Normalization Propagation,Bias-Variance Decomposition for Boltzmann Machines
6d0d6ec5-2f37-4ede-a582-938e092e0c6e,Recurrent Normalization Propagation,Weightless: Lossy Weight Encoding For Deep Neural Network Compression
c454b733-9e3b-4eef-a750-87b04c113801,Riemannian Optimization for Skip-Gram Negative Sampling,Word2net: Deep Representations of Language
3d89e730-14df-4551-a9ca-c312705c84ec,Riemannian Optimization for Skip-Gram Negative Sampling,Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning
19deb0fe-3b25-46ee-8f26-fb3d7a9350ac,Riemannian Optimization for Skip-Gram Negative Sampling,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments
e5dfd1b4-379d-400c-8750-2201722ec1c3,Rule Mining in Feature Space,Learning Sparse Neural Networks through L_0 Regularization
662f5c68-3845-46b9-9114-5dd108655bfb,Rule Mining in Feature Space,Non-Autoregressive Neural Machine Translation
791188f9-4d8f-4919-a4d0-8c3bad7f1f28,Rule Mining in Feature Space,Learning Sparse Neural Networks through L_0 Regularization
4512ac9d-8761-445b-926d-e2af49fca13b,SGDR: Stochastic Gradient Descent with Warm Restarts,Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling
39cd2495-6734-49a3-993a-21eda41f7447,SGDR: Stochastic Gradient Descent with Warm Restarts,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling
312d9721-7150-47fb-88e8-3ce8dc43ea8a,SGDR: Stochastic Gradient Descent with Warm Restarts,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning
22c39fea-9e0f-4b36-a77f-a10ca79e795c,Sample Efficient Actor-Critic with  Experience Replay,An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems.
66ced6b7-fe4b-48d7-923d-891f3c808fee,Sample Efficient Actor-Critic with  Experience Replay,Maximum a Posteriori Policy Optimisation
22e02c3f-71a3-4e81-832a-55ddbe54fb01,Sample Efficient Actor-Critic with  Experience Replay,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach
46058e7f-5228-4720-b8b1-6eb6b2b2d0d0,Submodular Sum-product Networks for Scene Understanding,Softmax Q-Distribution Estimation for Structured Prediction: A Theoretical Interpretation for RAML
ad27fa17-2b86-448b-8a57-301fcb2f0b13,Submodular Sum-product Networks for Scene Understanding,Monotonic Chunkwise Attention
42d0180d-dea0-4d1d-9bd4-3aad83b85139,Submodular Sum-product Networks for Scene Understanding,Demystifying overcomplete nonlinear auto-encoders: fast SGD convergence towards sparse representation from random initialization
0811e200-ad1f-46ec-bf58-abbdc8b21031,Tensorial Mixture Models,Representing dynamically: An active process for describing sequential data
066987b0-67de-4527-98d9-2a84d7ff3d4f,Tensorial Mixture Models,Expressive power of recurrent neural networks
19edfa7a-2457-40f5-9703-0baf8fc3cd6b,Tensorial Mixture Models,Enhancing the Transferability of Adversarial Examples with Noise Reduced Gradient
de6b1066-2cd4-43f8-a0fc-8af61115e608,The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables,"MACH: Embarrassingly parallel $K$-class classification in $O(d\log{K})$ memory and $O(K\log{K} + d\log{K})$ time, instead of $O(Kd)$"
fdd6f8a5-ade9-4f99-b653-ce579042caf6,The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables,APPLICATION OF DEEP CONVOLUTIONAL NEURAL NETWORK TO PREVENT ATM FRAUD BY FACIAL DISGUISE IDENTIFICATION
6fb5270b-cf46-4822-aed0-a111321cb584,The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables,Learning To Generate Reviews and Discovering Sentiment
5a74fcbc-c754-40c0-bef6-a3f278b6939c,The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning,Identifying Analogies Across Domains
733a6ef2-3629-49b2-98f6-1379399e2bdc,The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning,Automatic Parameter Tying in Neural Networks
57ae8f63-22d2-4064-be56-7af60545cc84,The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning,3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY
d615aae7-4de6-44b6-acd0-2affbdcb5ae8,The Power of Sparsity in Convolutional Neural Networks,Log-DenseNet: How to Sparsify a DenseNet
0a7dbabc-e929-4fd0-9eb4-f4cbef938772,The Power of Sparsity in Convolutional Neural Networks,PixelNN: Example-based Image Synthesis
7c403011-7094-4c18-876e-26b5e7151eeb,The Power of Sparsity in Convolutional Neural Networks,SMASH: One-Shot Model Architecture Search through HyperNetworks
12ae04bf-811a-47d5-99af-f850c7b26286,Tighter bounds lead to improved classifiers,Learning to Teach
f5ad1a86-a1c9-4d62-a445-d69ecf8387ab,Tighter bounds lead to improved classifiers,The Implicit Bias of Gradient Descent on Separable Data
d4c2361d-0b55-4d97-adaf-c0019c3f8d3d,Tighter bounds lead to improved classifiers,DLVM: A modern compiler infrastructure for deep learning systems
6ad5d9ad-75bd-4b8d-bb27-3948a94912b5,Towards the Limit of Network Quantization,Lifelong Learning by Adjusting Priors
6dbdc116-def1-49df-809d-7703005f2c46,Towards the Limit of Network Quantization,On the Convergence of Adam and Beyond
5abe2d2d-c8f9-400f-99f8-d0c16964bf07,Towards the Limit of Network Quantization,Weightless: Lossy Weight Encoding For Deep Neural Network Compression
d70f69fe-6abe-42fd-8fa4-e1434a9dd1a0,Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect
2d3414b2-2a6c-4ebf-92f6-dce45e84942b,Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning,Covariant Compositional Networks For Learning Graphs
3abec877-9fb9-41b3-9d3a-3ca713d27df0,Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples
142a592d-ef03-4ab6-a441-689b01c99349,Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks,Revisiting Bayes by Backprop
0ac29235-47be-4912-8118-26cecf33f2ea,Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks,Influence-Directed Explanations for Deep Convolutional Networks
4cbb0b95-4ef9-462c-8b77-9a59d203ef7f,Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks,Demystifying overcomplete nonlinear auto-encoders: fast SGD convergence towards sparse representation from random initialization
8eaac9a5-5f26-4a8b-92c4-c68b2a51e39f,Understanding Trainable Sparse Coding with Matrix Factorization,BLOCK-DIAGONAL HESSIAN-FREE OPTIMIZATION FOR TRAINING NEURAL NETWORKS
02bc50f9-79e9-46ea-9577-dbac5f93ec6c,Understanding Trainable Sparse Coding with Matrix Factorization,AANN: Absolute Artificial Neural Network
5d2dcddb-84a5-451d-b012-8a789fbb0700,Understanding Trainable Sparse Coding with Matrix Factorization,Multiscale Hidden Markov Models For Covariance Prediction
4eb67ecd-8659-41ce-934e-e05ece9a2668,Unsupervised Cross-Domain Image Generation,Spherical CNNs
7b6cf229-a92b-41ed-a019-9b8c33c26d23,Unsupervised Cross-Domain Image Generation,Data Augmentation Generative Adversarial Networks
86118721-b10a-4baf-9e94-53b19d8ae2b6,Unsupervised Cross-Domain Image Generation,IVE-GAN: Invariant Encoding Generative Adversarial Networks
c06c847c-fd0a-4893-a25e-1ce238592e0f,Unsupervised Pretraining for Sequence to Sequence Learning,Multi-task Learning on MNIST Image Datasets
2d2849b6-3981-443d-987d-d5c8377043bb,Unsupervised Pretraining for Sequence to Sequence Learning,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks
e648dfee-b3c9-4e10-8371-8e762a85421b,Unsupervised Pretraining for Sequence to Sequence Learning,FigureQA: An Annotated Figure Dataset for Visual Reasoning
6cafd1d5-263c-4853-a6b3-a968c86ec5d1,Variational Lossy Autoencoder,An image representation based convolutional network for DNA classification
2dfc2a64-12cd-4aee-b6d4-f2be85272612,Variational Lossy Autoencoder,The Mutual Autoencoder: Controlling Information in Latent Code Representations
1e06f374-7d43-4f4d-9339-8c0601046579,Variational Lossy Autoencoder,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs
db190055-e7cb-46b3-a98c-0869f9d57c78,Variational Recurrent Adversarial Deep Domain Adaptation,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation
35c7ba57-5849-40fa-a2ad-ca6ea8937796,Variational Recurrent Adversarial Deep Domain Adaptation,Adversarially Regularized Autoencoders
59ed05e6-67a8-4336-9145-5dbf0daaa102,Variational Recurrent Adversarial Deep Domain Adaptation,Associative Conversation Model: Generating Visual Information from Textual Information
31f4fb22-c9b5-42c2-b537-8f0df8830c4c,Warped Convolutions: Efficient Invariance to Spatial Transformations,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play
3aad01e7-2c55-42be-9988-567f38e63cf4,Warped Convolutions: Efficient Invariance to Spatial Transformations,Enhance Word Representation for Out-of-Vocabulary on Ubuntu Dialogue Corpus
4bc05670-fa63-4169-8225-f48caf798951,Warped Convolutions: Efficient Invariance to Spatial Transformations,Parametrizing filters of a CNN with a GAN
54e444a0-52e0-4873-968e-861316f76c53,Words or Characters? Fine-grained Gating for Reading Comprehension,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction
36978ee9-0e1b-4f4e-b175-ab8e31bd9b39,Words or Characters? Fine-grained Gating for Reading Comprehension,Reinforcement and Imitation Learning for Diverse Visuomotor Skills
ace29ede-50bf-40b1-b0b2-0a07d3df5d19,Words or Characters? Fine-grained Gating for Reading Comprehension,FAST READING COMPREHENSION WITH CONVNETS
