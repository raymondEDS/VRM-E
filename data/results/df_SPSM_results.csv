paper_id,title,strata,keywords,pscore,treatment,AVG_rating,conf_year,transformed_keywords
B1-Hhnslg,Prototypical Networks for Few-shot Learning,3,"[""Deep learning"", ""Transfer Learning""]",0.5141621133458976,1,5.0,2017, deep_learning transfer_learning
B1-q5Pqxl,Machine Comprehension Using Match-LSTM and Answer Pointer,3,"[""Natural language processing"", ""Deep learning""]",0.5847394174641485,1,6.333333333333333,2017, natural_language_processing deep_learning
B12Js_yRb,Learning to Count Objects in Natural Images for Visual Question Answering,3,"[""visual question answering"", ""vqa"", ""counting""]",0.47785563146248056,0,5.333333333333333,2018, visual_question_answering vqa counting
B13EC5u6W,Thinking like a machine — generating visual rationales through latent space optimization,3,"[""interpretability"", ""generative adversarial networks""]",0.5086917353018827,0,6.333333333333333,2018, interpretability generative_adversarial_networks
B13njo1R-,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control,3,"[""Reinforcement Learning"", ""Distillation"", ""Transfer Learning"", ""Continual Learning""]",0.4980781921001778,0,6.333333333333333,2018, reinforcement_learning distillation transfer_learning continual_learning
B14TlG-RW,QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension,3,"[""squad"", ""stanford question answering dataset"", ""reading comprehension"", ""attention"", ""text convolutions"", ""question answering""]",0.5951857576516222,0,6.333333333333333,2018, squad stanford_question_answering_dataset reading_comprehension attention text_convolutions question_answering
B14uJzW0b,No Spurious Local Minima in a Two Hidden Unit ReLU Network,3,"[""Non-convex optimization"", ""Deep Learning""]",0.44327590898534047,0,5.333333333333333,2018, non_convex_optimization deep_learning
B16Jem9xe,Learning in Implicit Generative Models,3,"[""Unsupervised Learning""]",0.41189305273240756,1,7.0,2017, unsupervised_learning
B16_iGWCW,Deep Boosting of Diverse Experts,3,"[""boosting learning"", ""deep learning"", ""neural network""]",0.5666611281205185,0,4.333333333333333,2018, boosting_learning deep_learning neural_network
B16dGcqlx,Third Person Imitation Learning,3,[],0.4609566114576124,1,5.666666666666667,2017,
B16yEqkCZ,Avoiding Catastrophic States with Intrinsic Fear,3,"[""reinforcement learning"", ""safe exploration"", ""dqn""]",0.4317967920308785,0,5.666666666666667,2018, reinforcement_learning safe_exploration dqn
B17JTOe0-,Emergence of grid-like representations by training recurrent neural networks to perform spatial localization,3,"[""recurrent neural network"", ""grid cell"", ""neural representation of space""]",0.5039700081347513,0,8.333333333333334,2018, recurrent_neural_network grid_cell neural_representation_of_space
B184E5qee,Improving Neural Language Models with a Continuous Cache,3,"[""Natural language processing""]",0.5957056680003027,1,7.0,2017, natural_language_processing
B186cP9gx,Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond,3,"[""Optimization"", ""Deep learning""]",0.4730026099687936,1,3.6666666666666665,2017, optimization deep_learning
B18WgG-CZ,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,3,"[""distributed sentence representations"", ""multi-task learning""]",0.553981168771128,0,6.666666666666667,2018, distributed_sentence_representations multi_task_learning
B1CNpYg0-,Learning to Compute Word Embeddings On the Fly,3,"[""NLU"", ""word embeddings"", ""representation learning""]",0.541036562306119,0,5.666666666666667,2018, nlu word_embeddings representation_learning
B1CQGfZ0b,Learning to select examples for program synthesis,3,"[""program synthesis"", ""program induction"", ""example selection""]",0.5279405650589295,0,4.666666666666667,2018, program_synthesis program_induction example_selection
B1D6ty-A-,Training Autoencoders by Alternating Minimization,3,"[""Deep Learning"", ""Autoencoders"", ""Alternating Optimization""]",0.4956359437119973,0,5.666666666666667,2018, deep_learning autoencoders alternating_optimization
B1DmUzWAW,A Simple Neural Attentive Meta-Learner,3,"[""meta-learning"", ""few-shot learning""]",0.5249375856399429,0,6.333333333333333,2018, meta_learning few_shot_learning
B1E7Pwqgl,Cooperative Training of Descriptor and Generator Networks,3,"[""Unsupervised Learning"", ""Deep learning""]",0.5445856690415737,1,4.333333333333333,2017, unsupervised_learning deep_learning
B1EA-M-0Z,Deep Neural Networks as Gaussian Processes,3,"[""Gaussian process"", ""Bayesian regression"", ""deep networks"", ""kernel methods""]",0.46875935789049283,0,5.666666666666667,2018, gaussian_process bayesian_regression deep_networks kernel_methods
B1EGg7ZCb,Autonomous Vehicle Fleet Coordination With Deep Reinforcement Learning,2,"[""Deep Reinforcement Learning"", ""mult-agent systems""]",0.3949984283167017,0,3.3333333333333335,2018, deep_reinforcement_learning mult_agent_systems
B1EPYJ-C-,Federated Learning: Strategies for Improving Communication Efficiency,3,[],0.44372884324296824,0,5.666666666666667,2018,
B1EVwkqTW,Make SVM great again with Siamese kernel for  few-shot learning,3,"[""SVM"", ""siamese network"", ""one-shot learning"", ""few-shot learning""]",0.5111605096032333,0,4.0,2018, svm siamese_network one_shot_learning few_shot_learning
B1ElR4cgg,Adversarially Learned Inference,3,"[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",0.47273176950897877,1,7.333333333333333,2017, computer_vision deep_learning unsupervised_learning semi_supervised_learning
B1G9tvcgx,Neural Machine Translation with Latent Semantic of Image and Text,3,[],0.5403936791976004,1,3.3333333333333335,2017,
B1GOWV5eg,Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning,3,"[""Deep learning"", ""Reinforcement Learning""]",0.45677996794834,1,7.666666666666667,2017, deep_learning reinforcement_learning
B1Gi6LeRZ,Learning from Between-class Examples for Deep Sound Recognition,3,"[""sound recognition"", ""supervised learning"", ""feature learning""]",0.5041106342677192,0,7.0,2018, sound_recognition supervised_learning feature_learning
B1IDRdeCW,The High-Dimensional Geometry of Binary Neural Networks,3,"[""Binary Neural Networks"", ""Neural Network Visualization""]",0.48751006010405284,0,6.0,2018, binary_neural_networks neural_network_visualization
B1Igu2ogg,Efficient Vector Representation for Documents through Corruption,3,"[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning""]",0.5153271310926887,1,6.666666666666667,2017, natural_language_processing deep_learning semi_supervised_learning
B1IzH7cxl,A Neural Stochastic Volatility Model,3,"[""Deep learning"", ""Supervised Learning""]",0.4095116757958031,1,5.333333333333333,2017, deep_learning supervised_learning
B1J_rgWRW,Understanding Deep Neural Networks with Rectified Linear Units,3,"[""expressive power"", ""benefits of depth"", ""empirical risk minimization"", ""global optimality"", ""computational hardness"", ""combinatorial optimization""]",0.49306498209508937,0,6.333333333333333,2018, expressive_power benefits_of_depth empirical_risk_minimization global_optimality computational_hardness combinatorial_optimization
B1KBHtcel,Here's My Point: Argumentation Mining with Pointer Networks,3,"[""Natural language processing""]",0.5950104439882179,1,4.666666666666667,2017, natural_language_processing
B1KFAGWAZ,Revisiting The Master-Slave Architecture In Multi-Agent Deep Reinforcement Learning,3,"[""Deep Reinforcement Learning"", ""Multi-Agent Reinforcement Learning"", ""StarCraft Micromanagement Tasks""]",0.46048929279471357,0,4.666666666666667,2018, deep_reinforcement_learning multi_agent_reinforcement_learning starcraft_micromanagement_tasks
B1KJJf-R-,Neural Program Search: Solving Data Processing Tasks from Description and Examples,3,"[""Deep learning"", ""Structured Prediction"", ""Natural Language Processing"", ""Neural Program Synthesis""]",0.5904012945178857,0,5.333333333333333,2018, deep_learning structured_prediction natural_language_processing neural_program_synthesis
B1Lc-Gb0Z,Deep Learning as a Mixed Convex-Combinatorial Optimization Problem,3,"[""hard-threshold units"", ""combinatorial optimization"", ""target propagation"", ""straight-through estimation"", ""quantization""]",0.46135190816917565,0,7.0,2018, hard_threshold_units combinatorial_optimization target_propagation straight_through_estimation quantization
B1M8JF9xx,On the Quantitative Analysis of Decoder-Based Generative Models,3,"[""Deep learning"", ""Unsupervised Learning""]",0.4928853370245852,1,6.666666666666667,2017, deep_learning unsupervised_learning
B1MRcPclx,Query-Reduction Networks for Question Answering,3,"[""Natural language processing"", ""Deep learning""]",0.49429357597480805,1,7.0,2017, natural_language_processing deep_learning
B1NGT8xCZ,Principled Hybrids of Generative and Discriminative Domain Adaptation,3,"[""domain adaptation"", ""neural networks"", ""generative models"", ""discriminative models""]",0.48903711696682856,0,5.333333333333333,2018, domain_adaptation neural_networks generative_models discriminative_models
B1NOXfWR-,Neural Task Graph Execution,3,"[""deep reinforcement learning"", ""task execution"", ""instruction execution""]",0.4410679593791402,0,5.333333333333333,2018, deep_reinforcement_learning task_execution instruction_execution
B1PA8fqeg,Multiagent System for Layer Free Network,3,[],0.4669163003013897,1,2.0,2017,
B1QRgziT-,Spectral Normalization for Generative Adversarial Networks,3,"[""Generative Adversarial Networks"", ""Deep Generative Models"", ""Unsupervised Learning""]",0.4177014627372563,0,7.333333333333333,2018, generative_adversarial_networks deep_generative_models unsupervised_learning
B1QgVti6Z,Empirical Risk Landscape Analysis for Understanding Deep Neural Networks,3,"[""Deep Learning Analysis"", ""Deep Learning Theory"", ""Empirical Risk"", ""Landscape Analysis"", ""Nonconvex Optimization""]",0.4275746608920538,0,5.666666666666667,2018, deep_learning_analysis deep_learning_theory empirical_risk landscape_analysis nonconvex_optimization
B1TTpYKgx,On the Expressive Power of Deep Neural Networks,3,"[""Theory"", ""Deep learning""]",0.5115833317134647,1,4.666666666666667,2017, theory deep_learning
B1X0mzZCW,Fidelity-Weighted Learning,3,"[""fidelity-weighted learning"", ""semisupervised learning"", ""weakly-labeled data"", ""teacher-student""]",0.5060707808247146,0,6.0,2018, fidelity_weighted_learning semisupervised_learning weakly_labeled_data teacher_student
B1X4DWWRb,Learning Weighted Representations for Generalization Across Designs,3,"[""Distributional shift"", ""causal effects"", ""domain adaptation""]",0.40646188955346185,0,6.666666666666667,2018, distributional_shift causal_effects domain_adaptation
B1YfAfcgl,Entropy-SGD: Biasing Gradient Descent Into Wide Valleys,3,"[""Deep learning"", ""Optimization""]",0.4760621448831934,1,8.0,2017, deep_learning optimization
B1Yy1BxCZ,"Don't Decay the Learning Rate, Increase the Batch Size",3,"[""batch size"", ""learning rate"", ""simulated annealing"", ""large batch training"", ""scaling rules"", ""stochastic gradient descent"", ""sgd"", ""imagenet"", ""optimization""]",0.5316445085808317,0,6.333333333333333,2018, batch_size learning_rate simulated_annealing large_batch_training scaling_rules stochastic_gradient_descent sgd imagenet optimization
B1Z3W-b0W,Learning to Infer,3,"[""Bayesian Deep Learning"", ""Amortized Inference"", ""Variational Auto-Encoders"", ""Learning to Learn""]",0.4763317565484868,0,5.333333333333333,2018, bayesian_deep_learning amortized_inference variational_auto_encoders learning_to_learn
B1ZXuTolx,Revisiting Denoising Auto-Encoders,3,[],0.5452209968595042,1,4.333333333333333,2017,
B1ZZTfZAW,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,3,"[""GAN"", ""medical"", ""records"", ""time"", ""series"", ""generation"", ""privacy""]",0.4355945962000435,0,5.0,2018, gan medical records time series generation privacy
B1ZvaaeAZ,WRPN: Wide Reduced-Precision Networks,3,"[""Low precision"", ""binary"", ""ternary"", ""4-bits networks""]",0.5146370915663117,0,6.333333333333333,2018, low_precision binary ternary 4_bits_networks
B1ae1lZRb,Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy,3,"[""Ternary"", ""4-bits"", ""low precision"", ""knowledge distillation"", ""knowledge transfer"", ""model compression""]",0.5562002750460221,0,7.333333333333333,2018, ternary 4_bits low_precision knowledge_distillation knowledge_transfer model_compression
B1akgy9xx,Making Stochastic Neural Networks from Deterministic Ones,3,"[""Deep learning"", ""Multi-modal learning"", ""Structured prediction""]",0.4989362052326544,1,5.5,2017, deep_learning multi_modal_learning structured_prediction
B1al7jg0b,Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation,3,"[""Catastrophic Interference"", ""Conceptor"", ""Backpropagation"", ""Continual Learning"", ""Lifelong Learning""]",0.5174548309419821,0,7.0,2018, catastrophic_interference conceptor backpropagation continual_learning lifelong_learning
B1bgpzZAZ,ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions,3,"[""Reading Comprehension"", ""Answering Multiple Choice Questions""]",0.5554976531707416,0,4.666666666666667,2018, reading_comprehension answering_multiple_choice_questions
B1ckMDqlg, Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,3,"[""Deep learning""]",0.5348125726629214,1,6.666666666666667,2017, deep_learning
B1e5ef-C-,"A Compressed Sensing View of Unsupervised Text Embeddings, Bag-of-n-Grams, and LSTMs",3,"[""theory"", ""LSTM"", ""unsupervised learning"", ""word embeddings"", ""compressed sensing"", ""sparse recovery"", ""document representation"", ""text classification""]",0.5240281713229475,0,6.666666666666667,2018, theory lstm unsupervised_learning word_embeddings compressed_sensing sparse_recovery document_representation text_classification
B1ewdt9xe,Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,3,[],0.5001932885555102,1,7.333333333333333,2017,
B1gJ1L2aW,Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality,3,"[""Adversarial Subspace"", ""Local Intrinsic Dimensionality"", ""Deep Neural Networks""]",0.44546750553978165,0,7.0,2018, adversarial_subspace local_intrinsic_dimensionality deep_neural_networks
B1gtu5ilg,Transfer of View-manifold Learning to Similarity Perception of Novel Objects,3,"[""Deep learning"", ""Transfer Learning""]",0.52755368925508,1,6.0,2017, deep_learning transfer_learning
B1hYRMbCW,On the regularization of Wasserstein GANs,3,[],0.40834925053626137,0,5.0,2018,
B1hcZZ-AW,N2N learning: Network to Network Compression via Policy Gradient Reinforcement Learning,3,"[""Deep learning"", ""Neural networks"", ""Model compression""]",0.47623631205239153,0,6.0,2018, deep_learning neural_networks model_compression
B1hdzd5lg,Words or Characters? Fine-grained Gating for Reading Comprehension,3,"[""Natural language processing"", ""Deep learning""]",0.570881829964792,1,6.666666666666667,2017, natural_language_processing deep_learning
B1i7ezW0-,Semi-Supervised Learning via New Deep Network Inversion,3,"[""inversion scheme"", ""deep neural networks"", ""semi-supervised learning"", ""MNIST"", ""SVHN"", ""CIFAR10""]",0.48390967918889505,0,5.333333333333333,2018, inversion_scheme deep_neural_networks semi_supervised_learning mnist svhn cifar10
B1jnyXXJx,Charged Point Normalization: An Efficient Solution to the Saddle Point Problem,3,"[""Deep learning"", ""Computer vision"", ""Optimization""]",0.47753580289956454,1,4.333333333333333,2017, deep_learning computer_vision optimization
B1jscMbAW,Divide and Conquer Networks,3,"[""Neural Networks"", ""Combinatorial Optimization"", ""Algorithms""]",0.50168095932575,0,6.666666666666667,2018, neural_networks combinatorial_optimization algorithms
B1kIr-WRb,LEARNING SEMANTIC WORD RESPRESENTATIONS VIA TENSOR FACTORIZATION,3,"[""Word Embeddings"", ""Tensor Factorization"", ""Natural Language Processing""]",0.5365961284766237,0,5.0,2018, word_embeddings tensor_factorization natural_language_processing
B1kJ6H9ex,Combining policy gradient and Q-learning,3,"[""Deep learning"", ""Reinforcement Learning""]",0.4480328760189463,1,7.666666666666667,2017, deep_learning reinforcement_learning
B1l8BtlCb,Non-Autoregressive Neural Machine Translation,3,"[""machine translation"", ""non-autoregressive"", ""transformer"", ""fertility"", ""nmt""]",0.44347894000389193,0,6.666666666666667,2018, machine_translation non_autoregressive transformer fertility nmt
B1lMMx1CW,THE EFFECTIVENESS OF A TWO-LAYER NEURAL NETWORK FOR RECOMMENDATIONS,3,"[""Recommender systems"", ""deep learning"", ""personalization""]",0.5574322658994959,0,6.333333333333333,2018, recommender_systems deep_learning personalization
B1mAJI9gl,Towards Understanding the Invertibility of Convolutional Neural Networks,3,"[""Deep learning"", ""Theory""]",0.4476369485269895,1,5.333333333333333,2017, deep_learning theory
B1mAkPxCZ,VOCABULARY-INFORMED VISUAL FEATURE AUGMENTATION FOR ONE-SHOT LEARNING,3,"[""vocabulary-informed learning"", ""data augmentation""]",0.46774618188244904,0,5.0,2018, vocabulary_informed_learning data_augmentation
B1mSWUxR-,Softmax Q-Distribution Estimation for Structured Prediction: A Theoretical Interpretation for RAML,3,"[""structured prediction"", ""RAML"", ""theory"", ""Bayes decision rule"", ""reward function""]",0.5168811757041951,0,5.333333333333333,2018, structured_prediction raml theory bayes_decision_rule reward_function
B1mvVm-C-,Universal Agent for Disentangling Environments and Tasks,3,"[""reinforcement learning"", ""transfer learning""]",0.48541035735333943,0,6.333333333333333,2018, reinforcement_learning transfer_learning
B1n8LexRZ,Generalizing Hamiltonian Monte Carlo with Neural Networks,3,"[""markov"", ""chain"", ""monte"", ""carlo"", ""sampling"", ""posterior"", ""deep"", ""learning"", ""hamiltonian"", ""mcmc""]",0.5049180647165477,0,7.0,2018, markov chain monte carlo sampling posterior deep learning hamiltonian mcmc
B1nLkl-0Z,Learning Gaussian Policies from Smoothed Action Value Functions,3,"[""Reinforcement learning""]",0.4641362881205623,0,5.666666666666667,2018, reinforcement_learning
B1nZ1weCZ,Learning to Multi-Task by Active Sampling,3,"[""Deep Reinforcement Learning""]",0.4467606496524081,0,6.333333333333333,2018, deep_reinforcement_learning
B1nxTzbRZ,Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger,3,"[""forward modeling"", ""partially observable"", ""deep learning"", ""strategy game"", ""real-time strategy""]",0.5074812045580616,0,4.666666666666667,2018, forward_modeling partially_observable deep_learning strategy_game real_time_strategy
B1oK8aoxe,Stochastic Neural Networks for Hierarchical Reinforcement Learning,3,"[""Deep learning"", ""Unsupervised Learning"", ""Reinforcement Learning""]",0.45943927811615193,1,7.333333333333333,2017, deep_learning unsupervised_learning reinforcement_learning
B1p461b0W,Deep Learning is Robust to Massive Label Noise,3,"[""label noise"", ""weakly supervised learning"", ""robustness of neural networks"", ""deep learning"", ""large datasets""]",0.4831739544601671,0,4.666666666666667,2018, label_noise weakly_supervised_learning robustness_of_neural_networks deep_learning large_datasets
B1s6xvqlx,Recurrent Environment Simulators,3,"[""Deep learning"", ""Unsupervised Learning"", ""Applications""]",0.546122330356027,1,6.666666666666667,2017, deep_learning unsupervised_learning applications
B1spAqUp-,Pixel Deconvolutional Networks,3,"[""Deep Learning"", ""Deconvolutional Layer"", ""Pixel CNN""]",0.5758498021093833,0,5.333333333333333,2018, deep_learning deconvolutional_layer pixel_cnn
B1suU-bAW,Learning Covariate-Specific Embeddings with Tensor Decompositions,3,"[""Word embedding"", ""tensor decomposition""]",0.4856429735251352,0,5.0,2018, word_embedding tensor_decomposition
B1tC-LT6W,Trace norm regularization and faster inference for embedded speech recognition RNNs,3,"[""LVCSR"", ""speech recognition"", ""embedded"", ""low rank factorization"", ""RNN"", ""GRU"", ""trace norm""]",0.5575092332917404,0,4.666666666666667,2018, lvcsr speech_recognition embedded low_rank_factorization rnn gru trace_norm
B1tExikAW,LatentPoison -- Adversarial Attacks On The Latent Space,3,"[""adversarial attacks"", ""security"", ""auto-encoder""]",0.4727347010695207,0,4.0,2018, adversarial_attacks security auto_encoder
B1twdMCab,Dynamic Integration of Background Knowledge in Neural NLU Systems,3,"[""natural language processing"", ""background knowledge"", ""word embeddings"", ""question answering"", ""natural language inference""]",0.5841800383865924,0,5.333333333333333,2018, natural_language_processing background_knowledge word_embeddings question_answering natural_language_inference
B1uvH_gC-,Parametric Manifold Learning Via Sparse Multidimensional Scaling,3,"[""Manifold Learning"", ""Non-linear Dimensionality Reduction"", ""Neural Networks"", ""Unsupervised Learning""]",0.5053806893785233,0,4.0,2018, manifold_learning non_linear_dimensionality_reduction neural_networks unsupervised_learning
B1vRTeqxg,Learning Continuous Semantic Representations of Symbolic Expressions,4,"[""Deep learning""]",0.615847412038213,1,6.0,2017, deep_learning
B1ydPgTpW,Predicting Auction Price of Vehicle License Plate with Deep Recurrent Neural Network,3,"[""price predictions"", ""expert system"", ""recurrent neural networks"", ""deep learning"", ""natural language processing""]",0.4885145066226151,0,4.666666666666667,2018, price_predictions expert_system recurrent_neural_networks deep_learning natural_language_processing
B1zlp1bRW,Large Scale Optimal Transport and Mapping Estimation,2,"[""optimal transport"", ""Wasserstein"", ""domain adaptation"", ""generative models"", ""Monge map"", ""optimal mapping""]",0.38671561210207195,0,6.75,2018, optimal_transport wasserstein domain_adaptation generative_models monge_map optimal_mapping
BJ--gPcxl,Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks,3,"[""Deep learning"", ""Semi-Supervised Learning"", ""Computer vision""]",0.4823870651575079,1,5.666666666666667,2017, deep_learning semi_supervised_learning computer_vision
BJ0Ee8cxx,Hierarchical Memory Networks,3,"[""Deep learning"", ""Natural language processing""]",0.5478972734151673,1,4.666666666666667,2017, deep_learning natural_language_processing
BJ0hF1Z0b,Learning Differentially Private Recurrent Language Models,3,"[""differential privacy"", ""LSTMs"", ""language models"", ""privacy""]",0.4767218877330485,0,7.333333333333333,2018, differential_privacy lstms language_models privacy
BJ3filKll,Efficient Representation of Low-Dimensional Manifolds using Deep Networks,3,"[""Theory"", ""Deep learning""]",0.5237559520010634,1,6.0,2017, theory deep_learning
BJ46w6Ule,Dynamic Partition Models,3,[],0.5399381094792491,1,4.0,2017,
BJ4prNx0W,Learning what to learn in a neural program,3,[],0.5706133970542062,0,4.666666666666667,2018,
BJ5UeU9xx,Visualizing Deep Neural Network Decisions: Prediction Difference Analysis,3,"[""Deep learning"", ""Applications""]",0.5287523558873084,1,7.0,2017, deep_learning applications
BJ6anzb0Z,Multimodal Sentiment Analysis To Explore the Structure of Emotions,4,[],0.6136980570725082,0,5.0,2018,
BJ6oOfqge,Temporal Ensembling for Semi-Supervised Learning,3,[],0.46781038612798476,1,8.0,2017,
BJ78bJZCZ,Efficiently applying attention to sequential data with the Recurrent Discounted Attention unit,3,"[""RNNs""]",0.575042851915103,0,4.333333333333333,2018, rnns
BJ7d0fW0b,Faster Reinforcement Learning with Expert State Sequences,3,"[""Reinforcement Learning"", ""Imitation Learning""]",0.4517054702567807,0,5.666666666666667,2018, reinforcement_learning imitation_learning
BJ8c3f-0b,Auto-Encoding Sequential Monte Carlo,3,"[""Variational Autoencoders"", ""Inference amortization"", ""Model learning"", ""Sequential Monte Carlo"", ""ELBOs""]",0.48630965794284303,0,5.666666666666667,2018, variational_autoencoders inference_amortization model_learning sequential_monte_carlo elbos
BJ8fyHceg,Tuning Recurrent Neural Networks with Reinforcement Learning,3,"[""Deep learning"", ""Reinforcement Learning"", ""Structured prediction"", ""Supervised Learning"", ""Applications""]",0.5038219030774792,1,5.333333333333333,2017, deep_learning reinforcement_learning structured_prediction supervised_learning applications
BJ8vJebC-,Synthetic and Natural Noise Both Break Neural Machine Translation,3,"[""neural machine translation"", ""characters"", ""noise"", ""adversarial examples"", ""robust training""]",0.5512793599956477,0,7.333333333333333,2018, neural_machine_translation characters noise adversarial_examples robust_training
BJ9fZNqle,Multi-modal Variational Encoder-Decoders,3,"[""Deep learning"", ""Structured prediction"", ""Natural language processing""]",0.5466679031710219,1,3.6666666666666665,2017, deep_learning structured_prediction natural_language_processing
BJAA4wKxg,A Convolutional Encoder Model for Neural Machine Translation,3,[],0.5722365234419833,1,6.333333333333333,2017,
BJAFbaolg,Learning to Generate Samples from Noise through Infusion Training,3,"[""Deep learning"", ""Unsupervised Learning""]",0.4420268865526358,1,7.0,2017, deep_learning unsupervised_learning
BJB7fkWR-,Domain Adaptation for Deep Reinforcement Learning in Visually Distinct Games,3,"[""Deep Reinforcement Learning"", ""Domain Adaptation"", ""Adversarial Networks""]",0.5165459824531422,0,3.0,2018, deep_reinforcement_learning domain_adaptation adversarial_networks
BJC8LF9ex,Recurrent Neural Networks for Multivariate Time Series with Missing Values,3,"[""Deep learning""]",0.5359765927105329,1,5.666666666666667,2017, deep_learning
BJC_jUqxe,A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5521391597602778,1,6.333333333333333,2017, natural_language_processing deep_learning supervised_learning
BJDEbngCZ,Global Convergence of Policy Gradient Methods for Linearized  Control Problems,3,"[""linear quadratic regulator"", ""policy gradient"", ""natural gradient"", ""reinforcement learning"", ""non-convex optimization""]",0.4617310198169931,0,5.333333333333333,2018, linear_quadratic_regulator policy_gradient natural_gradient reinforcement_learning non_convex_optimization
BJDH5M-AW,Synthesizing Robust Adversarial Examples,3,"[""adversarial examples""]",0.488369422927545,0,6.333333333333333,2018, adversarial_examples
BJE-4xW0W,CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training,3,"[""causality"", ""structural causal models"", ""GANs"", ""conditional GANs"", ""BEGAN"", ""adversarial training""]",0.40509058783595114,0,7.333333333333333,2018, causality structural_causal_models gans conditional_gans began adversarial_training
BJFG8Yqxl,Group Sparse CNNs for Question Sentence Classification with Answer Sets,3,[],0.5310267349610506,1,5.0,2017,
BJGWO9k0Z,Critical Percolation as a Framework to Analyze the Training of Deep Networks,3,"[""Deep Convolutional Networks"", ""Loss function landscape"", ""Graph Structured Data"", ""Training Complexity"", ""Theory of deep learning"", ""Percolation theory"", ""Anderson Localization""]",0.4705488492636542,0,6.666666666666667,2018, deep_convolutional_networks loss_function_landscape graph_structured_data training_complexity theory_of_deep_learning percolation_theory anderson_localization
BJIgi_eCZ,FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension,3,"[""Attention Mechanism"", ""Machine Comprehension"", ""Natural Language Processing"", ""Deep Learning""]",0.5409534777634706,0,7.333333333333333,2018, attention_mechanism machine_comprehension natural_language_processing deep_learning
BJInEZsTb,Learning Representations and Generative Models for 3D Point Clouds,3,"[""representation learning"", ""auto-encoders"", ""3D point clouds"", ""generative models"", ""GANs"", ""Gaussian Mixture Models""]",0.5404746490575686,0,6.333333333333333,2018, representation_learning auto_encoders 3d_point_clouds generative_models gans gaussian_mixture_models
BJInMmWC-,Generative Entity Networks: Disentangling Entitites and Attributes in Visual Scenes using Partial Natural Language Descriptions,3,"[""VAE"", ""Generative Model"", ""Vision"", ""Natural Language""]",0.4960463313733846,0,4.666666666666667,2018, vae generative_model vision natural_language
BJJ9bz-0-,Reinforcement Learning from Imperfect Demonstrations,3,"[""learning from demonstration"", ""reinforcement learning"", ""maximum entropy learning""]",0.427889646036204,0,5.333333333333333,2018, learning_from_demonstration reinforcement_learning maximum_entropy_learning
BJJLHbb0-,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,3,"[""Density estimation"", ""unsupervised anomaly detection"", ""high-dimensional data"", ""Deep autoencoder"", ""Gaussian mixture modeling"", ""latent low-dimensional space""]",0.44553041789446185,0,8.0,2018, density_estimation unsupervised_anomaly_detection high_dimensional_data deep_autoencoder gaussian_mixture_modeling latent_low_dimensional_space
BJK3Xasel,Nonparametric Neural Networks,3,"[""Deep learning"", ""Supervised Learning""]",0.5031176120234043,1,6.333333333333333,2017, deep_learning supervised_learning
BJKYvt5lg,PixelVAE: A Latent Variable Model for Natural Images,3,"[""Deep learning"", ""Unsupervised Learning""]",0.5297137146548341,1,6.666666666666667,2017, deep_learning unsupervised_learning
BJLmN8xRW,Character Level Based Detection of DGA Domain Names,3,"[""deep neural networks"", ""short text classification"", ""cybersecurity"", ""domain generation algorithms"", ""malicious domain names""]",0.5443670651701286,0,5.333333333333333,2018, deep_neural_networks short_text_classification cybersecurity domain_generation_algorithms malicious_domain_names
BJMuY-gRW,Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs,3,"[""hierarchical"", ""tree-lstm"", ""treelstm"", ""syntax"", ""composition""]",0.5538463788771039,0,5.0,2018, hierarchical tree_lstm treelstm syntax composition
BJNRFNlRW,TRAINING GENERATIVE ADVERSARIAL NETWORKS VIA PRIMAL-DUAL SUBGRADIENT METHODS: A LAGRANGIAN PERSPECTIVE ON GAN,2,"[""GAN"", ""Primal-Dual Subgradient"", ""Mode Collapse"", ""Saddle Point""]",0.3721226746686866,0,6.666666666666667,2018, gan primal_dual_subgradient mode_collapse saddle_point
BJO-BuT1g,A Learned Representation For Artistic Style,3,"[""Computer vision"", ""Deep learning""]",0.5479860401664198,1,7.666666666666667,2017, computer_vision deep_learning
BJOFETxR-,Learning to Represent Programs with Graphs,3,"[""programs"", ""source code"", ""graph neural networks""]",0.5171436514996337,0,8.0,2018, programs source_code graph_neural_networks
BJQPG5lR-,Avoiding degradation in deep feed-forward networks by phasing out skip-connections,3,"[""optimization"", ""vanishing gradients"", ""shattered gradients"", ""skip-connections""]",0.4805375010603333,0,6.0,2018, optimization vanishing_gradients shattered_gradients skip_connections
BJQRKzbA-,Hierarchical Representations for Efficient Architecture Search,3,"[""deep learning"", ""architecture search""]",0.49920686318602403,0,6.666666666666667,2018, deep_learning architecture_search
BJRIA3Fgg,Modularized Morphing of Neural Networks,3,"[""Deep learning"", ""Computer vision""]",0.47905240123501175,1,6.25,2017, deep_learning computer_vision
BJRZzFlRb,Compressing Word Embeddings via Deep Compositional Code Learning,3,"[""natural language processing"", ""word embedding"", ""compression"", ""deep learning""]",0.5689888094561175,0,7.0,2018, natural_language_processing word_embedding compression deep_learning
BJRxfZbAW,The Context-Aware Learner,3,[],0.4680691520667362,0,4.666666666666667,2018,
BJVEEF9lx,Learning Approximate Distribution-Sensitive Data Structures,3,"[""Unsupervised Learning""]",0.5723568999233525,1,3.6666666666666665,2017, unsupervised_learning
BJYwwY9ll,"Snapshot Ensembles: Train 1, Get M for Free",3,"[""Deep learning"", ""Computer vision""]",0.5100887528203907,1,8.0,2017, deep_learning computer_vision
BJ_MGwqlg,Rethinking Numerical Representations for Deep Neural Networks,3,"[""Deep learning""]",0.5435165589503443,1,5.333333333333333,2017, deep_learning
BJ_QxP1AZ,Unleashing the Potential of CNNs for Interpretable Few-Shot Learning,3,"[""Few-Shot Learning"", ""Neural Network Understanding"", ""Visual Concepts""]",0.5242104633557539,0,5.333333333333333,2018, few_shot_learning neural_network_understanding visual_concepts
BJ_UL-k0b,Recasting Gradient-Based Meta-Learning as Hierarchical Bayes,3,"[""meta-learning"", ""learning to learn"", ""hierarchical Bayes"", ""approximate Bayesian methods""]",0.5069542285142182,0,6.666666666666667,2018, meta_learning learning_to_learn hierarchical_bayes approximate_bayesian_methods
BJ_wN01C-,Deep Rewiring: Training very sparse deep networks,3,"[""deep learning"", ""pruning"", ""LSTM"", ""convolutional networks"", ""recurrent neural network"", ""sparse networks"", ""neuromorphic hardware"", ""energy efficient computing"", ""low memory hardware"", ""stochastic differential equation"", ""fokker-planck equation""]",0.4785946159308132,0,6.333333333333333,2018, deep_learning pruning lstm convolutional_networks recurrent_neural_network sparse_networks neuromorphic_hardware energy_efficient_computing low_memory_hardware stochastic_differential_equation fokker_planck_equation
BJa0ECFxe,Information Dropout: learning optimal representations through noise,3,"[""Theory"", ""Deep learning""]",0.5174499000094912,1,5.333333333333333,2017, theory deep_learning
BJaU__eCZ,Hallucinating brains with artificial brains,3,"[""3D fMRI data"", ""Deep Learning"", ""Generative Adversarial Network"", ""Classification""]",0.4453278851484654,0,6.333333333333333,2018, 3d_fmri_data deep_learning generative_adversarial_network classification
BJbD_Pqlg,Human perception in computer vision,3,"[""Computer vision"", ""Transfer Learning""]",0.5032290335063966,1,6.333333333333333,2017, computer_vision transfer_learning
BJcAWaeCW,Graph Topological Features via GAN,3,"[""graph topology"", ""GAN"", ""network science"", ""hierarchical learning""]",0.4208776144021058,0,3.6666666666666665,2018, graph_topology gan network_science hierarchical_learning
BJehNfW0-,Do GANs learn the distribution? Some Theory and Empirics,2,"[""Generative Adversarial Networks"", ""mode collapse"", ""birthday paradox"", ""support size estimation""]",0.37269123842101676,0,6.666666666666667,2018, generative_adversarial_networks mode_collapse birthday_paradox support_size_estimation
BJgPCveAW,Characterizing Sparse Connectivity Patterns in Neural Networks,3,"[""Machine learning"", ""Neural networks"", ""Sparse neural networks"", ""Pre-defined sparsity"", ""Scatter"", ""Connectivity patterns"", ""Adjacency matrix"", ""Parameter Reduction"", ""Morse code""]",0.5377813808710649,0,4.333333333333333,2018, machine_learning neural_networks sparse_neural_networks pre_defined_sparsity scatter connectivity_patterns adjacency_matrix parameter_reduction morse_code
BJgVaG-Ab,AUTOMATA GUIDED HIERARCHICAL REINFORCEMENT LEARNING FOR ZERO-SHOT SKILL COMPOSITION,3,"[""Hierarchical reinforcement learning"", ""temporal logic"", ""skill composition""]",0.48379863972953774,0,4.0,2018, hierarchical_reinforcement_learning temporal_logic skill_composition
BJgd7m0xRZ,Unsupervised Adversarial Anomaly  Detection using One-Class Support Vector Machines,3,"[""anomaly detection"", ""one class support vector machine"", ""adversarial learning""]",0.48124729642640107,0,4.0,2018, anomaly_detection one_class_support_vector_machine adversarial_learning
BJh6Ztuxl,Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks,3,"[""Natural language processing"", ""Deep learning""]",0.5850871284164161,1,8.0,2017, natural_language_processing deep_learning
BJhZeLsxx,What does it take to generate natural textures?,3,"[""Deep learning"", ""Unsupervised Learning""]",0.5467472963352108,1,7.666666666666667,2017, deep_learning unsupervised_learning
BJhxcGZCW,Generative Discovery of Relational Medical Entity Pairs,3,"[""Knowledge Discovery"", ""Generative Modeling"", ""Medical"", ""Entity Pair""]",0.46828010887443616,0,3.3333333333333335,2018, knowledge_discovery generative_modeling medical entity_pair
BJij4yg0Z,A Bayesian Perspective on Generalization and Stochastic Gradient Descent,3,"[""generalization"", ""stochastic gradient descent"", ""stochastic differential equations"", ""scaling rules"", ""large batch training"", ""bayes theorem"", ""batch size""]",0.5045679927984038,0,5.666666666666667,2018, generalization stochastic_gradient_descent stochastic_differential_equations scaling_rules large_batch_training bayes_theorem batch_size
BJj6qGbRW,Few-Shot Learning with Graph Neural Networks,3,[],0.5254222830608773,0,7.0,2018,
BJjBnN9a-,Continuous Convolutional Neural Networks for Image Classification,3,"[""convolutional neural networks"", ""image classification"", ""deep learning"", ""feature representation"", ""hilbert maps"", ""reproducing kernel hilbert space""]",0.5334983787054971,0,5.0,2018, convolutional_neural_networks image_classification deep_learning feature_representation hilbert_maps reproducing_kernel_hilbert_space
BJjn-Yixl,Attentive Recurrent Comparators,3,"[""Deep learning"", ""Computer vision""]",0.5877755467544374,1,4.0,2017, deep_learning computer_vision
BJjquybCW,The loss surface and expressivity of deep convolutional neural networks,3,"[""convolutional neural networks"", ""loss surface"", ""expressivity"", ""critical point"", ""global minima"", ""linear separability""]",0.5046459323623339,0,5.5,2018, convolutional_neural_networks loss_surface expressivity critical_point global_minima linear_separability
BJk59JZ0b,Guide Actor-Critic for Continuous Control,3,"[""Reinforcement learning"", ""actor-critic"", ""continuous control""]",0.414873280238749,0,5.666666666666667,2018, reinforcement_learning actor_critic continuous_control
BJk7Gf-CZ,Global Optimality Conditions for Deep Neural Networks,3,"[""deep linear neural networks"", ""global optimality"", ""deep learning""]",0.4209770769161217,0,6.666666666666667,2018, deep_linear_neural_networks global_optimality deep_learning
BJlrSmbAZ,Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,3,"[""uncertainty estimation"", ""deep learning"", ""Bayesian learning"", ""batch normalization""]",0.5119860383661201,0,5.333333333333333,2018, uncertainty_estimation deep_learning bayesian_learning batch_normalization
BJluGHcee,Tensorial Mixture Models,3,"[""Deep learning"", ""Supervised Learning"", ""Unsupervised Learning""]",0.5149358293968784,1,5.333333333333333,2017, deep_learning supervised_learning unsupervised_learning
BJluxbWC-,Unseen Class Discovery in Open-world Classification,3,[],0.48745654393227467,0,4.666666666666667,2018,
BJlxmAKlg,ReasoNet: Learning to Stop Reading in Machine Comprehension,3,"[""Deep learning"", ""Natural language processing""]",0.5539553394900978,1,5.333333333333333,2017, deep_learning natural_language_processing
BJm4T4Kgx,Adversarial Machine Learning at Scale,3,"[""Computer vision"", ""Supervised Learning""]",0.4607259942865136,1,6.333333333333333,2017, computer_vision supervised_learning
BJmCKBqgl,DyVEDeep: Dynamic Variable Effort Deep Neural Networks,3,[],0.549905462312958,1,6.333333333333333,2017,
BJrFC6ceg,PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications,3,[],0.4784422040619716,1,6.666666666666667,2017,
BJtNZAFgg,Adversarial Feature Learning,2,[],0.3964535844684444,1,7.0,2017,
BJuWrGW0Z,Dynamic Neural Program Embeddings for Program Repair,3,"[""Program Embedding"", ""Program Semantics"", ""Dynamic Traces""]",0.5604990368710199,0,6.666666666666667,2018, program_embedding program_semantics dynamic_traces
BJubPWZRW,Cross-View Training for Semi-Supervised Learning,3,"[""semi-supervised learning"", ""image recognition"", ""sequence tagging"", ""dependency parsing""]",0.5169207705900849,0,4.666666666666667,2018, semi_supervised_learning image_recognition sequence_tagging dependency_parsing
BJuysoFeg,Revisiting Batch Normalization For Practical Domain Adaptation,3,[],0.4770399685056344,1,5.0,2017,
BJvVbCJCb,Neural Clustering By Predicting And Copying Noise,3,"[""unsupervised learning"", ""clustering"", ""deep learning""]",0.4944692247244617,0,5.0,2018, unsupervised_learning clustering deep_learning
BJvWjcgAZ,Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update,3,"[""Deep Learning"", ""Reinforcement Learning""]",0.5071369077067452,0,5.0,2018, deep_learning reinforcement_learning
BJwFrvOeg,A Neural Knowledge Language Model,3,"[""Natural language processing"", ""Deep learning""]",0.5155530939935096,1,6.0,2017, natural_language_processing deep_learning
BJxhLAuxg,A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games,3,[],0.47656255497318467,1,4.0,2017,
BJy0fcgRZ,Capturing Human Category Representations by Sampling in Deep Feature Spaces,3,"[""category representations"", ""psychology"", ""cognitive science"", ""deep neural networks""]",0.5440310522699594,0,5.333333333333333,2018, category_representations psychology cognitive_science deep_neural_networks
BJypUGZ0Z,Accelerating Neural Architecture Search using Performance Prediction,3,[],0.5590271450978701,0,5.333333333333333,2018,
Bk-ofQZRb,TD Learning with Constrained Gradients,3,"[""Reinforcement Learning"", ""TD Learning"", ""DQN""]",0.4769366852107588,0,3.0,2018, reinforcement_learning td_learning dqn
Bk0FWVcgx,Topology and Geometry of Half-Rectified Network Optimization,3,"[""Theory"", ""Deep learning""]",0.4128853759653409,1,5.666666666666667,2017, theory deep_learning
Bk0MRI5lg,Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units,3,[],0.5132907627304438,1,4.666666666666667,2017,
Bk2TqVcxe,Discovering objects and their relations from entangled scene representations,3,[],0.5322278415607226,1,5.666666666666667,2017,
Bk346Ok0W,Sensor Transformation Attention Networks,3,"[""attention"", ""sensor-selection"", ""multi-sensor"", ""natural noise""]",0.5808618905869639,0,4.666666666666667,2018, attention sensor_selection multi_sensor natural_noise
Bk3F5Y9lx,Epitomic Variational Autoencoders,3,"[""Unsupervised Learning""]",0.4854770282670677,1,5.666666666666667,2017, unsupervised_learning
Bk67W4Yxl,Improved Architectures for Computer Go,3,"[""Games"", ""Supervised Learning"", ""Deep learning""]",0.41520225963045465,1,4.25,2017, games supervised_learning deep_learning
Bk6qQGWRb,Efficient Exploration through Bayesian   Deep Q-Networks,3,"[""Deep RL"", ""Thompson Sampling"", ""Posterior update""]",0.45240324752738265,0,5.333333333333333,2018, deep_rl thompson_sampling posterior_update
Bk7wvW-C-,Exploring Asymmetric Encoder-Decoder Structure for Context-based Sentence Representation Learning,3,"[""asymmetric structure"", ""RNN-CNN"", ""fast"", ""unsupervised"", ""representation"", ""sentence""]",0.5240969601303748,0,5.333333333333333,2018, asymmetric_structure rnn_cnn fast unsupervised representation sentence
Bk8BvDqex,Metacontrol for Adaptive Imagination-Based Optimization,3,"[""Deep learning"", ""Reinforcement Learning"", ""Optimization""]",0.5204267955631994,1,7.75,2017, deep_learning reinforcement_learning optimization
Bk8N0RLxx,Vocabulary Selection Strategies for Neural Machine Translation,3,"[""Natural language processing""]",0.48475533576238933,1,4.5,2017, natural_language_processing
Bk8ZcAxR-,Eigenoption Discovery through the Deep Successor Representation,3,"[""reinforcement learning"", ""options"", ""successor representation"", ""proto-value functions"", ""Atari"", ""Arcade Learning Environment""]",0.5010109625634394,0,7.333333333333333,2018, reinforcement_learning options successor_representation proto_value_functions atari arcade_learning_environment
Bk8aOm9xl,Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning,3,"[""Reinforcement Learning""]",0.44645535008510384,1,6.0,2017, reinforcement_learning
Bk9zbyZCZ, Neural Map: Structured Memory for Deep Reinforcement Learning,3,"[""deep reinforcement learning"", ""deep learning"", ""memory""]",0.5478505431280035,0,7.333333333333333,2018, deep_reinforcement_learning deep_learning memory
BkA7gfZAb,Stable Distribution Alignment Using the Dual of the Adversarial Distance,3,"[""domain adaptation"", ""adversarial networks"", ""statistical distance"", ""duality""]",0.4770553331849172,0,5.666666666666667,2018, domain_adaptation adversarial_networks statistical_distance duality
BkCPyXm1l,SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks,3,"[""Deep learning"", ""Optimization"", ""Computer vision""]",0.5009766094611194,1,3.6666666666666665,2017, deep_learning optimization computer_vision
BkCV_W-AZ,Regret Minimization for Partially Observable Deep Reinforcement Learning,3,"[""deep reinforcement learning""]",0.5061114180699661,0,5.333333333333333,2018, deep_reinforcement_learning
BkDB51WR-,Learning temporal evolution of probability distribution with Recurrent Neural Network,3,"[""predictive distribution estimation"", ""probabilistic RNN"", ""uncertainty in time series prediction""]",0.5378390376380817,0,5.666666666666667,2018, predictive_distribution_estimation probabilistic_rnn uncertainty_in_time_series_prediction
BkGakb9lx,RenderGAN: Generating Realistic Labeled Data,3,"[""Unsupervised Learning"", ""Computer vision"", ""Deep learning"", ""Applications""]",0.5105411320842145,1,5.666666666666667,2017, unsupervised_learning computer_vision deep_learning applications
BkIkkseAZ,Theoretical properties of the global optimizer of two-layer Neural Network,3,"[""Non-convex optimization"", ""Two-layer Neural Network"", ""global optimality"", ""first-order optimality""]",0.48378700345100817,0,6.0,2018, non_convex_optimization two_layer_neural_network global_optimality first_order_optimality
BkIqod5ll,Convolutional Neural Networks Generalization Utilizing the Data Graph Structure,3,"[""Supervised Learning"", ""Deep learning""]",0.5483968077389438,1,4.0,2017, supervised_learning deep_learning
BkJ3ibb0-,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,3,[],0.45544622378209926,0,6.666666666666667,2018,
BkJsCIcgl,The Predictron: End-To-End Learning and Planning,3,"[""Deep learning"", ""Reinforcement Learning"", ""Supervised Learning"", ""Semi-Supervised Learning""]",0.4997670846450158,1,6.333333333333333,2017, deep_learning reinforcement_learning supervised_learning semi_supervised_learning
BkLhaGZRW,Improving GAN Training via Binarized Representation Entropy (BRE) Regularization,3,[],0.42117925930122047,0,5.666666666666667,2018,
BkLhzHtlg,Learning Recurrent Representations for Hierarchical Behavior Modeling,3,"[""Unsupervised Learning"", ""Semi-Supervised Learning"", ""Reinforcement Learning"", ""Applications""]",0.5667625629514466,1,6.666666666666667,2017, unsupervised_learning semi_supervised_learning reinforcement_learning applications
BkM27IxR-,Learning to Optimize Neural Nets,3,"[""Learning to learn"", ""meta-learning"", ""reinforcement learning"", ""optimization""]",0.46371587926344066,0,5.666666666666667,2018, learning_to_learn meta_learning reinforcement_learning optimization
BkM3ibZRW,Adversarially Regularized Autoencoders,3,"[""representation learning"", ""natural language generation"", ""discrete structure modeling"", ""adversarial training"", ""unaligned text style-transfer""]",0.526786515033134,0,5.75,2018, representation_learning natural_language_generation discrete_structure_modeling adversarial_training unaligned_text_style_transfer
BkN_r2lR-,Identifying Analogies Across Domains,3,"[""unsupervised mapping"", ""cross domain mapping""]",0.5039597681251079,0,5.333333333333333,2018, unsupervised_mapping cross_domain_mapping
BkPrDFgR-,Piecewise Linear Neural Networks verification: A comparative study,3,"[""Verification"", ""SMT solver"", ""Mixed Integer Programming"", ""Neural Networks""]",0.5016034575716662,0,4.666666666666667,2018, verification smt_solver mixed_integer_programming neural_networks
BkQCGzZ0-,Discrete Autoencoders for Sequence Models,3,"[""autoencoders"", ""sequence models"", ""discrete representations""]",0.5241051888039124,0,5.0,2018, autoencoders sequence_models discrete_representations
BkQqq0gRb,Variational Continual Learning,3,"[""continual learning"", ""online variational inference""]",0.4915076236214339,0,6.0,2018, continual_learning online_variational_inference
BkS3fnl0W,Semi-supervised Outlier Detection using Generative And Adversary Framework,3,"[""Semi-supervised Learning"", ""Generative And Adversary Framework"", ""One-class classification"", ""Outlier detection""]",0.4160163865990878,0,3.6666666666666665,2018, semi_supervised_learning generative_and_adversary_framework one_class_classification outlier_detection
BkSDMA36Z,A New Method of Region Embedding for Text Classification,3,"[""region embedding"", ""local context unit"", ""text classification""]",0.5638504818852073,0,6.0,2018, region_embedding local_context_unit text_classification
BkSmc8qll,Dynamic Neural Turing Machine with Continuous and Discrete Addressing Schemes,3,"[""Deep learning"", ""Natural language processing"", ""Reinforcement Learning""]",0.5750694569049554,1,5.666666666666667,2017, deep_learning natural_language_processing reinforcement_learning
BkSqjHqxg,Skip-graph: Learning graph embeddings with an encoder-decoder model,3,"[""Unsupervised Learning"", ""Deep learning""]",0.49472472813372625,1,6.0,2017, unsupervised_learning deep_learning
BkUDW_lCb,Pointing Out SQL Queries From Text,3,"[""Program Synthesis"", ""Semantic Parsing"", ""WikiTable"", ""SQL"", ""Pointer Network""]",0.5462141142115287,0,4.666666666666667,2018, program_synthesis semantic_parsing wikitable sql pointer_network
BkUDvt5gg,Wav2Letter: an End-to-End ConvNet-based Speech Recognition System,3,"[""Deep learning"", ""Speech"", ""Structured prediction""]",0.5435494493979406,1,6.5,2017, deep_learning speech structured_prediction
BkUHlMZ0b,Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach,3,"[""robustness"", ""adversarial machine learning"", ""neural network"", ""extreme value theory"", ""adversarial example"", ""adversarial perturbation""]",0.4098022879671922,0,7.0,2018, robustness adversarial_machine_learning neural_network extreme_value_theory adversarial_example adversarial_perturbation
BkUp6GZRW,Boosting the Actor with Dual Critic,3,"[""reinforcement learning"", ""actor-critic algorithm"", ""Lagrangian duality""]",0.4469798228252738,0,6.0,2018, reinforcement_learning actor_critic_algorithm lagrangian_duality
BkV4VS9ll,The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning,3,"[""Theory"", ""Deep learning""]",0.5144948057556248,1,3.0,2017, theory deep_learning
BkVf1AeAZ,Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks,3,"[""label embedding"", ""deep learning"", ""label representation"", ""computer vision"", ""natural language processing""]",0.46684016764108843,0,3.6666666666666665,2018, label_embedding deep_learning label_representation computer_vision natural_language_processing
BkVsEMYel,Inductive Bias of Deep Convolutional Networks through Pooling Geometry,3,"[""Theory"", ""Deep learning""]",0.5573838455228919,1,6.666666666666667,2017, theory deep_learning
BkVsWbbAW,Deep Generative Dual Memory Network for Continual Learning,3,"[""Continual Learning"", ""Catastrophic Forgetting"", ""Sequential Multitask Learning"", ""Deep Generative Models"", ""Dual Memory Networks"", ""Deep Learning""]",0.5416722613555113,0,6.0,2018, continual_learning catastrophic_forgetting sequential_multitask_learning deep_generative_models dual_memory_networks deep_learning
BkXMikqxx,Cortical-Inspired Open-Bigram Representation for Handwritten Word Recognition,4,[],0.6388296979171401,1,5.333333333333333,2017,
BkXmYfbAZ,Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering,3,"[""multitask learning"", ""deep learning"", ""modularity""]",0.48979616431070616,0,6.666666666666667,2018, multitask_learning deep_learning modularity
Bk_fs6gA-,Long Term Memory Network for Combinatorial Optimization Problems,3,"[""Memory Networks"", ""Combinatorial Optimization"", ""Binary LP""]",0.4776936524067405,0,3.6666666666666665,2018, memory_networks combinatorial_optimization binary_lp
Bk_zTU5eg,Inefficiency of stochastic gradient descent with larger mini-batches (and more learners),3,"[""Deep learning"", ""Optimization""]",0.5177873457443344,1,5.0,2017, deep_learning optimization
Bkab5dqxe,A Compositional Object-Based Approach to Learning Physical Dynamics,3,"[""Deep learning"", ""Unsupervised Learning""]",0.5287183878326849,1,7.333333333333333,2017, deep_learning unsupervised_learning
BkabRiQpb,Consequentialist conditional cooperation in social dilemmas with imperfect information,3,"[""deep reinforcement learning"", ""cooperation"", ""social dilemma"", ""multi-agent systems""]",0.4736987639670244,0,6.0,2018, deep_reinforcement_learning cooperation social_dilemma multi_agent_systems
BkbY4psgg,Making Neural Programming Architectures Generalize via Recursion,3,"[""Deep learning""]",0.5907698831604226,1,8.333333333333334,2017, deep_learning
Bkbc-Vqeg,Learning Word-Like Units from Joint Audio-Visual Analylsis,3,"[""Speech"", ""Computer vision"", ""Deep learning"", ""Multi-modal learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",0.5730492687138441,1,5.333333333333333,2017, speech computer_vision deep_learning multi_modal_learning unsupervised_learning semi_supervised_learning
BkdpaH9ll,Boosting Image Captioning with Attributes,3,"[""Computer vision"", ""Applications""]",0.573744481626137,1,5.0,2017, computer_vision applications
BkeC_J-R-,Combination of Supervised and Reinforcement Learning For Vision-Based Autonomous Control,3,"[""Reinforcement learning"", ""deep learning"", ""autonomous control""]",0.47046928348621125,0,4.0,2018, reinforcement_learning deep_learning autonomous_control
Bkepl7cee,Parametric Exponential Linear Unit for Deep Convolutional Neural Networks,3,[],0.49157040617334297,1,5.5,2017,
BkeqO7x0-,Unsupervised Cipher Cracking Using Discrete GANs,3,[],0.45152434359968885,0,7.333333333333333,2018,
BkfEzz-0-,Neuron as an Agent,2,"[""Multi-agent Reinforcement Learning"", ""Communication"", ""Reward Distribution"", ""Trusted Third Party"", ""Auction Theory""]",0.3431878435333297,0,5.333333333333333,2018, multi_agent_reinforcement_learning communication reward_distribution trusted_third_party auction_theory
BkfiXiUlg,Learning Efficient Algorithms with Hierarchical Attentive Memory,4,[],0.6020644972944682,1,4.333333333333333,2017,
Bkfwyw5xg,Investigating Different Context Types and Representations for Learning Word Embeddings,3,"[""Unsupervised Learning"", ""Natural language processing""]",0.48802720057798815,1,4.666666666666667,2017, unsupervised_learning natural_language_processing
Bki1Ct1AW,Baseline-corrected space-by-time non-negative matrix factorization for decoding single trial population spike trains,3,"[""Space-by-time non-negative matrix factorization"", ""dimensionality reduction"", ""baseline correction"", ""neuronal decoding"", ""mutual information""]",0.5607981045977369,0,5.333333333333333,2018, space_by_time_non_negative_matrix_factorization dimensionality_reduction baseline_correction neuronal_decoding mutual_information
Bki4EfWCb,Inference Suboptimality in Variational Autoencoders,3,"[""Approximate Inference"", ""Amortization"", ""Posterior Approximations"", ""Variational Autoencoder""]",0.4802874870678769,0,6.0,2018, approximate_inference amortization posterior_approximations variational_autoencoder
BkiIkBJ0b,Do Deep Reinforcement Learning Algorithms really Learn to Navigate?,2,"[""deep reinforcement learning"", ""navigation"", ""path-planning"", ""mapping""]",0.3816373917813505,0,4.333333333333333,2018, deep_reinforcement_learning navigation path_planning mapping
BkisuzWRW,Zero-Shot Visual Imitation,3,"[""imitation"", ""zero-shot"", ""self-supervised"", ""robotics"", ""skills"", ""navigation"", ""manipulation"", ""vizdoom"", ""reinforcement""]",0.45870026618114423,0,7.666666666666667,2018, imitation zero_shot self_supervised robotics skills navigation manipulation vizdoom reinforcement
BkjLkSqxg,LipNet: End-to-End Sentence-level Lipreading,3,"[""Computer vision"", ""Deep learning""]",0.597511549593596,1,4.666666666666667,2017, computer_vision deep_learning
Bkl1uWb0Z,Inducing Grammars with and for Neural Machine Translation,3,"[""structured attention"", ""neural machine translation"", ""grammar induction""]",0.4940248096757236,0,4.666666666666667,2018, structured_attention neural_machine_translation grammar_induction
BkmM8Dceg,Warped Convolutions: Efficient Invariance to Spatial Transformations,3,[],0.5305199188331278,1,6.333333333333333,2017,
BkoCeqgR-,On the Construction and Evaluation of Color Invariant Networks,3,"[""deep learning"", ""invariance"", ""data set"", ""evaluation""]",0.5787528609494063,0,3.3333333333333335,2018, deep_learning invariance data_set evaluation
BkoXnkWAb,Shifting Mean Activation Towards Zero with Bipolar Activation Functions,3,[],0.5407963080584736,0,4.666666666666667,2018,
BkpXqwUTZ,Iterative temporal differencing with fixed random feedback alignment support spike-time dependent plasticity in vanilla backpropagation for deep learning,3,"[""Iterative temporal differencing"", ""feedback alignment"", ""spike-time dependent plasticity"", ""vanilla backpropagation"", ""deep learning""]",0.523867528128058,0,2.3333333333333335,2018, iterative_temporal_differencing feedback_alignment spike_time_dependent_plasticity vanilla_backpropagation deep_learning
Bkp_y7qxe,Unsupervised Deep Learning of State Representation Using Robotic Priors ,4,"[""Deep learning"", ""Computer vision"", ""Unsupervised Learning""]",0.6053921608721824,1,3.0,2017, deep_learning computer_vision unsupervised_learning
BkpiPMbA-,Decision Boundary Analysis of Adversarial Examples,2,"[""adversarial machine learning"", ""supervised representation learning"", ""decision regions"", ""decision boundaries""]",0.37581314173095887,0,6.0,2018, adversarial_machine_learning supervised_representation_learning decision_regions decision_boundaries
BkrSv0lA-,Loss-aware Weight Quantization of Deep Networks,3,"[""deep learning"", ""network quantization""]",0.5148406694274332,0,6.666666666666667,2018, deep_learning network_quantization
BkrsAzWAb,Online Learning Rate Adaptation with Hypergradient Descent,3,[],0.558338190044947,0,6.666666666666667,2018,
Bks8cPcxe,DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning,3,"[""Deep learning"", ""Applications"", ""Optimization""]",0.5874760645242424,1,7.0,2017, deep_learning applications optimization
Bkul3t9ee,Unsupervised Perceptual Rewards for Imitation Learning,3,"[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Reinforcement Learning"", ""Transfer Learning""]",0.47056020552241007,1,5.333333333333333,2017, computer_vision deep_learning unsupervised_learning reinforcement_learning transfer_learning
BkwHObbRZ,Learning One-hidden-layer Neural Networks with Landscape Design,3,"[""theory"", ""non-convex optimization"", ""loss surface""]",0.5045742865327301,0,7.333333333333333,2018, theory non_convex_optimization loss_surface
By-7dz-AZ,A Framework for the Quantitative Evaluation of Disentangled Representations,3,[],0.44124344211209493,0,6.333333333333333,2018,
By-IifZRW,Gaussian Process Neurons,3,"[""gaussian process neuron activation function stochastic transfer function learning variational bayes probabilistic""]",0.5093118553018915,0,5.333333333333333,2018, gaussian_process_neuron_activation_function_stochastic_transfer_function_learning_variational_bayes_probabilistic
By0ANxbRW,DNN Model Compression Under Accuracy Constraints,3,"[""DNN Compression"", ""Weigh-sharing"", ""Model Compression""]",0.5070868672034405,0,3.3333333333333335,2018, dnn_compression weigh_sharing model_compression
By14kuqxx,Bit-Pragmatic Deep Neural Network Computing,3,"[""Deep learning"", ""Applications""]",0.5803521444440954,1,6.0,2017, deep_learning applications
By1snw5gl,L-SR1: A Second Order Optimization Method for Deep Learning,3,[],0.47390274117723413,1,4.333333333333333,2017,
By3VrbbAb,Realtime query completion via deep language models,3,"[""query completion"", ""realtime"", ""error correction"", ""recurrent network"", ""beam search""]",0.4660408779010504,0,5.0,2018, query_completion realtime error_correction recurrent_network beam_search
By3v9k-RZ,LEARNING TO ORGANIZE KNOWLEDGE WITH N-GRAM MACHINES,3,"[""neuro-symbolic reasoning"", ""information extraction"", ""learn to search""]",0.4992596416101653,0,4.333333333333333,2018, neuro_symbolic_reasoning information_extraction learn_to_search
By4HsfWAZ,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,3,"[""deep learning"", ""physical processes"", ""forecasting"", ""spatio-temporal""]",0.5126823112594014,0,6.666666666666667,2018, deep_learning physical_processes forecasting spatio_temporal
By5SY2gA-,Towards Building Affect sensitive Word Distributions,3,"[""Affect lexicon"", ""word embeddings"", ""Word2Vec"", ""GloVe"", ""WordNet"", ""joint learning"", ""sentiment analysis"", ""word similarity"", ""outlier detection"", ""affect prediction""]",0.5410057993539592,0,4.666666666666667,2018, affect_lexicon word_embeddings word2vec glove wordnet joint_learning sentiment_analysis word_similarity outlier_detection affect_prediction
By5e2L9gl,Trusting SVM for Piecewise Linear CNNs,3,[],0.4922467831841225,1,5.0,2017,
By5ugjyCb,PACT: Parameterized Clipping Activation for Quantized Neural Networks,3,"[""deep learning"", ""quantized deep neural network"", ""activation quantization""]",0.5187928075928843,0,5.0,2018, deep_learning quantized_deep_neural_network activation_quantization
By9iRkWA-,Phase Conductor on Multi-layered Attentions for Machine Comprehension,4,"[""Attention Model"", ""Machine Comprehension"", ""Question Answering""]",0.6108451277952834,0,6.0,2018, attention_model machine_comprehension question_answering
ByBAl2eAZ,Parameter Space Noise for Exploration,3,"[""reinforcement learning"", ""exploration"", ""parameter noise""]",0.40378066498100024,0,6.666666666666667,2018, reinforcement_learning exploration parameter_noise
ByBwSPcex,Song From PI: A Musically Plausible Network for Pop Music Generation,3,"[""Applications""]",0.5460449614377154,1,5.666666666666667,2017, applications
ByC7ww9le,Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering,3,"[""Natural language processing"", ""Supervised Learning"", ""Deep learning""]",0.49863526936395786,1,4.333333333333333,2017, natural_language_processing supervised_learning deep_learning
ByCPHrgCW,Deep Learning Inferences with Hybrid Homomorphic Encryption,3,"[""deep learning"", ""homomorphic encryption"", ""hybrid homomorphic encryption"", ""privacy preserving"", ""representation learning"", ""neural networks""]",0.4890453756931237,0,4.0,2018, deep_learning homomorphic_encryption hybrid_homomorphic_encryption privacy_preserving representation_learning neural_networks
ByED-X-0W,Parametric Information Bottleneck to Optimize Stochastic Neural Networks,3,"[""Information Bottleneck"", ""Deep Neural Networks""]",0.4723747228386097,0,4.666666666666667,2018, information_bottleneck deep_neural_networks
ByEPMj5el,Out-of-class novelty generation: an experimental foundation,3,"[""Deep learning"", ""Unsupervised Learning""]",0.42137452530792013,1,5.5,2017, deep_learning unsupervised_learning
ByG4hz5le,Adaptive Feature Abstraction for Translating Video to Language,3,"[""Computer vision"", ""Deep learning""]",0.5705529019683029,1,5.0,2017, computer_vision deep_learning
ByG8A7cee,Reference-Aware Language Models,3,"[""Natural language processing"", ""Deep learning""]",0.5827183084100234,1,5.333333333333333,2017, natural_language_processing deep_learning
ByIAPUcee,Frustratingly Short Attention Spans in Neural Language Modeling,3,"[""Natural language processing"", ""Deep learning""]",0.5445619470685732,1,7.0,2017, natural_language_processing deep_learning
ByJ7obb0b,Understanding and Exploiting the Low-Rank Structure of Deep Networks,3,"[""Deep Learning"", ""Derivative Calculations"", ""Optimization Algorithms""]",0.5388182334904008,0,3.6666666666666665,2018, deep_learning derivative_calculations optimization_algorithms
ByJDAIe0b,Integrating Episodic Memory into a Reinforcement Learning Agent Using Reservoir Sampling,3,"[""reinforcement learning"", ""external memory"", ""deep learning"", ""policy gradient"", ""online learning""]",0.531079780987452,0,4.0,2018, reinforcement_learning external_memory deep_learning policy_gradient online_learning
ByJHuTgA-,On the State of the Art of Evaluation in Neural Language Models,4,"[""rnn"", ""language modelling""]",0.6083946768575388,0,6.666666666666667,2018, rnn language_modelling
ByJIWUnpW,Automatically Inferring Data Quality for Spatiotemporal Forecasting,3,"[""spatiotemporal data"", ""graph convolutional network"", ""data quality""]",0.5120461596624156,0,6.666666666666667,2018, spatiotemporal_data graph_convolutional_network data_quality
ByJWeR1AW,Data augmentation instead of explicit regularization,3,"[""deep learning"", ""data augmentation"", ""regularization""]",0.4748297270496011,0,5.0,2018, deep_learning data_augmentation regularization
ByJbJwxCW,Relational Multi-Instance Learning for Concept Annotation from Medical Time Series,3,"[""Multi-instance learning"", ""Medical Time Series"", ""Concept Annotation""]",0.5227917443004159,0,4.0,2018, multi_instance_learning medical_time_series concept_annotation
ByKWUeWA-,GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets,2,"[""Individualized Treatment Effects"", ""Counterfactual Estimation"", ""Generative Adversarial Nets""]",0.38037191189571007,0,6.0,2018, individualized_treatment_effects counterfactual_estimation generative_adversarial_nets
ByL48G-AW,Simple Nearest Neighbor Policy Method for Continuous Control Tasks,3,"[""nearest neighbor"", ""reinforcement learning"", ""policy"", ""continuous control""]",0.4407086931138462,0,3.6666666666666665,2018, nearest_neighbor reinforcement_learning policy continuous_control
ByOExmWAb,MaskGAN: Better Text Generation via Filling in the _______,3,"[""Deep learning"", ""GAN""]",0.47959905778929307,0,7.0,2018, deep_learning gan
ByOK0rwlx,Ternary Weight Decomposition and Binary Activation Encoding for Fast and Compact Neural Network,3,"[""Deep learning""]",0.5325009481116831,1,5.0,2017, deep_learning
ByOfBggRZ,Detecting Statistical Interactions from Neural Network Weights,3,"[""statistical interaction detection"", ""multilayer perceptron"", ""generalized additive model""]",0.5086394420304573,0,7.0,2018, statistical_interaction_detection multilayer_perceptron generalized_additive_model
ByOnmlWC-,Policy Optimization by Genetic Distillation ,3,"[""Genetic algorithms"", ""deep reinforcement learning"", ""imitation learning""]",0.40614975906604256,0,5.666666666666667,2018, genetic_algorithms deep_reinforcement_learning imitation_learning
ByOvsIqeg,Regularizing CNNs with Locally Constrained Decorrelations,3,"[""Computer vision"", ""Deep learning"", ""Optimization""]",0.46190862514253517,1,7.0,2017, computer_vision deep_learning optimization
ByQPVFull,Training Group Orthogonal Neural Networks with Privileged Information,3,"[""Deep learning"", ""Computer vision"", ""Supervised Learning""]",0.4886779916555545,1,5.666666666666667,2017, deep_learning computer_vision supervised_learning
ByQZjx-0-,Faster Discovery of Neural Architectures by Searching for Paths in a Large Model,3,"[""neural architecture search""]",0.44756536368566446,0,5.333333333333333,2018, neural_architecture_search
ByQpn1ZA-,Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step,2,"[""Deep learning"", ""GAN""]",0.33318723326720406,0,6.333333333333333,2018, deep_learning gan
ByRWCqvT-,Learning to cluster in order to transfer across domains and tasks,3,"[""transfer learning"", ""similarity prediction"", ""clustering"", ""domain adaptation"", ""unsupervised learning"", ""computer vision"", ""deep learning"", ""constrained clustering""]",0.4493176146464388,0,7.0,2018, transfer_learning similarity_prediction clustering domain_adaptation unsupervised_learning computer_vision deep_learning constrained_clustering
ByS1VpgRZ,cGANs with Projection Discriminator,3,"[""Generative Adversarial Networks"", ""GANs"", ""conditional GANs"", ""Generative models"", ""Projection""]",0.4834078806002153,0,6.333333333333333,2018, generative_adversarial_networks gans conditional_gans generative_models projection
BySRH6CpW,Learning Discrete Weights Using the Local Reparameterization Trick,3,"[""deep learning"", ""discrete weight network""]",0.5271525330840953,0,6.333333333333333,2018, deep_learning discrete_weight_network
ByToKu9ll,Evaluation of Defensive Methods for DNNs against Multiple Adversarial Evasion Models,3,"[""Deep learning""]",0.4165379384503214,1,4.666666666666667,2017, deep_learning
ByUEelW0-,Modifying memories in a Recurrent Neural Network Unit,3,"[""LSTM"", ""RNN"", ""rotation matrix"", ""long-term memory"", ""natural language processing""]",0.5594339464709813,0,3.6666666666666665,2018, lstm rnn rotation_matrix long_term_memory natural_language_processing
ByW2Avqgg,Neural Causal Regularization under the Independence of Mechanisms Assumption,3,"[""Deep learning"", ""Applications""]",0.4527321820783124,1,5.0,2017, deep_learning applications
ByW5yxgA-,Multiscale Hidden Markov Models For Covariance Prediction,3,"[""multiscale models"", ""hidden Markov model"", ""covariance prediction""]",0.5031168492224437,0,5.666666666666667,2018, multiscale_models hidden_markov_model covariance_prediction
ByYPLJA6W,Distribution Regression Network,3,"[""distribution regression"", ""supervised learning"", ""regression analysis""]",0.4503555796076336,0,6.333333333333333,2018, distribution_regression supervised_learning regression_analysis
ByZmGjkA-,Understanding Grounded Language Learning Agents,3,"[""Language AI Learning Reinforcement Deep""]",0.5041715929956867,0,5.333333333333333,2018, language_ai_learning_reinforcement_deep
ByZvfijeg,Higher Order Recurrent Neural Networks,3,"[""Deep learning"", ""Natural language processing""]",0.5804364128983899,1,4.333333333333333,2017, deep_learning natural_language_processing
Bya8fGWAZ,Value Propagation Networks,3,"[""Learning to plan"", ""Reinforcement Learning"", ""Value Iteration"", ""Navigation"", ""Convnets""]",0.4690231858636599,0,5.666666666666667,2018, learning_to_plan reinforcement_learning value_iteration navigation convnets
ByaQIGg0-,AUTOMATED DESIGN USING NEURAL NETWORKS AND GRADIENT DESCENT,3,"[""Deep Learning"", ""Automated Design"", ""Gradient Descent""]",0.5313671694840695,0,5.333333333333333,2018, deep_learning automated_design gradient_descent
BybQ7zWCb,“Style” Transfer for Musical Audio Using Multiple Time-Frequency Representations,3,"[""Musical audio"", ""neural style transfer"", ""Time-Frequency"", ""Spectrogram""]",0.5648951638834269,0,5.666666666666667,2018, musical_audio neural_style_transfer time_frequency spectrogram
BybtVK9lg,Autoencoding Variational Inference For Topic Models,3,"[""Deep learning"", ""Unsupervised Learning"", ""Applications"", ""Optimization""]",0.48504485914486434,1,6.333333333333333,2017, deep_learning unsupervised_learning applications optimization
BycCx8qex,DRAGNN: A Transition-Based Framework for Dynamically Connected Neural Networks,3,"[""Natural language processing"", ""Deep learning"", ""Multi-modal learning"", ""Structured prediction""]",0.5545331309241774,1,6.0,2017, natural_language_processing deep_learning multi_modal_learning structured_prediction
Byd-EfWCb,Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks,3,"[""distributed representations"", ""sentence embedding"", ""representation learning"", ""unsupervised learning"", ""encoder-decoder"", ""RNN""]",0.47820634881889096,0,5.0,2018, distributed_representations sentence_embedding representation_learning unsupervised_learning encoder_decoder rnn
BydARw9ex,Capacity and Trainability in Recurrent Neural Networks,3,"[""Deep learning""]",0.5671056200309126,1,7.666666666666667,2017, deep_learning
BydLzGb0Z,Twin Networks: Matching the Future for Sequence Generation,3,"[""generative rnns"", ""long term dependencies"", ""speech recognition"", ""image captioning""]",0.5088265421041891,0,7.0,2018, generative_rnns long_term_dependencies speech_recognition image_captioning
BydjJte0-,Towards Reverse-Engineering Black-Box Neural Networks,3,"[""black box"", ""security"", ""privacy"", ""attack"", ""metamodel"", ""adversarial example"", ""reverse-engineering"", ""machine learning""]",0.438240287082852,0,6.333333333333333,2018, black_box security privacy attack metamodel adversarial_example reverse_engineering machine_learning
BydrOIcle,Unrolled Generative Adversarial Networks,3,"[""Deep learning"", ""Unsupervised Learning"", ""Optimization""]",0.42059698912882443,1,7.666666666666667,2017, deep_learning unsupervised_learning optimization
ByeqORgAW,Proximal Backpropagation,3,[],0.5344349214906231,0,6.0,2018,
BygpQlbA-,Towards Provable Control for Unknown Linear Dynamical Systems,3,"[""optimal control"", ""reinforcement learning""]",0.5005435628427545,0,5.333333333333333,2018, optimal_control reinforcement_learning
Bygq-H9eg,An Analysis of Deep Neural Network Models for Practical Applications,3,"[""Computer vision"", ""Deep learning"", ""Applications""]",0.5673986245418925,1,4.333333333333333,2017, computer_vision deep_learning applications
Byht0GbRZ,STRUCTURED ALIGNMENT NETWORKS,3,"[""structured attention"", ""sentence matching""]",0.5741075695631109,0,5.333333333333333,2018, structured_attention sentence_matching
ByhthReRb,A Neural Method for Goal-Oriented Dialog Systems to interact with Named Entities,3,"[""Named Entities"", ""Neural methods"", ""Goal oriented dialog""]",0.4802184052748474,0,4.333333333333333,2018, named_entities neural_methods goal_oriented_dialog
Byiy-Pqlx,Lie-Access Neural Turing Machines,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5110650118885368,1,6.75,2017, natural_language_processing deep_learning supervised_learning
Byj54-bAW,A Tensor Analysis on Dense Connectivity via Convolutional Arithmetic Circuits,3,"[""DenseNets"", ""Tensor Analysis"", ""Convolutional Arithmetic Circuits""]",0.4886423395529128,0,4.333333333333333,2018, densenets tensor_analysis convolutional_arithmetic_circuits
Byj72udxe,Pointer Sentinel Mixture Models,3,"[""Natural language processing"", ""Deep learning""]",0.5945855113979983,1,7.666666666666667,2017, natural_language_processing deep_learning
Byk-VI9eg,Generative Multi-Adversarial Networks,3,"[""Deep learning"", ""Unsupervised Learning"", ""Games""]",0.47183354873109556,1,6.666666666666667,2017, deep_learning unsupervised_learning games
Byk4My-RZ,Flexible Prior Distributions for Deep Generative Models,3,"[""Deep Generative Models"", ""GANs""]",0.45622470430239453,0,5.666666666666667,2018, deep_generative_models gans
BylSPv9gx,Exploring Sparsity in Recurrent Neural Networks,3,"[""Speech"", ""Deep learning"", ""Supervised Learning""]",0.5172470806986427,1,6.5,2017, speech deep_learning supervised_learning
ByldLrqlx,DeepCoder: Learning to Write Programs,3,"[""Deep learning"", ""Supervised Learning"", ""Applications"", ""Structured prediction""]",0.5876046895639938,1,6.333333333333333,2017, deep_learning supervised_learning applications structured_prediction
Bym0cU1CZ,Towards Interpretable Chit-chat: Open Domain Dialogue Generation with Dialogue Acts,3,"[""dialogue generation"", ""dialogue acts"", ""open domain conversation"", ""supervised learning"", ""reinforcement learning""]",0.4586111339448146,0,6.0,2018, dialogue_generation dialogue_acts open_domain_conversation supervised_learning reinforcement_learning
BymIbLKgl,Learning Invariant Representations Of Planar Curves ,3,"[""Computer vision"", ""Deep learning"", ""Supervised Learning"", ""Applications""]",0.5168678843412019,1,6.333333333333333,2017, computer_vision deep_learning supervised_learning applications
ByqFhGZCW,MACHINE VS MACHINE: MINIMAX-OPTIMAL DEFENSE AGAINST ADVERSARIAL EXAMPLES,3,[],0.44868052437929523,0,5.333333333333333,2018,
ByqiJIqxg,Online Bayesian Transfer Learning for Sequential Data Modeling,3,"[""Unsupervised Learning"", ""Transfer Learning"", ""Applications""]",0.4991003725615458,1,6.333333333333333,2017, unsupervised_learning transfer_learning applications
ByquB-WC-,Finding ReMO (Related Memory Object): A Simple neural architecture for Text based Reasoning,4,"[""Natural Language Processing"", ""Deep Learning"", ""Reasoning""]",0.6015893966183313,0,4.0,2018, natural_language_processing deep_learning reasoning
ByrZyglCb,Robustness of Classifiers to Universal Perturbations: A Geometric Perspective,3,"[""Universal perturbations"", ""robustness"", ""curvature""]",0.42811587619553343,0,6.0,2018, universal_perturbations robustness curvature
Bys4ob-Rb,Certified Defenses against Adversarial Examples ,3,"[""adversarial examples"", ""certificate of robustness"", ""convex relaxations""]",0.415065682900192,0,7.0,2018, adversarial_examples certificate_of_robustness convex_relaxations
BysZhEqee,Marginal Deep Architectures: Deep learning for Small and Middle Scale Applications,3,[],0.5245538455268459,1,3.6666666666666665,2017,
Bys_NzbC-,Achieving Strong Regularization for Deep Neural Networks,3,"[""deep learning"", ""regularization""]",0.44918630028447654,0,5.0,2018, deep_learning regularization
BysvGP5ee,Variational Lossy Autoencoder,3,"[""Deep learning"", ""Unsupervised Learning""]",0.5181679278096576,1,6.666666666666667,2017, deep_learning unsupervised_learning
Byt3oJ-0W,Learning Latent Permutations with Gumbel-Sinkhorn Networks,3,"[""Permutation"", ""Latent"", ""Sinkhorn"", ""Inference"", ""Optimal Transport"", ""Gumbel"", ""Softmax"", ""Sorting""]",0.4538169190969837,0,7.0,2018, permutation latent sinkhorn inference optimal_transport gumbel softmax sorting
ByuI-mW0W,Towards a Testable Notion of Generalization for Generative Adversarial Networks,3,"[""generative adversarial networks"", ""Wasserstein"", ""GAN"", ""generalization"", ""theory""]",0.4139315771473151,0,5.0,2018, generative_adversarial_networks wasserstein gan generalization theory
ByuP8yZRb,Censoring Representations with Multiple-Adversaries over Random Subspaces,3,"[""Adversarial Training"", ""Privacy Protection"", ""Random Subspace""]",0.4345633875636605,0,5.666666666666667,2018, adversarial_training privacy_protection random_subspace
ByvJuTigl,End-to-End Learnable Histogram Filters,3,"[""Deep learning"", ""Unsupervised Learning""]",0.5209270889316969,1,3.6666666666666665,2017, deep_learning unsupervised_learning
BywyFQlAW,Minimax Curriculum Learning: Machine Teaching with Desirable Difficulties and Scheduled Diversity,3,"[""machine teaching"", ""deep learning"", ""minimax"", ""curriculum learning"", ""submodular"", ""diversity""]",0.5062623406238561,0,5.666666666666667,2018, machine_teaching deep_learning minimax curriculum_learning submodular diversity
Byx5BTilg,Exploring the Application of Deep Learning for Supervised Learning Problems,3,"[""Deep learning"", ""Supervised Learning""]",0.5473237133635042,1,4.0,2017, deep_learning supervised_learning
ByxLBMZCb,Learning Deep Models: Critical Points and Local Openness,3,"[""Training Deep Models"", ""Non-convex Optimization"", ""Local and Global Equivalence"", ""Local Openness""]",0.4381465807276867,0,5.666666666666667,2018, training_deep_models non_convex_optimization local_and_global_equivalence local_openness
ByxpMd9lx,Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks,3,"[""Natural language processing"", ""Deep learning"", ""Transfer Learning""]",0.5633609946289379,1,6.666666666666667,2017, natural_language_processing deep_learning transfer_learning
ByzvHagA-,Disentangled activations in deep networks,3,"[""representation learning"", ""disentanglement"", ""regularization""]",0.5004647505657694,0,5.0,2018, representation_learning disentanglement regularization
H1-nGgWC-,Gaussian Process Behaviour in Wide Deep Neural Networks,3,"[""Gaussian Processes"", ""Bayesian Deep Learning"", ""Theory of Deep Neural Networks""]",0.457975204589595,0,6.0,2018, gaussian_processes bayesian_deep_learning theory_of_deep_neural_networks
H1-oTz-Cb,Parametrizing filters of a CNN with a GAN,3,"[""invariance"", ""cnn"", ""gan"", ""infogan"", ""transformation""]",0.46098807598960995,0,3.3333333333333335,2018, invariance cnn gan infogan transformation
H113pWZRb,Topology Adaptive Graph Convolutional  Networks,3,"[""graph convolutional neural networks"", ""graph-structured data"", ""semi-classification""]",0.5172520662060492,0,5.0,2018, graph_convolutional_neural_networks graph_structured_data semi_classification
H11lAfbCW,On Characterizing the Capacity of Neural Networks Using Algebraic Topology,3,"[""deep learning theory"", ""architecture selection"", ""algebraic topology""]",0.45947027115454914,0,3.6666666666666665,2018, deep_learning_theory architecture_selection algebraic_topology
H12GRgcxg,Training deep neural-networks using a noise adaptation layer,3,"[""Deep learning"", ""Optimization""]",0.4790206485577997,1,5.666666666666667,2017, deep_learning optimization
H135uzZ0-,Mixed Precision Training of Convolutional Neural Networks using Integer Operations,3,"[""deep learning training"", ""reduced precision"", ""imagenet"", ""dynamic fixed point""]",0.5374280761690969,0,6.666666666666667,2018, deep_learning_training reduced_precision imagenet dynamic_fixed_point
H139Q_gAW,Learning Graph Convolution Filters from Data Manifold,3,"[""Label Propagation"", ""Depthwise separable convolution"", ""Graph and geometric convolution""]",0.5047799071804451,0,5.0,2018, label_propagation depthwise_separable_convolution graph_and_geometric_convolution
H13F3Pqll,Inverse Problems in Computer Vision using  Adversarial  Imagination Priors,3,"[""Unsupervised Learning"", ""Deep learning""]",0.45800520464416755,1,4.666666666666667,2017, unsupervised_learning deep_learning
H13WofbAb,Faster Distributed Synchronous SGD with Weak Synchronization,3,"[""distributed"", ""deep learning"", ""straggler""]",0.47534439617235236,0,3.6666666666666665,2018, distributed deep_learning straggler
H15RufWAW,GraphGAN: Generating Graphs via Random Walks,3,"[""GAN"", ""graphs"", ""random walks"", ""implicit generative models""]",0.46703656467572485,0,5.666666666666667,2018, gan graphs random_walks implicit_generative_models
H15odZ-C-,Semantic Interpolation in Implicit Models,3,"[""Deep Generative Models"", ""GANs""]",0.4710605474325603,0,6.0,2018, deep_generative_models gans
H178hw9ex,Dynamic Steerable Frame Networks,3,"[""Computer vision"", ""Deep learning""]",0.5330632057939961,1,5.333333333333333,2017, computer_vision deep_learning
H18WqugAb,Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks,3,"[""sequence-to-sequence recurrent networks"", ""compositionality"", ""systematicity"", ""generalization"", ""language-driven navigation""]",0.5693349218646399,0,6.333333333333333,2018, sequence_to_sequence_recurrent_networks compositionality systematicity generalization language_driven_navigation
H18uzzWAZ,Correcting Nuisance Variation using Wasserstein Distance,3,"[""Nuisance variation"", ""transform learning"", ""image embeddings""]",0.4719316888751235,0,5.333333333333333,2018, nuisance_variation transform_learning image_embeddings
H196sainb,Word translation without parallel data,3,"[""unsupervised learning"", ""machine translation"", ""multilingual embeddings"", ""parallel dictionary induction"", ""adversarial training""]",0.5489759583362389,0,6.666666666666667,2018, unsupervised_learning machine_translation multilingual_embeddings parallel_dictionary_induction adversarial_training
H1A5ztj3b,Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates,3,"[""Deep Learning"", ""machine learning""]",0.48225268825742545,0,4.0,2018, deep_learning machine_learning
H1BHbmWCZ,TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING,3,"[""Deep Learning"", ""Robotics"", ""Artificial Intelligence"", ""Computer Vision""]",0.5230847894167237,0,2.3333333333333335,2018, deep_learning robotics artificial_intelligence computer_vision
H1BLjgZCb,Generating Natural Adversarial Examples,3,"[""adversarial examples"", ""generative adversarial networks"", ""interpretability"", ""image classification"", ""textual entailment"", ""machine translation""]",0.5068972272003596,0,6.333333333333333,2018, adversarial_examples generative_adversarial_networks interpretability image_classification textual_entailment machine_translation
H1BO9M-0Z,Lifelong Word Embedding via Meta-Learning,3,"[""Lifelong learning"", ""meta learning"", ""word embedding""]",0.4311965129854114,0,4.0,2018, lifelong_learning meta_learning word_embedding
H1DGha1CZ,Enhancing Batch Normalized Convolutional Networks using Displaced Rectifier Linear Units: A Systematic Comparative Study,3,"[""Batch Normalized"", ""Convolutional Neural Networks"", ""Displaced Rectifier Linear Unit"", ""Comparative Study""]",0.5006166156593354,0,4.0,2018, batch_normalized convolutional_neural_networks displaced_rectifier_linear_unit comparative_study
H1DJFybC-,Learning to Infer Graphics Programs from Hand-Drawn Images,3,"[""program induction"", ""HCI"", ""deep learning""]",0.5802024839404962,0,4.666666666666667,2018, program_induction hci deep_learning
H1DkN7ZCZ,Deep learning mutation prediction enables early stage lung cancer detection in liquid biopsy,3,"[""somatic mutation"", ""variant calling"", ""cancer"", ""liquid biopsy"", ""early detection"", ""convolution"", ""deep learning"", ""machine learning"", ""lung cancer"", ""error suppression"", ""mutect""]",0.4181305198111387,0,5.666666666666667,2018, somatic_mutation variant_calling cancer liquid_biopsy early_detection convolution deep_learning machine_learning lung_cancer error_suppression mutect
H1Dy---0Z,Distributed Prioritized Experience Replay,3,"[""deep learning"", ""reinforcement learning"", ""distributed systems""]",0.4735945930148068,0,7.333333333333333,2018, deep_learning reinforcement_learning distributed_systems
H1Fk2Iqex,Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech,3,"[""Applications"", ""Supervised Learning"", ""Deep learning"", ""Speech""]",0.5082430991886505,1,5.333333333333333,2017, applications supervised_learning deep_learning speech
H1GEvHcee,Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM,3,"[""Deep learning"", ""Unsupervised Learning""]",0.46720641180980055,1,5.333333333333333,2017, deep_learning unsupervised_learning
H1Go7Koex,Character-aware Attention Residual Network for Sentence Representation,3,"[""Deep learning""]",0.5173845552824599,1,4.0,2017, deep_learning
H1Gq5Q9el,Unsupervised Pretraining for Sequence to Sequence Learning,3,"[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning"", ""Transfer Learning""]",0.5414680032992523,1,6.0,2017, natural_language_processing deep_learning semi_supervised_learning transfer_learning
H1Heentlx,Deep Variational Canonical Correlation Analysis,3,[],0.4925751496494054,1,5.666666666666667,2017,
H1I3M7Z0b,WSNet: Learning Compact and Efficient Networks with Weight Sampling,3,"[""Deep learning"", ""model compression""]",0.4944491137673377,0,5.666666666666667,2018, deep_learning model_compression
H1K6Tb-AZ,TESLA: Task-wise Early Stopping and Loss Aggregation for Dynamic Neural Network Inference,3,[],0.4289037851634687,0,4.333333333333333,2018,
H1LAqMbRW,Latent forward model for Real-time Strategy game planning with incomplete information,3,"[""Real time strategy"", ""latent space"", ""forward model"", ""monte carlo tree search"", ""reinforcement learning"", ""planning""]",0.43208064595828405,0,4.333333333333333,2018, real_time_strategy latent_space forward_model monte_carlo_tree_search reinforcement_learning planning
H1MczcgR-,Understanding Short-Horizon Bias in Stochastic Meta-Optimization,3,"[""meta-learning; optimization; short-horizon bias.""]",0.4363077471713781,0,7.0,2018, meta_learning;_optimization;_short_horizon_bias.
H1MjAnqxg,Intelligible Language Modeling with Input Switched Affine Networks,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5458756393723525,1,6.333333333333333,2017, natural_language_processing deep_learning supervised_learning
H1Nyf7W0Z,Alpha-divergence bridges maximum likelihood and reinforcement learning in neural sequence generation,3,"[""neural network"", ""reinforcement learning"", ""natural language processing"", ""machine translation"", ""alpha-divergence""]",0.43385992577079874,0,4.0,2018, neural_network reinforcement_learning natural_language_processing machine_translation alpha_divergence
H1O0KGC6b,Post-training for Deep Learning,3,[],0.5074647276471552,0,4.0,2018,
H1OQukZ0-,Online Hyper-Parameter Optimization,3,"[""hyper-parameters"", ""optimization""]",0.48912911119601127,0,4.333333333333333,2018, hyper_parameters optimization
H1T2hmZAb,Deep Complex Networks,3,"[""deep learning"", ""complex-valued neural networks""]",0.5952351263090502,0,6.333333333333333,2018, deep_learning complex_valued_neural_networks
H1UOm4gA-,Interactive Grounded Language Acquisition and Generalization in a 2D World,3,"[""grounded language learning and generalization"", ""zero-shot language learning""]",0.5328206115857022,0,6.333333333333333,2018, grounded_language_learning_and_generalization zero_shot_language_learning
H1U_af-0-,Quadrature-based features for kernel approximation,3,"[""kernel methods"", ""low-rank approximation"", ""quadrature rules"", ""random features""]",0.5318056753302057,0,5.666666666666667,2018, kernel_methods low_rank_approximation quadrature_rules random_features
H1VGkIxRZ,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,3,"[""Neural networks"", ""out-of-distribution detection""]",0.49869431734223174,0,7.0,2018, neural_networks out_of_distribution_detection
H1VjBebR-,The Role of Minimal Complexity Functions in Unsupervised Learning of Semantic Mappings,3,"[""Unsupervised learning"", ""cross-domain mapping"", ""Kolmogorov complexity"", ""Occam's razor""]",0.5146347553049715,0,6.666666666666667,2018, unsupervised_learning cross_domain_mapping kolmogorov_complexity occam's_razor
H1VyHY9gg,Data Noising as Smoothing in Neural Network Language Models,3,"[""Natural language processing"", ""Deep learning""]",0.5290792247250153,1,6.666666666666667,2017, natural_language_processing deep_learning
H1W1UN9gg,Deep Information Propagation,3,"[""Theory"", ""Deep learning""]",0.43541387677686244,1,8.333333333333334,2017, theory deep_learning
H1WgVz-AZ,Learning Approximate Inference Networks for Structured Prediction,3,"[""Approximate Inference Networks"", ""Structured Prediction"", ""Multi-Label Classification"", ""Sequence Labeling""]",0.5074954984502834,0,7.0,2018, approximate_inference_networks structured_prediction multi_label_classification sequence_labeling
H1Ww66x0-,Lifelong Learning with Output Kernels,3,"[""multitask learning"", ""lifelong learning"", ""online learning""]",0.4238837510233381,0,3.0,2018, multitask_learning lifelong_learning online_learning
H1Xw62kRZ,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,3,"[""Program Synthesis"", ""Reinforcement Learning"", ""Language Model""]",0.49578443779147197,0,6.0,2018, program_synthesis reinforcement_learning language_model
H1Y8hhg0b,Learning Sparse Neural Networks through L_0 Regularization,3,"[""Sparsity"", ""compression"", ""hard and soft attention.""]",0.47564626149619454,0,6.333333333333333,2018, sparsity compression hard_and_soft_attention.
H1Yp-j1Cb,An Online Learning Approach to Generative Adversarial Networks,2,"[""Generative Adversarial Networks"", ""GANs"", ""online learning""]",0.3838154611034192,0,6.666666666666667,2018, generative_adversarial_networks gans online_learning
H1YynweCb,Kronecker Recurrent Units,3,"[""Recurrent neural network"", ""Vanishing and exploding gradients"", ""Parameter efficiency"", ""Kronecker matrices"", ""Soft unitary constraint""]",0.5392773065663433,0,6.0,2018, recurrent_neural_network vanishing_and_exploding_gradients parameter_efficiency kronecker_matrices soft_unitary_constraint
H1_EDpogx,Near-Data Processing for Machine Learning,3,[],0.4834169320438278,1,5.0,2017,
H1_QSDqxl,Rule Mining in Feature Space,3,"[""Unsupervised Learning""]",0.5135398365383057,1,3.6666666666666665,2017, unsupervised_learning
H1a37GWCZ,UNSUPERVISED SENTENCE EMBEDDING USING DOCUMENT STRUCTURE-BASED CONTEXT,3,"[""distributed representation"", ""sentence embedding"", ""structure"", ""technical documents"", ""sentence embedding"", ""out-of-vocabulary""]",0.5419756164366248,0,5.666666666666667,2018, distributed_representation sentence_embedding structure technical_documents sentence_embedding out_of_vocabulary
H1aIuk-RW,Active Learning for Convolutional Neural Networks: A Core-Set Approach,3,"[""Active Learning"", ""Convolutional Neural Networks"", ""Core-Set Selection""]",0.46887926640749233,0,7.0,2018, active_learning convolutional_neural_networks core_set_selection
H1acq85gx,Maximum Entropy Flow Networks,3,[],0.4900229174275216,1,7.0,2017,
H1bM1fZCW,GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks,3,"[""Multitask learning"", ""computer vision"", ""multitask loss function""]",0.4917477480864824,0,4.666666666666667,2018, multitask_learning computer_vision multitask_loss_function
H1bhRHeA-,Unbiased scalable softmax optimization,3,"[""softmax"", ""optimization"", ""implicit sgd""]",0.5142607784688031,0,5.0,2018, softmax optimization implicit_sgd
H1cKvl-Rb,UCB EXPLORATION VIA Q-ENSEMBLES,3,"[""Reinforcement learning"", ""Q-learning"", ""ensemble method"", ""upper confidence bound""]",0.4350254567019378,0,6.0,2018, reinforcement_learning q_learning ensemble_method upper_confidence_bound
H1cWzoxA-,Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling,3,"[""deep learning"", ""attention mechanism"", ""sequence modeling"", ""natural language processing"", ""sentence embedding""]",0.5080882024015155,0,7.0,2018, deep_learning attention_mechanism sequence_modeling natural_language_processing sentence_embedding
H1dh6Ax0Z,TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning,3,"[""reinforcement learning"", ""deep learning"", ""planning""]",0.43187088594976375,0,5.666666666666667,2018, reinforcement_learning deep_learning planning
H1eLE8qlx,Options Discovery with Budgeted Reinforcement Learning,3,"[""Reinforcement Learning""]",0.4406888155822865,1,4.5,2017, reinforcement_learning
H1fl8S9ee,Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks,3,"[""Deep learning"", ""Reinforcement Learning""]",0.49520057762181546,1,6.666666666666667,2017, deep_learning reinforcement_learning
H1hoFU9xe,Generative Adversarial Networks for Image Steganography,3,"[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Applications"", ""Supervised Learning""]",0.41295345050592935,1,5.0,2017, computer_vision deep_learning unsupervised_learning applications supervised_learning
H1kG7GZAW,Variational Inference of Disentangled Latent Concepts from Unlabeled Observations,3,"[""disentangled representations"", ""variational inference""]",0.4667183209195617,0,6.666666666666667,2018, disentangled_representations variational_inference
H1kMMmb0-,Sequential Coordination of Deep Models for Learning Visual Arithmetic,3,"[""reinforcement learning"", ""pretrained"", ""deep learning"", ""perception"", ""algorithmic""]",0.5354712430834738,0,3.0,2018, reinforcement_learning pretrained deep_learning perception algorithmic
H1kjdOYlx,Modular Multitask Reinforcement Learning with Policy Sketches,3,"[""Reinforcement Learning"", ""Transfer Learning""]",0.4687510371122916,1,4.0,2017, reinforcement_learning transfer_learning
H1l8sz-AW,Improving generalization by regularizing in $L^2$ function space,3,"[""natural gradient"", ""generalization"", ""optimization"", ""function space"", ""Hilbert""]",0.4843282965703346,0,5.0,2018, natural_gradient generalization optimization function_space hilbert
H1mCp-ZRZ,Action-dependent Control Variates for Policy Optimization via Stein Identity,2,"[""reinforcement learning"", ""control variates"", ""sample efficiency"", ""variance reduction""]",0.3459489568928966,0,7.0,2018, reinforcement_learning control_variates sample_efficiency variance_reduction
H1meywxRW,DCN+: Mixed Objective And Deep Residual Coattention for Question Answering,3,"[""question answering"", ""deep learning"", ""natural language processing"", ""reinforcement learning""]",0.49760788612112494,0,7.0,2018, question_answering deep_learning natural_language_processing reinforcement_learning
H1oRQDqlg,Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning,3,"[""Unsupervised Learning""]",0.41207529861408554,1,4.0,2017, unsupervised_learning
H1oyRlYgg,On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,3,"[""Deep learning"", ""Optimization""]",0.48185049178895184,1,8.0,2017, deep_learning optimization
H1pri9vTZ,Deep Function Machines: Generalized Neural Networks for Topological Layer Expression,3,"[""deep learning theory"", ""infinite neural networks"", ""topology""]",0.5449628263080898,0,4.666666666666667,2018, deep_learning_theory infinite_neural_networks topology
H1q-TM-AW,A DIRT-T Approach to Unsupervised Domain Adaptation,3,"[""domain adaptation"", ""unsupervised learning"", ""semi-supervised learning""]",0.43427025318860385,0,7.333333333333333,2018, domain_adaptation unsupervised_learning semi_supervised_learning
H1rRWl-Cb,An information-theoretic analysis of deep latent-variable models,3,"[""information theory"", ""generative models"", ""latent variable models"", ""variational autoencoders""]",0.4559198304769089,0,5.666666666666667,2018, information_theory generative_models latent_variable_models variational_autoencoders
H1sUHgb0Z,Learning From Noisy Singly-labeled Data,3,"[""crowdsourcing"", ""noisy annotations"", ""deep leaerning""]",0.4954426652959915,0,6.666666666666667,2018, crowdsourcing noisy_annotations deep_leaerning
H1srNebAZ,Discovering the mechanics of hidden neurons,3,"[""deep learning"", ""experimental analysis"", ""hidden neurons""]",0.5340519594592764,0,5.333333333333333,2018, deep_learning experimental_analysis hidden_neurons
H1tSsb-AW,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines,2,"[""reinforcement learning"", ""policy gradient"", ""variance reduction"", ""baseline"", ""control variates""]",0.3958921272623448,0,7.0,2018, reinforcement_learning policy_gradient variance_reduction baseline control_variates
H1u8fMW0b,Toward predictive machine learning for active vision,3,"[""active inference"", ""predictive coding"", ""motor control""]",0.5723810750026402,0,3.6666666666666665,2018, active_inference predictive_coding motor_control
H1uP7ebAW,Learning to diagnose from scratch by exploiting dependencies among labels,3,"[""medical diagnosis"", ""medical imaging"", ""multi-label classification""]",0.5491386680493663,0,6.0,2018, medical_diagnosis medical_imaging multi_label_classification
H1uR4GZRZ,Stochastic Activation Pruning for Robust Adversarial Defense,3,[],0.41904433210089614,0,6.333333333333333,2018,
H1vCXOe0b,Interpreting Deep Classification Models With Bayesian Inference,3,[],0.5011739040534966,0,3.6666666666666665,2018,
H1vEXaxA-,Emergent Translation in Multi-Agent Communication,3,[],0.4528340998062035,0,6.666666666666667,2018,
H1wgawqxl,Nonparametrically Learning Activation Functions in Deep Neural Nets,3,[],0.4888130139024287,1,6.0,2017,
H1wt9x-RW,Interpretable and Pedagogical Examples,3,"[""machine teaching"", ""interpretability"", ""communication"", ""cognitive science""]",0.5707681204093009,0,6.666666666666667,2018, machine_teaching interpretability communication cognitive_science
H1xJjlbAZ,INTERPRETATION OF NEURAL NETWORK IS FRAGILE,3,"[""Adversarial Attack"", ""Interpretability"", ""Saliency Map"", ""Influence Function"", ""Robustness"", ""Machine Learning"", ""Deep Learning"", ""Neural Network""]",0.492179604355453,0,5.0,2018, adversarial_attack interpretability saliency_map influence_function robustness machine_learning deep_learning neural_network
H1zJ-v5xl,Quasi-Recurrent Neural Networks,3,"[""Natural language processing"", ""Deep learning""]",0.5832189500634991,1,6.666666666666667,2017, natural_language_processing deep_learning
H1zriGeCZ,Hyperparameter optimization: a spectral approach,3,"[""Hyperparameter Optimization"", ""Fourier Analysis"", ""Decision Tree"", ""Compressed Sensing""]",0.5187376832260279,0,7.0,2018, hyperparameter_optimization fourier_analysis decision_tree compressed_sensing
HJ0NvFzxl,Learning Graphical State Transitions,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning"", ""Structured prediction""]",0.4885174193866751,1,8.333333333333334,2017, natural_language_processing deep_learning supervised_learning structured_prediction
HJ0UKP9ge,Bidirectional Attention Flow for Machine Comprehension,3,"[""Natural language processing"", ""Deep learning""]",0.55408526432341,1,7.666666666666667,2017, natural_language_processing deep_learning
HJ1HFlZAb,Evaluation of generative networks through their data augmentation capacity,3,"[""Generative models"", ""Evaluation of generative models"", ""Data Augmentation""]",0.4422493436102295,0,3.6666666666666665,2018, generative_models evaluation_of_generative_models data_augmentation
HJ1JBJ5gl,Representing inferential uncertainty in deep neural networks through sampling,3,"[""Deep learning"", ""Theory"", ""Applications""]",0.44533332923555063,1,4.333333333333333,2017, deep_learning theory applications
HJ1kmv9xx,LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation,3,"[""Computer vision"", ""Deep learning"", ""Unsupervised Learning""]",0.4754146618380591,1,6.333333333333333,2017, computer_vision deep_learning unsupervised_learning
HJ39YKiTb,Associative Conversation Model: Generating Visual Information from Textual Information,3,"[""conversation model"", ""multimodal embedding"", ""attention mechanism"", ""natural language processing"", ""encoder-decoder model""]",0.4966257068984139,0,3.3333333333333335,2018, conversation_model multimodal_embedding attention_mechanism natural_language_processing encoder_decoder_model
HJ3d2Ax0-,Benefits of Depth for Long-Term Memory of Recurrent Networks,3,"[""recurrent neural networks"", ""deep networks"", ""correlations"", ""long term memory"", ""tensor networks"", ""tensor analysis""]",0.5505261487993248,0,6.0,2018, recurrent_neural_networks deep_networks correlations long_term_memory tensor_networks tensor_analysis
HJ4IhxZAb,Meta-Learning Transferable Active Learning Policies by Deep Reinforcement Learning,3,"[""Active Learning"", ""Deep Reinforcement Learning""]",0.4592087124740023,0,6.333333333333333,2018, active_learning deep_reinforcement_learning
HJ5AUm-CZ,The Variational Homoencoder: Learning to Infer High-Capacity Generative Models from Few Examples,3,"[""generative models"", ""one-shot learning"", ""metalearning"", ""pixelcnn"", ""hierarchical bayesian"", ""omniglot""]",0.5012378090277516,0,6.0,2018, generative_models one_shot_learning metalearning pixelcnn hierarchical_bayesian omniglot
HJ5PIaseg,Towards an automatic Turing test: Learning to evaluate dialogue responses,3,"[""Natural language processing"", ""Applications""]",0.46254090529885095,1,5.333333333333333,2017, natural_language_processing applications
HJ6idTdgg,Pedestrian Detection Based On Fast R-CNN and Batch Normalization ,3,[],0.4865049453927039,1,2.75,2017,
HJ7O61Yxe,Modelling Relational Time Series using Gaussian Embeddings,3,"[""Applications"", ""Deep learning""]",0.5047484130618088,1,4.0,2017, applications deep_learning
HJ8W1Q-0Z,GATED FAST WEIGHTS FOR ASSOCIATIVE RETRIEVAL,3,"[""fast weights"", ""RNN"", ""associative retrieval"", ""time-varying variables""]",0.529340238162208,0,4.0,2018, fast_weights rnn associative_retrieval time_varying_variables
HJ94fqApW,Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers,3,"[""model pruning"", ""batch normalization"", ""convolutional neural network"", ""ISTA""]",0.4420767786318403,0,6.0,2018, model_pruning batch_normalization convolutional_neural_network ista
HJ9rLLcxg,Dataset Augmentation in Feature Space,3,"[""Unsupervised Learning""]",0.5362812288295571,1,5.666666666666667,2017, unsupervised_learning
HJBhEMbRb,A Spectral Approach to Generalization and Optimization in Neural Networks,3,"[""Generalization"", ""Neural Networks"", ""Fourier Analysis""]",0.4576668106967251,0,5.333333333333333,2018, generalization neural_networks fourier_analysis
HJC2SzZCW,Sensitivity and Generalization in Neural Networks: an Empirical Study,3,"[""generalization"", ""complexity"", ""experimental study"", ""linear regions"", ""Jacobian""]",0.4939591994065892,0,5.666666666666667,2018, generalization complexity experimental_study linear_regions jacobian
HJCXZQbAZ,Hierarchical Density Order Embeddings,3,"[""embeddings"", ""word embeddings"", ""probabilistic embeddings"", ""hierarchical representation"", ""probabilistic representation"", ""order embeddings"", ""wordnet"", ""hyperlex""]",0.4908494516464056,0,6.0,2018, embeddings word_embeddings probabilistic_embeddings hierarchical_representation probabilistic_representation order_embeddings wordnet hyperlex
HJDBUF5le,Towards a Neural Statistician,3,[],0.5100930197851996,1,7.333333333333333,2017,
HJDUjKeA-,Learning objects from pixels,3,"[""objects"", ""unsupervised"", ""reinforcement learning"", ""atari""]",0.5146560207669836,0,3.6666666666666665,2018, objects unsupervised reinforcement_learning atari
HJDV5YxCW,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks,3,"[""Deep Learning"", ""Computer Vision"", ""Approximation""]",0.5626331614779664,0,5.0,2018, deep_learning computer_vision approximation
HJDdiT9gl,Generating Long and Diverse Responses with Neural Conversation Models,3,"[""Natural language processing"", ""Deep learning""]",0.5634556767851304,1,6.333333333333333,2017, natural_language_processing deep_learning
HJF3iD9xe,Deep Learning with Sets and Point Clouds,3,"[""Deep learning"", ""Structured prediction"", ""Computer vision"", ""Supervised Learning"", ""Semi-Supervised Learning""]",0.5045061890019276,1,5.666666666666667,2017, deep_learning structured_prediction computer_vision supervised_learning semi_supervised_learning
HJGODLqgx,Recurrent Hidden Semi-Markov Model,3,"[""Deep learning"", ""Unsupervised Learning"", ""Structured prediction""]",0.45828174724367854,1,7.0,2017, deep_learning unsupervised_learning structured_prediction
HJGXzmspb,Training and Inference with Integers in Deep Neural Networks,3,"[""quantization"", ""training"", ""bitwidth"", ""ternary weights""]",0.521416958405041,0,7.333333333333333,2018, quantization training bitwidth ternary_weights
HJGv1Z-AW,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input,3,"[""disentanglement"", ""communication"", ""emergent language"", ""compositionality"", ""multi-agent""]",0.4826757499609466,0,7.0,2018, disentanglement communication emergent_language compositionality multi_agent
HJGwcKclx,Soft Weight-Sharing for Neural Network Compression,3,"[""Deep learning"", ""Optimization""]",0.48752059943030396,1,7.0,2017, deep_learning optimization
HJIY0E9ge,A Simple yet Effective Method to Prune Dense Layers of Neural Networks,3,"[""Deep learning""]",0.4408213744973368,1,4.333333333333333,2017, deep_learning
HJIhGXWCZ,Prediction Under Uncertainty with Error Encoding Networks,3,[],0.5603927427050626,0,4.666666666666667,2018,
HJIoJWZCZ,Adversarial Dropout Regularization,3,"[""domain adaptation"", ""computer vision"", ""generative models""]",0.4053454758453885,0,6.666666666666667,2018, domain_adaptation computer_vision generative_models
HJJ0w--0W,Long-term Forecasting using Tensor-Train RNNs,3,"[""RNNs"", ""time series forecasting"", ""nonlinear dynamics"", ""tensor-train""]",0.4918466896694188,0,5.0,2018, rnns time_series_forecasting nonlinear_dynamics tensor_train
HJJ23bW0b,Initialization matters: Orthogonal Predictive State Recurrent Neural Networks,3,"[""recurrent neural networks"", ""orthogonal random features"", ""predictive state representations""]",0.5348797368051349,0,6.333333333333333,2018, recurrent_neural_networks orthogonal_random_features predictive_state_representations
HJKkY35le,Mode Regularized Generative Adversarial Networks,2,"[""Deep learning"", ""Unsupervised Learning""]",0.3358196586324353,1,6.0,2017, deep_learning unsupervised_learning
HJMN-xWC-,Learning Parsimonious Deep Feed-forward Networks,3,"[""Parsimonious Deep Feed-forward Networks"", ""structure learning"", ""classification"", ""overfitting"", ""fewer parameters"", ""high interpretability""]",0.49812105967978415,0,4.666666666666667,2018, parsimonious_deep_feed_forward_networks structure_learning classification overfitting fewer_parameters high_interpretability
HJNGGmZ0Z,What is image captioning made of?,3,"[""image captioning"", ""representation learning"", ""interpretability"", ""rnn"", ""multimodal"", ""vision to language""]",0.5522922772452293,0,4.0,2018, image_captioning representation_learning interpretability rnn multimodal vision_to_language
HJNMYceCW,Residual Loss Prediction: Reinforcement Learning With No Incremental Feedback,3,"[""Reinforcement Learning"", ""Structured Prediction"", ""Contextual Bandits"", ""Learning Reduction""]",0.4117216260944426,0,6.666666666666667,2018, reinforcement_learning structured_prediction contextual_bandits learning_reduction
HJOQ7MgAW,Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum,3,[],0.554734932582606,0,6.0,2018,
HJOZBvcel,Learning to Discover Sparse Graphical Models,3,[],0.45503915402825845,1,6.0,2017,
HJPSN3gRW,Learning to navigate by distilling visual information and natural language instructions,3,"[""Deep reinforcement learning"", ""Computer Vision"", ""Multi-modal fusion"", ""Language Grounding""]",0.5215297982258934,0,4.333333333333333,2018, deep_reinforcement_learning computer_vision multi_modal_fusion language_grounding
HJPmdP9le,Efficient Summarization with Read-Again and Copy Mechanism,3,[],0.5081460028325732,1,5.333333333333333,2017,
HJRV1ZZAW,FAST READING COMPREHENSION WITH CONVNETS,4,"[""reading comprehension"", ""question answering"", ""CNN"", ""ConvNet"", ""Inference""]",0.6180157019062119,0,5.333333333333333,2018, reading_comprehension question_answering cnn convnet inference
HJSA_e1AW,Normalized Direction-preserving Adam,3,"[""optimization"", ""generalization"", ""Adam"", ""SGD""]",0.46844360081173536,0,4.666666666666667,2018, optimization generalization adam sgd
HJSCGD9ex,Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context,3,"[""Natural language processing""]",0.5284208008451142,1,4.333333333333333,2017, natural_language_processing
HJStZKqel,Lifelong Perceptual Programming By Example,3,"[""Deep learning"", ""Supervised Learning""]",0.5282490761029066,1,4.666666666666667,2017, deep_learning supervised_learning
HJTXaw9gx,Recursive Regression with Neural Networks: Approximating the HJI PDE Solution,3,"[""Supervised Learning"", ""Games"", ""Theory""]",0.5219786679445592,1,5.0,2017, supervised_learning games theory
HJTzHtqee,A Compare-Aggregate Model for Matching Text Sequences,3,"[""Natural language processing"", ""Deep learning""]",0.5469777983311186,1,7.0,2017, natural_language_processing deep_learning
HJUOHGWRb,Contextual Explanation Networks,3,"[""interpretability"", ""regularization"", ""deep learning"", ""graphical models"", ""model diagnostics"", ""survival analysis""]",0.5322928716398161,0,6.0,2018, interpretability regularization deep_learning graphical_models model_diagnostics survival_analysis
HJV1zP5xg,Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models,3,"[""Deep learning"", ""Computer vision"", ""Natural language processing""]",0.5182637310989848,1,5.333333333333333,2017, deep_learning computer_vision natural_language_processing
HJWGdbbCW,Reinforcement and Imitation Learning for Diverse Visuomotor Skills,3,"[""reinforcement learning"", ""imitation learning"", ""robotics"", ""visuomotor skills""]",0.45267754293011997,0,4.666666666666667,2018, reinforcement_learning imitation_learning robotics visuomotor_skills
HJWHIKqgl,Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,3,"[""Unsupervised Learning""]",0.432337568421307,1,7.0,2017, unsupervised_learning
HJWLfGWRb,Matrix capsules with EM routing,3,"[""Computer Vision"", ""Deep Learning"", ""Dynamic routing""]",0.48494708450762647,0,5.666666666666667,2018, computer_vision deep_learning dynamic_routing
HJWzXsKxx,Training Long Short-Term Memory With Sparsified Stochastic Gradient Descent,3,"[""Optimization"", ""Deep learning""]",0.46677467887474927,1,4.333333333333333,2017, optimization deep_learning
HJXOfZ-AZ,When and where do feed-forward neural networks learn localist representations?,3,"[""localist"", ""pdp"", ""neural network"", ""representation"", ""psychology"", ""cognition""]",0.4914725702378453,0,3.6666666666666665,2018, localist pdp neural_network representation psychology cognition
HJXyS7bRb,A Goal-oriented Neural Conversation Model by Self-Play,3,"[""conversation model"", ""seq2seq"", ""self-play"", ""reinforcement learning""]",0.5181996294279846,0,4.333333333333333,2018, conversation_model seq2seq self_play reinforcement_learning
HJYQLb-RW,On the limitations of first order approximation in GAN dynamics,2,"[""GANs"", ""first order dynamics"", ""convergence"", ""mode collapse""]",0.37414673271047616,0,5.333333333333333,2018, gans first_order_dynamics convergence mode_collapse
HJYoqzbC-,A comparison of second-order methods for deep convolutional neural networks,3,[],0.47030038498878557,0,4.666666666666667,2018,
HJZiRkZC-,Byte-Level Recursive Convolutional Auto-Encoder for Text,3,[],0.5768727946381557,0,5.666666666666667,2018,
HJ_X8GupW,Multi-label Learning for Large Text Corpora using Latent Variable Model with Provable Gurantees,3,"[""Spectral Method"", ""Multi-label Learning"", ""Tensor Factorisation""]",0.4570965330643444,0,3.6666666666666665,2018, spectral_method multi_label_learning tensor_factorisation
HJ_aoCyRZ,SpectralNet: Spectral Clustering using Deep Neural Networks,3,"[""unsupervised learning"", ""spectral clustering"", ""siamese networks""]",0.4711864199545896,0,5.666666666666667,2018, unsupervised_learning spectral_clustering siamese_networks
HJaDJZ-0W,Block-Sparse Recurrent Neural Networks,3,"[""Pruning"", ""block sparsity"", ""structured sparsity"", ""Recurrent Neural Networks"", ""Speech Recognition""]",0.576565469203667,0,5.666666666666667,2018, pruning block_sparsity structured_sparsity recurrent_neural_networks speech_recognition
HJcLcw9xg,The Preimage of Rectifier Network Activities,3,[],0.4790261818746724,1,4.0,2017,
HJcSzz-CZ,Meta-Learning for Semi-Supervised Few-Shot Classification,3,"[""Few-shot learning"", ""semi-supervised learning"", ""meta-learning""]",0.4592056921729415,0,6.0,2018, few_shot_learning semi_supervised_learning meta_learning
HJcjQTJ0W,PrivyNet: A Flexible Framework for Privacy-Preserving Deep Neural Network Training,3,"[""Privacy-preserving deep learning"", ""Neural network training""]",0.43340614877388745,0,4.666666666666667,2018, privacy_preserving_deep_learning neural_network_training
HJdXGy1RW,CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble Behavior,3,"[""CNN"", ""ensemble"", ""image recognition""]",0.4607201420268923,0,4.333333333333333,2018, cnn ensemble image_recognition
HJeqWztlg,Hierarchical compositional feature learning,3,"[""Unsupervised Learning""]",0.5910856535566456,1,4.666666666666667,2017, unsupervised_learning
HJewuJWCZ,Learning to Teach,3,[],0.5001974139840959,0,7.333333333333333,2018,
HJg1NTGZRZ,Bit-Regularized Optimization of Neural Nets,3,[],0.5178545454382013,0,3.6666666666666665,2018,
HJgXCV9xx,Dialogue Learning With Human-in-the-Loop,3,"[""Natural language processing""]",0.48705191204512355,1,6.0,2017, natural_language_processing
HJhIM0xAW,Learning a neural response metric for retinal prosthesis,3,"[""Metric learning"", ""Computational Neuroscience"", ""Retina"", ""Neural Prosthesis""]",0.5319639234315046,0,6.0,2018, metric_learning computational_neuroscience retina neural_prosthesis
HJhcg6Fxg,Binary Paragraph Vectors,3,"[""Natural language processing"", ""Transfer Learning""]",0.49643498926281915,1,5.666666666666667,2017, natural_language_processing transfer_learning
HJjePwx0-,Better Generalization by Efficient Trust Region Method,3,[],0.42859991186750995,0,5.666666666666667,2018,
HJjiFK5gx,Neural Program Lattices,3,"[""Deep learning"", ""Semi-Supervised Learning""]",0.5604612591902081,1,6.0,2017, deep_learning semi_supervised_learning
HJjvxl-Cb,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,3,"[""deep reinforcement learning"", ""maximum entropy learning"", ""stochastic actor-critic""]",0.4228493608207506,0,5.0,2018, deep_reinforcement_learning maximum_entropy_learning stochastic_actor_critic
HJlgm-B9lx,Learning to Understand: Incorporating Local Contexts with Global Attention for Sentiment Classification,3,"[""Natural language processing"", ""Deep learning"", ""Applications""]",0.5921052562302184,1,3.3333333333333335,2017, natural_language_processing deep_learning applications
HJnQJXbC-,AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks,3,"[""asynchronous"", ""neural network"", ""deep learning"", ""graph"", ""tree"", ""rnn""]",0.499875641628315,0,5.333333333333333,2018, asynchronous neural_network deep_learning graph tree rnn
HJpfMIFll,Geometry of Polysemy,3,"[""Natural language processing""]",0.5327929083873102,1,7.0,2017, natural_language_processing
HJqUtdOaZ,ENRICHMENT OF FEATURES FOR CLASSIFICATION USING AN OPTIMIZED LINEAR/NON-LINEAR COMBINATION OF INPUT FEATURES,3,"[""Classification"", ""Feature Combination"", ""Feature Mapping"", ""Feed-Forward Neural Network"", ""Genetic Algorithm"", ""Linear Transfer Function"", ""Non-Linear Transfer Function""]",0.5140526023794784,0,2.0,2018, classification feature_combination feature_mapping feed_forward_neural_network genetic_algorithm linear_transfer_function non_linear_transfer_function
HJr4QJ26W,Improving image generative models with human interactions,3,"[""human in the loop"", ""GANs"", ""generative adversarial networks"", ""image generative models"", ""computer vision""]",0.5164531277420416,0,4.333333333333333,2018, human_in_the_loop gans generative_adversarial_networks image_generative_models computer_vision
HJrDIpiee,Investigating Recurrence and Eligibility Traces in Deep Q-Networks,3,"[""Reinforcement Learning"", ""Deep learning""]",0.41402228194978,1,3.6666666666666665,2017, reinforcement_learning deep_learning
HJrJpzZRZ,Self-Supervised Learning of Object Motion Through Adversarial Video Prediction,3,"[""adversarial"", ""video prediction"", ""flow""]",0.5305113597086978,0,4.0,2018, adversarial video_prediction flow
HJsjkMb0Z,i-RevNet: Deep Invertible Networks,3,[],0.554863065606204,0,8.333333333333334,2018,
HJsk5-Z0W,Structured Deep Factorization Machine: Towards General-Purpose Architectures,3,"[""factorization"", ""general-purpose methods""]",0.597279089142143,0,3.6666666666666665,2018, factorization general_purpose_methods
HJtEm4p6Z,Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,3,"[""2000-Speaker Neural TTS"", ""Monotonic Attention"", ""Speech Synthesis""]",0.507155796371134,0,6.333333333333333,2018, 2000_speaker_neural_tts monotonic_attention speech_synthesis
HJtN5K9gx,Learning Disentangled Representations in Deep Generative Models,3,"[""Semi-Supervised Learning"", ""Deep learning"", ""Computer vision""]",0.5138169260877464,1,5.666666666666667,2017, semi_supervised_learning deep_learning computer_vision
HJvvRoe0W,An image representation based convolutional network for DNA classification,3,"[""DNA sequences"", ""Hilbert curves"", ""Convolutional neural networks"", ""chromatin structure""]",0.556436803874934,0,7.0,2018, dna_sequences hilbert_curves convolutional_neural_networks chromatin_structure
HJw8fAgA-,Learning Dynamic State Abstractions for Model-Based Reinforcement Learning,3,"[""generative models"", ""probabilistic modelling"", ""reinforcement learning"", ""state-space models"", ""planning""]",0.5077270697635647,0,6.333333333333333,2018, generative_models probabilistic_modelling reinforcement_learning state_space_models planning
HJy_5Mcll,ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation,3,"[""Deep learning""]",0.49167110846771594,1,4.0,2017, deep_learning
HJzgZ3JCW,Efficient Sparse-Winograd Convolutional Neural Networks,3,"[""deep learning"", ""convolutional neural network"", ""pruning""]",0.5073300284559388,0,7.333333333333333,2018, deep_learning convolutional_neural_network pruning
Hk-FlMbAZ,The Manifold Assumption and Defenses Against Adversarial Perturbations,2,"[""the manifold assumption"", ""adversarial perturbation"", ""neural networks""]",0.3642303464625162,0,4.0,2018, the_manifold_assumption adversarial_perturbation neural_networks
Hk-mgcsgx,An Information Retrieval Approach for Finding Dependent Subspaces of Multiple Views,3,"[""Unsupervised Learning""]",0.5484566803197145,1,4.0,2017, unsupervised_learning
Hk0wHx-RW,Learning Sparse Latent Representations with the Deep Copula Information Bottleneck,3,"[""Information Bottleneck"", ""Deep Information Bottleneck"", ""Deep Variational Information Bottleneck"", ""Variational Autoencoder"", ""Sparsity"", ""Disentanglement"", ""Interpretability"", ""Copula"", ""Mutual Information""]",0.5084374875239389,0,5.75,2018, information_bottleneck deep_information_bottleneck deep_variational_information_bottleneck variational_autoencoder sparsity disentanglement interpretability copula mutual_information
Hk1iOLcle,MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset,3,[],0.5728418091862331,1,6.0,2017,
Hk1l9Xqxe,BIOACOUSTIC SEGMENTATION BY HIERARCHICAL DIRICHLET PROCESS HIDDEN MARKOV MODEL,3,[],0.47959583086168783,1,4.666666666666667,2017,
Hk2MHt-3-,Coupled Ensembles of Neural Networks,3,"[""Ensemble learning"", ""neural networks""]",0.5083572169776168,0,6.0,2018, ensemble_learning neural_networks
Hk2aImxAb,Multi-Scale Dense Networks for Resource Efficient Image Classification,3,"[""efficient learning"", ""budgeted learning"", ""deep learning"", ""image classification"", ""convolutional networks""]",0.5571474500450551,0,8.333333333333334,2018, efficient_learning budgeted_learning deep_learning image_classification convolutional_networks
Hk3ddfWRW,Imitation Learning from Visual Data with Multiple Intentions,3,"[""multi-modal imitation learning"", ""deep learning"", ""generative models"", ""stochastic neural networks""]",0.5361463668415556,0,5.333333333333333,2018, multi_modal_imitation_learning deep_learning generative_models stochastic_neural_networks
Hk3mPK5gg,Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning,3,"[""Reinforcement Learning"", ""Applications"", ""Games""]",0.420101235704296,1,5.666666666666667,2017, reinforcement_learning applications games
Hk4_qw5xe,Towards Principled Methods for Training Generative Adversarial Networks,3,[],0.40596533916539324,1,8.333333333333334,2017,
Hk4kQHceg,Multiplicative LSTM for sequence modelling,3,"[""Deep learning"", ""Natural language processing"", ""Unsupervised Learning""]",0.5412825580476531,1,4.666666666666667,2017, deep_learning natural_language_processing unsupervised_learning
Hk5elxbRW,Smooth Loss Functions for Deep Top-k Classification,3,[],0.5172430210778286,0,7.0,2018,
Hk6WhagRW,Emergent Communication through Negotiation,3,"[""multi-agent learning"", ""reinforcement learning"", ""game theory"", ""emergent communication""]",0.43911632689218855,0,6.0,2018, multi_agent_learning reinforcement_learning game_theory emergent_communication
Hk6a8N5xe,Classify or Select: Neural Architectures for Extractive Document Summarization,4,"[""Natural language processing"", ""Supervised Learning"", ""Applications"", ""Deep learning""]",0.6014846595374332,1,4.666666666666667,2017, natural_language_processing supervised_learning applications deep_learning
Hk6kPgZA-,Certifying Some Distributional Robustness with Principled Adversarial Training,2,"[""adversarial training"", ""distributionally robust optimization"", ""deep learning"", ""optimization"", ""learning theory""]",0.3669874267646944,0,9.0,2018, adversarial_training distributionally_robust_optimization deep_learning optimization learning_theory
Hk85q85ee,Symmetry-Breaking Convergence Analysis of Certain Two-layered Neural Networks with ReLU nonlinearity,3,"[""Theory"", ""Deep learning"", ""Optimization""]",0.43335001738683104,1,5.333333333333333,2017, theory deep_learning optimization
Hk8N3Sclg,Multi-Agent Cooperation and the Emergence of (Natural) Language,3,"[""Natural language processing"", ""Reinforcement Learning"", ""Games""]",0.5154244101362194,1,7.0,2017, natural_language_processing reinforcement_learning games
Hk8TGSKlg,Reasoning with Memory Augmented Neural Networks for Language Comprehension,3,"[""Natural language processing"", ""Deep learning""]",0.5708196064087989,1,6.666666666666667,2017, natural_language_processing deep_learning
Hk8XMWgRb,Not-So-Random Features,3,"[""kernel learning"", ""random features"", ""online learning""]",0.48979381247432113,0,5.666666666666667,2018, kernel_learning random_features online_learning
Hk8rlUqge,Joint Multimodal Learning with Deep Generative Models,3,[],0.42830644121689054,1,4.333333333333333,2017,
Hk91SGWR-,Investigating Human Priors for Playing Video Games,3,"[""Prior knowledge"", ""Reinforcement learning"", ""Cognitive Science""]",0.4930162269571211,0,5.333333333333333,2018, prior_knowledge reinforcement_learning cognitive_science
Hk95PK9le,Deep Biaffine Attention for Neural Dependency Parsing,3,"[""Natural language processing"", ""Deep learning""]",0.5392733843738965,1,5.333333333333333,2017, natural_language_processing deep_learning
Hk99zCeAb,"Progressive Growing of GANs for Improved Quality, Stability, and Variation",3,"[""generative adversarial networks"", ""unsupervised learning"", ""hierarchical methods""]",0.4577195665625645,0,5.666666666666667,2018, generative_adversarial_networks unsupervised_learning hierarchical_methods
Hk9Xc_lR-,On the Discrimination-Generalization Tradeoff in GANs,3,"[""generative adversarial network"", ""discrimination"", ""generalization""]",0.42242246151097507,0,5.333333333333333,2018, generative_adversarial_network discrimination generalization
HkAClQgA-,A Deep Reinforced Model for Abstractive Summarization,3,"[""deep learning"", ""natural language processing"", ""reinforcement learning"", ""text summarization"", ""sequence generation""]",0.5674053044914558,0,7.0,2018, deep_learning natural_language_processing reinforcement_learning text_summarization sequence_generation
HkCjNI5ex,Regularizing Neural Networks by Penalizing Confident Output Distributions,3,"[""Deep learning"", ""Supervised Learning"", ""Speech"", ""Structured prediction""]",0.4679741865171738,1,5.333333333333333,2017, deep_learning supervised_learning speech structured_prediction
HkCnm-bAb,Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?,3,"[""deep learning"", ""deep reinforcement learning"", ""combinatorial games"", ""optimality""]",0.44926199327797667,0,5.666666666666667,2018, deep_learning deep_reinforcement_learning combinatorial_games optimality
HkCsm6lRb,Generative Models of Visually Grounded Imagination,3,"[""variational autoencoders"", ""generative models"", ""language"", ""vision"", ""abstraction"", ""compositionality"", ""hierarchy""]",0.5027504089757251,0,7.0,2018, variational_autoencoders generative_models language vision abstraction compositionality hierarchy
HkCvZXbC-,3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY,3,[],0.4046040085653114,0,4.333333333333333,2018,
HkE0Nvqlg,Structured Attention Networks,3,[],0.5016102439836516,1,8.0,2017,
HkEI22jeg,Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses,3,"[""Deep learning"", ""Applications""]",0.5686014700375682,1,6.333333333333333,2017, deep_learning applications
HkGJUXb0-,Learning Efficient Tensor Representations with Ring Structure Networks,3,"[""Tensor Decomposition"", ""Tensor Networks"", ""Stochastic Gradient Descent""]",0.5146166491206173,0,5.333333333333333,2018, tensor_decomposition tensor_networks stochastic_gradient_descent
HkGcX--0-,Auxiliary Guided Autoregressive Variational Autoencoders,3,[],0.4832955337814183,0,5.666666666666667,2018,
HkIQH7qel,Learning Recurrent Span Representations for Extractive Question Answering,3,"[""Natural language processing""]",0.5798954426920445,1,6.333333333333333,2017, natural_language_processing
HkJ1rgbCb,Using Deep Reinforcement Learning to Generate Rationales for Molecules,3,"[""Reinforcement Learning"", ""Chemistry"", ""Interpretable Models""]",0.4544972088271967,0,5.0,2018, reinforcement_learning chemistry interpretable_models
HkJq1Ocxl,Programming With a Differentiable Forth Interpreter,3,[],0.5691761842818606,1,6.0,2017,
HkL7n1-0b,Wasserstein Auto-Encoders,3,"[""auto-encoder"", ""generative models"", ""GAN"", ""VAE"", ""unsupervised learning""]",0.43842185292903707,0,8.0,2018, auto_encoder generative_models gan vae unsupervised_learning
HkLXCE9lx,RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning,3,"[""Reinforcement Learning"", ""Deep learning""]",0.5031749797055939,1,3.3333333333333335,2017, reinforcement_learning deep_learning
HkMCybx0-,Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs),3,"[""Deep learning"", ""Theory""]",0.5204035578328979,0,4.0,2018, deep_learning theory
HkMhoDITb,Reinforcement Learning via Replica Stacking of Quantum Measurements for the Training of Quantum Boltzmann Machines,3,"[""Quantum Annealing"", ""Reinforcement Learning"", ""Boltzmann Machines"", ""Markov Chain Monte Carlo""]",0.4732676192100208,0,4.666666666666667,2018, quantum_annealing reinforcement_learning boltzmann_machines markov_chain_monte_carlo
HkMvEOlAb,Learning Latent Representations in Neural Networks for Clustering through Pseudo Supervision and Graph-based Activity Regularization,3,"[""representation learning"", ""unsupervised clustering"", ""pseudo supervision"", ""graph-based activity regularization"", ""auto-clustering output layer""]",0.46753582608210115,0,6.666666666666667,2018, representation_learning unsupervised_clustering pseudo_supervision graph_based_activity_regularization auto_clustering_output_layer
HkNEuToge,Energy-Based Spherical Sparse Coding,3,[],0.5353243280141047,1,5.333333333333333,2017,
HkNGsseC-,On the Expressive Power of Overlapping Architectures of Deep Learning,3,"[""Deep Learning"", ""Expressive Efficiency"", ""Overlapping"", ""Receptive Fields""]",0.5095471398823752,0,6.666666666666667,2018, deep_learning expressive_efficiency overlapping receptive_fields
HkNKFiGex,Neural Photo Editing with Introspective Adversarial Networks,3,"[""Computer vision"", ""Unsupervised Learning"", ""Applications""]",0.5106120193699049,1,5.666666666666667,2017, computer_vision unsupervised_learning applications
HkNRsU5ge,Sigma Delta Quantized Networks,4,"[""Computer vision"", ""Deep learning"", ""Applications""]",0.6052921735407935,1,7.333333333333333,2017, computer_vision deep_learning applications
HkOhuyA6-,Graph Classification with 2D Convolutional Neural Networks,3,"[""graph classification"", ""convolutional neural networks"", ""2D CNN"", ""representation""]",0.4867873382958301,0,4.666666666666667,2018, graph_classification convolutional_neural_networks 2d_cnn representation
HkPCrEZ0Z,Combining Model-based and Model-free RL via Multi-step Control Variates,3,[],0.4192528467163964,0,4.666666666666667,2018,
HkSOlP9lg,Recurrent Inference Machines for Solving Inverse Problems,3,"[""Optimization"", ""Deep learning"", ""Computer vision""]",0.5298032528409289,1,5.333333333333333,2017, optimization deep_learning computer_vision
HkTEFfZRb,Attacking Binarized Neural Networks,3,"[""adversarial examples"", ""adversarial attacks"", ""binary"", ""binarized neural networks""]",0.49295117723804266,0,6.666666666666667,2018, adversarial_examples adversarial_attacks binary binarized_neural_networks
HkUR_y-RZ,SEARNN: Training RNNs with global-local losses,3,"[""Structured prediction"", ""RNNs""]",0.5083256450129522,0,6.666666666666667,2018, structured_prediction rnns
HkXWCMbRW,Towards Image Understanding from Deep Compression Without Decoding,3,[],0.5941279232175622,0,7.0,2018,
HkYhZDqxg,Tree-structured decoding with doubly-recurrent neural networks,3,"[""Natural language processing"", ""Supervised Learning"", ""Structured prediction""]",0.5772114504538288,1,6.333333333333333,2017, natural_language_processing supervised_learning structured_prediction
HkZy-bW0-,Temporally Efficient Deep Learning with Spikes,3,"[""online learning"", ""spiking networks"", ""deep learning"", ""temporal""]",0.492063898060501,0,7.0,2018, online_learning spiking_networks deep_learning temporal
HkanP0lRW,Data-driven Feature Sampling for Deep Hyperspectral Classification and Segmentation,3,"[""Applied deep learning"", ""Image segmentation"", ""Hyperspectral Imaging"", ""Feature sampling""]",0.5311931285150124,0,4.333333333333333,2018, applied_deep_learning image_segmentation hyperspectral_imaging feature_sampling
HkbJTYyAb,Convolutional Normalizing Flows,3,[],0.43917485988057026,0,3.6666666666666665,2018,
Hkbd5xZRb,Spherical CNNs,3,"[""deep learning"", ""equivariance"", ""convolution"", ""group convolution"", ""3D"", ""vision"", ""omnidirectional"", ""shape recognition"", ""molecular energy regression""]",0.5178792005021831,0,8.0,2018, deep_learning equivariance convolution group_convolution 3d vision omnidirectional shape_recognition molecular_energy_regression
HkbmWqxCZ,The Mutual Autoencoder: Controlling Information in Latent Code Representations,3,[],0.45823321595912575,0,4.333333333333333,2018,
Hkc-TeZ0W,A Hierarchical Model for Device Placement,3,"[""deep learning"", ""device placement"", ""policy gradient optimization""]",0.5042491961777977,0,6.0,2018, deep_learning device_placement policy_gradient_optimization
HkcTe-bR-,Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design,3,"[""reinforcement learning"", ""molecule design"", ""de novo design"", ""ppo"", ""sample-efficient reinforcement learning""]",0.4884694997057314,0,5.666666666666667,2018, reinforcement_learning molecule_design de_novo_design ppo sample_efficient_reinforcement_learning
HkcdHtqlx,Gated-Attention Readers for Text Comprehension,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5892270853404565,1,6.333333333333333,2017, natural_language_processing deep_learning supervised_learning
HkeJVllRW,Sparse-Complementary Convolution for Efficient Model Utilization on CNNs,3,"[""CNN"", ""sparse convolution"", ""sparse kernel"", ""sparsity"", ""model utilization"", ""image classification""]",0.5332538597682104,0,5.333333333333333,2018, cnn sparse_convolution sparse_kernel sparsity model_utilization image_classification
HkepKG-Rb,A Semantic Loss Function for Deep Learning with Symbolic Knowledge,3,"[""deep learning"", ""symbolic knowledge"", ""semi-supervised learning"", ""constraints""]",0.5445459440568698,0,5.333333333333333,2018, deep_learning symbolic_knowledge semi_supervised_learning constraints
HkfXMz-Ab,Neural Sketch Learning for Conditional Program Generation,3,"[""Program generation"", ""Source code"", ""Program synthesis"", ""Deep generative models""]",0.49189397990451894,0,7.333333333333333,2018, program_generation source_code program_synthesis deep_generative_models
Hkfmn5n6W,Exponentially vanishing sub-optimal local minima in multilayer neural networks,3,"[""neural networks"", ""theory"", ""optimization"", ""local minima"", ""loss landscape""]",0.47051138876789417,0,6.0,2018, neural_networks theory optimization local_minima loss_landscape
Hkg4TI9xl,A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks,3,"[""Computer vision""]",0.5661703663001217,1,6.0,2017, computer_vision
Hkg8bDqee,Introspection:Accelerating Neural Network Training By Learning Weight Evolution,3,"[""Computer vision"", ""Deep learning"", ""Optimization""]",0.5132758794116239,1,8.0,2017, computer_vision deep_learning optimization
HkgNdt26Z,Distributed Fine-tuning of Language Models on Private Data,3,"[""distributed training"", ""federated learning"", ""language modeling"", ""differential privacy""]",0.44897282167843794,0,4.333333333333333,2018, distributed_training federated_learning language_modeling differential_privacy
Hki-ZlbA-,Ground-Truth Adversarial Examples,3,"[""adversarial examples"", ""neural networks"", ""formal verification"", ""ground truths""]",0.42452163842970936,0,5.0,2018, adversarial_examples neural_networks formal_verification ground_truths
HkinqfbAb,Automatic Parameter Tying in Neural Networks,3,"[""neural network"", ""quantization"", ""compression""]",0.48974724959177,0,6.0,2018, neural_network quantization compression
HkjL6MiTb,Siamese Survival Analysis with Competing Risks,3,"[""survival analysis"", ""competing risks"", ""siamese neural networks""]",0.5293221475222702,0,4.0,2018, survival_analysis competing_risks siamese_neural_networks
HklZOfW0W,UPS: optimizing Undirected Positive Sparse graph for neural graph filtering,3,[],0.4988837793863546,0,4.333333333333333,2018,
HkljfjFee,Support Regularized Sparse Coding and Its Fast Encoder,3,[],0.47629353795260754,1,6.666666666666667,2017,
HklpCzC6-,Image Segmentation by Iterative Inference from Conditional Score Estimation,3,"[""semantic segmentation"", ""conditional denoising autoencoders"", ""iterative inference""]",0.5855154844195014,0,4.333333333333333,2018, semantic_segmentation conditional_denoising_autoencoders iterative_inference
HkmaTz-0W,Visualizing the Loss Landscape of Neural Nets,3,"[""visualization"", ""loss surface"", ""flatness"", ""sharpness""]",0.4742538169373145,0,4.666666666666667,2018, visualization loss_surface flatness sharpness
Hkn7CBaTW,Learning how to explain neural networks: PatternNet and PatternAttribution,3,"[""machine learning"", ""interpretability"", ""deep learning""]",0.5171722520954128,0,7.333333333333333,2018, machine_learning interpretability deep_learning
HknbyQbC-,Generating Adversarial Examples with Adversarial Networks,3,"[""adversarial examples"", ""generative adversarial network"", ""black-box attack""]",0.40060393649211395,0,5.666666666666667,2018, adversarial_examples generative_adversarial_network black_box_attack
Hko85plCW,Monotonic Chunkwise Attention,3,"[""attention"", ""sequence-to-sequence"", ""speech recognition"", ""document summarization""]",0.5363564386420953,0,7.0,2018, attention sequence_to_sequence speech_recognition document_summarization
Hkp3uhxCW,Revisiting Bayes by Backprop,3,"[""Bayesian"", ""Deep Learning"", ""Recurrent Neural Networks"", ""LSTM""]",0.5797298257344692,0,5.666666666666667,2018, bayesian deep_learning recurrent_neural_networks lstm
HkpLeH9el,Neural Functional Programming,3,"[""Supervised Learning""]",0.5559680567921447,1,5.4,2017, supervised_learning
HkpRBFxRb,Learning to Mix n-Step Returns: Generalizing Lambda-Returns for Deep Reinforcement Learning,3,"[""Reinforcement Learning"", ""Lambda-Returns""]",0.44109631640347996,0,5.333333333333333,2018, reinforcement_learning lambda_returns
HkpYwMZRb,Gradients explode - Deep Networks are shallow - ResNet explained,3,"[""deep learning"", ""MLP"", ""ResNet"", ""residual network"", ""exploding gradient problem"", ""vanishing gradient problem"", ""effective depth"", ""batch normalization"", ""covariate shift""]",0.5214104577422476,0,5.333333333333333,2018, deep_learning mlp resnet residual_network exploding_gradient_problem vanishing_gradient_problem effective_depth batch_normalization covariate_shift
HkpbnH9lx,Density estimation using Real NVP,3,"[""Deep learning"", ""Unsupervised Learning""]",0.49672833967222707,1,7.666666666666667,2017, deep_learning unsupervised_learning
HksioDcxl,Joint Training of Ratings and Reviews with Recurrent Recommender Networks,3,[],0.5838524157578528,1,6.0,2017,
Hksj2WWAW,Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs,3,"[""symbolic reasoning"", ""mathematical equations"", ""recursive neural networks"", ""neural programing""]",0.5747555531974162,0,6.333333333333333,2018, symbolic_reasoning mathematical_equations recursive_neural_networks neural_programing
HktJec1RZ,Towards Neural Phrase-based Machine Translation,3,"[""Neural Machine Translation"", ""Sequence to Sequence"", ""Sequence Modeling""]",0.5442437845642779,0,6.666666666666667,2018, neural_machine_translation sequence_to_sequence sequence_modeling
HktK4BeCZ,Learning Deep Mean Field Games for Modeling Large Population Behavior,3,"[""mean field games"", ""reinforcement learning"", ""Markov decision processes"", ""inverse reinforcement learning"", ""deep learning"", ""inverse optimal control"", ""computational social science"", ""population modeling""]",0.4064111623025156,0,8.666666666666666,2018, mean_field_games reinforcement_learning markov_decision_processes inverse_reinforcement_learning deep_learning inverse_optimal_control computational_social_science population_modeling
HktRlUlAZ,Polar Transformer Networks,3,"[""equivariance"", ""invariance"", ""canonical coordinates""]",0.5206660104605638,0,7.333333333333333,2018, equivariance invariance canonical_coordinates
HktXuGb0-,Reward Estimation via State Prediction,3,"[""reinforcement learning"", ""inverse reinforcement learning"", ""imitation learning""]",0.4621479787559723,0,4.0,2018, reinforcement_learning inverse_reinforcement_learning imitation_learning
Hku9NK5lx,Training Compressed Fully-Connected Networks with a Density-Diversity Penalty,3,"[""Deep learning""]",0.4495501406861064,1,7.0,2017, deep_learning
HkuGJ3kCb,All-but-the-Top: Simple and Effective Postprocessing for Word Representations,3,[],0.557453161720281,0,6.666666666666667,2018,
HkuVu3ige,On orthogonality and learning recurrent networks with long term dependencies,3,"[""Deep learning""]",0.45889086952430325,1,5.666666666666667,2017, deep_learning
HkvS3Mqxe,Coarse Pruning of Convolutional Neural Networks with Random Masks,3,[],0.4583174879054875,1,5.0,2017,
HkwBEMWCZ,Skip Connections Eliminate Singularities,3,"[""deep learning"", ""optimization"", ""skip connections""]",0.4940634886360414,0,7.333333333333333,2018, deep_learning optimization skip_connections
HkwVAXyCW,Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks,3,"[""recurrent neural networks"", ""dynamic learning"", ""conditional computation""]",0.5129329633270626,0,6.0,2018, recurrent_neural_networks dynamic_learning conditional_computation
HkwZSG-CZ,Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,3,[],0.5963236290473876,0,7.333333333333333,2018,
HkwoSDPgg,Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data,3,[],0.4581805925893912,1,8.333333333333334,2017,
HkwrqtlR-,WHAT ARE GANS USEFUL FOR?,3,"[""Generative Modeling"", ""Generative Adversarial Networks"", ""Density Estimation""]",0.43537793805397823,0,3.0,2018, generative_modeling generative_adversarial_networks density_estimation
HkxAAvcxx,Transformation-based Models of Video Sequences,3,"[""Computer vision"", ""Unsupervised Learning""]",0.5033584413391108,1,4.666666666666667,2017, computer_vision unsupervised_learning
HkxF5RgC-,Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip,3,"[""Sparsity"", ""Pruning"", ""Compression"", ""RNN"", ""LSTM"", ""Persistent"", ""RF-Resident"", ""GPU""]",0.5782288405883076,0,6.0,2018, sparsity pruning compression rnn lstm persistent rf_resident gpu
HkyYqU9lx,Sequence to Sequence Transduction with Hard Monotonic Attention,3,"[""Natural language processing"", ""Applications""]",0.504990724715503,1,4.666666666666667,2017, natural_language_processing applications
Hkz6aNqle,Deep Error-Correcting Output Codes,3,[],0.5519727435432875,1,3.0,2017,
HkzuKpLgg,Efficient Communications in Training Large Scale Neural Networks,3,"[""Applications"", ""Deep learning""]",0.5269116419949887,1,5.0,2017, applications deep_learning
Hy-2G6ile,Gated Multimodal Units for Information Fusion,3,"[""Multi-modal learning"", ""Applications"", ""Supervised Learning""]",0.5138198019455201,1,5.666666666666667,2017, multi_modal_learning applications supervised_learning
Hy-lMNqex,Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability,3,"[""Deep learning"", ""Applications""]",0.5689877642344935,1,4.8,2017, deep_learning applications
Hy0L4t5el,Tree-Structured Variational Autoencoder,3,[],0.5569905849495045,1,3.3333333333333335,2017,
Hy1d-ebAb,Learning Deep Generative Models of Graphs,3,"[""Generative Model of Graphs""]",0.42089409429529334,0,5.666666666666667,2018, generative_model_of_graphs
Hy3MvSlRW,Adversarial reading networks for machine comprehension,3,"[""machine reading"", ""adversarial training""]",0.5512351718324294,0,4.666666666666667,2018, machine_reading adversarial_training
Hy3_KuYxg,Divide and Conquer with Neural Networks,3,"[""Deep learning""]",0.5337867789469158,1,3.6666666666666665,2017, deep_learning
Hy6GHpkCW,A Neural Representation of Sketch Drawings,3,"[""applications"", ""image modelling"", ""computer-assisted"", ""drawing"", ""art"", ""creativity"", ""dataset""]",0.5480613140571903,0,7.0,2018, applications image_modelling computer_assisted drawing art creativity dataset
Hy6b4Pqee,Deep Probabilistic Programming,3,[],0.5049843397259266,1,6.666666666666667,2017,
Hy7EPh10W,Novelty Detection with GAN,3,"[""novelty detection"", ""GAN"", ""feature matching"", ""semi-supervised""]",0.4726103262154986,0,5.0,2018, novelty_detection gan feature_matching semi_supervised
Hy7fDog0b,AmbientGAN: Generative models from lossy measurements,2,"[""Generative models"", ""Adversarial networks"", ""Lossy measurements""]",0.38934183433183467,0,7.333333333333333,2018, generative_models adversarial_networks lossy_measurements
Hy8X3aKee,Deep Symbolic Representation Learning for Heterogeneous Time-series Classification,3,[],0.5513811867762767,1,4.0,2017,
Hy8hkYeRb,A Deep Predictive Coding Network for Learning Latent Representations,3,"[""Predictive coding"", ""deep neural network"", ""generative model"", ""unsupervised learning"", ""learning latent representations""]",0.4728843504065286,0,3.3333333333333335,2018, predictive_coding deep_neural_network generative_model unsupervised_learning learning_latent_representations
HyAbMKwxe,Tighter bounds lead to improved classifiers,3,[],0.5241052383305924,1,6.0,2017,
HyAddcLge,Revisiting Distributed Synchronous SGD,3,"[""Optimization"", ""Deep learning"", ""Applications""]",0.504024613686242,1,5.666666666666667,2017, optimization deep_learning applications
HyBbjW-RW,Open Loop Hyperparameter Optimization and Determinantal Point Processes,3,"[""hyperparameter optimization"", ""random search"", ""determinantal point processes"", ""low discrepancy sequences""]",0.5052067765695187,0,4.0,2018, hyperparameter_optimization random_search determinantal_point_processes low_discrepancy_sequences
HyCRyS9gx,Fast Adaptation in Generative Models with Generative Matching Networks,3,"[""Deep learning"", ""Unsupervised Learning""]",0.40419361963238654,1,5.333333333333333,2017, deep_learning unsupervised_learning
HyDAQl-AW,Time Limits in Reinforcement Learning,3,"[""reinforcement learning"", ""Markov decision processes"", ""deep learning""]",0.4002432568766288,0,4.333333333333333,2018, reinforcement_learning markov_decision_processes deep_learning
HyDMX0l0Z,Towards Effective GANs for Data Distributions with Diverse Modes,3,"[""generative adversarial networks"", ""GANs"", ""deep learning"", ""unsupervised learning"", ""generative models"", ""adversarial learning""]",0.4221066130089386,0,4.666666666666667,2018, generative_adversarial_networks gans deep_learning unsupervised_learning generative_models adversarial_learning
HyET6tYex,Universality in halting time,3,"[""Optimization""]",0.4433453799204033,1,4.0,2017, optimization
HyEeMu_xx,Progressive Attention Networks for Visual Attribute Prediction,3,"[""Deep learning"", ""Computer vision"", ""Multi-modal learning""]",0.4770025684541881,1,5.666666666666667,2017, deep_learning computer_vision multi_modal_learning
HyEi7bWR-,Orthogonal Recurrent Neural Networks with Scaled Cayley Transform,3,"[""recurrent neural networks"", ""vanishing gradients"", ""exploding gradients"", ""orthogonal"", ""unitary"", ""long term dependencies"", ""uRNN""]",0.5596318457546129,0,6.0,2018, recurrent_neural_networks vanishing_gradients exploding_gradients orthogonal unitary long_term_dependencies urnn
HyFaiGbCW,Generalization of Learning using Reservoir Computing,3,"[""Generalization"", ""Reservoir Computing"", ""dynamical system"", ""Siamese Neural Network"", ""image classification"", ""similarity"", ""dimensionality reduction""]",0.5080832115212494,0,4.0,2018, generalization reservoir_computing dynamical_system siamese_neural_network image_classification similarity dimensionality_reduction
HyFkG45gl,Machine Solver for Physics Word Problems,3,[],0.5530438818915121,1,4.333333333333333,2017,
HyGTuv9eg,Incorporating long-range consistency in CNN-based texture generation,3,"[""Computer vision"", ""Deep learning""]",0.5493902442953851,1,6.333333333333333,2017, computer_vision deep_learning
HyH9lbZAW,Variational Message Passing with Structured Inference Networks,3,"[""Variational Inference"", ""Variational Message Passing"", ""Variational Auto-Encoder"", ""Graphical Models"", ""Structured Models"", ""Natural Gradients""]",0.49542510678888674,0,7.0,2018, variational_inference variational_message_passing variational_auto_encoder graphical_models structured_models natural_gradients
HyHmGyZCZ,Comparison of Paragram and GloVe Results for Similarity Benchmarks,3,"[""language models"", ""vector spaces"", ""word embedding"", ""similarity""]",0.5427931598812614,0,3.0,2018, language_models vector_spaces word_embedding similarity
HyI5ro0pW,Neural Networks with Block Diagonal Inner Product Layers,3,"[""Deep Learning"", ""Neural Networks""]",0.5446901773824118,0,5.0,2018, deep_learning neural_networks
HyI6s40a-,Towards Safe Deep Learning: Unsupervised Defense Against Generic Adversarial Attacks,3,"[""Adversarial Attacks"", ""Unsupervised Defense"", ""Deep Learning""]",0.46194903053511543,0,5.0,2018, adversarial_attacks unsupervised_defense deep_learning
HyIFzx-0b,BinaryFlex: On-the-Fly Kernel Generation in Binary Convolutional Networks,3,[],0.47932025518739724,0,4.333333333333333,2018,
HyKZyYlRZ,Large Scale Multi-Domain Multi-Task Learning with MultiModel,3,"[""multi-task learning"", ""transfer learning""]",0.5483467997359829,0,5.0,2018, multi_task_learning transfer_learning
HyM25Mqel,Sample Efficient Actor-Critic with  Experience Replay,3,"[""Deep learning"", ""Reinforcement Learning""]",0.45192257981942024,1,6.333333333333333,2017, deep_learning reinforcement_learning
HyMTkQZAb,Kronecker-factored Curvature Approximations for Recurrent Neural Networks,3,"[""optimization"", ""K-FAC"", ""natural gradient"", ""recurrent neural networks""]",0.47691444809267736,0,6.333333333333333,2018, optimization k_fac natural_gradient recurrent_neural_networks
HyNxRZ9xg,Cat2Vec: Learning Distributed Representation of Multi-field Categorical Data,3,"[""Unsupervised Learning"", ""Deep learning"", ""Applications""]",0.4903963073730272,1,4.333333333333333,2017, unsupervised_learning deep_learning applications
HyPpD0g0Z,Grouping-By-ID: Guarding Against Adversarial Domain Shifts,3,"[""supervised representation learning"", ""causality"", ""interpretability"", ""transfer learning""]",0.4347719964723601,0,5.333333333333333,2018, supervised_representation_learning causality interpretability transfer_learning
HyQJ-mclg,Incremental Network Quantization: Towards Lossless CNNs with Low-precision Weights,3,"[""Deep learning"", ""Optimization""]",0.4468645691237605,1,7.333333333333333,2017, deep_learning optimization
HyQWFOVge,Significance of Softmax-Based Features over Metric Learning-Based Features,3,"[""Computer vision"", ""Deep learning""]",0.473967814357376,1,5.333333333333333,2017, computer_vision deep_learning
HyRVBzap-,Cascade Adversarial Machine Learning Regularized with a Unified Embedding,2,"[""adversarial machine learning"", ""embedding"", ""regularization"", ""adversarial attack""]",0.38229090776474134,0,5.666666666666667,2018, adversarial_machine_learning embedding regularization adversarial_attack
HyRnez-RW,Multi-Mention Learning for Reading Comprehension with Neural Cascades,3,"[""reading comprehension"", ""multi-loss"", ""question answering"", ""scalable"", ""TriviaQA"", ""feed-forward"", ""latent variable"", ""attention""]",0.5724672236896289,0,6.0,2018, reading_comprehension multi_loss question_answering scalable triviaqa feed_forward latent_variable attention
HyTqHL5xg,Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data,3,"[""Deep learning"", ""Unsupervised Learning""]",0.565285590534484,1,6.333333333333333,2017, deep_learning unsupervised_learning
HyTrSegCb,Achieving morphological agreement with Concorde,3,"[""NLP"", ""morphology"", ""seq2seq""]",0.5866024101250884,0,4.333333333333333,2018, nlp morphology seq2seq
HyUNwulC-,Parallelizing Linear Recurrent Neural Nets Over Sequence Length,3,"[""rnn"", ""sequence"", ""parallel"", ""qrnn"", ""sru"", ""gilr"", ""gilr-lstm""]",0.5712202285797703,0,6.666666666666667,2018, rnn sequence parallel qrnn sru gilr gilr_lstm
HyWDCXjgx,Multi-label learning with the RNNs for Fashion Search,3,"[""Computer vision"", ""Deep learning"", ""Supervised Learning"", ""Applications""]",0.5169354280250492,1,3.3333333333333335,2017, computer_vision deep_learning supervised_learning applications
HyWG0H5ge,Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks,3,"[""Deep learning"", ""Optimization"", ""Theory"", ""Supervised Learning""]",0.4704351650337199,1,5.666666666666667,2017, deep_learning optimization theory supervised_learning
HyWWpw5ex,Recurrent Coevolutionary Feature Embedding Processes for Recommendation,3,"[""Deep learning"", ""Applications""]",0.5172982169666965,1,6.0,2017, deep_learning applications
HyWrIgW0W,"Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks",3,"[""sgd"", ""variational inference"", ""gradient noise"", ""out-of-equilibrium""]",0.4390239940152454,0,6.333333333333333,2018, sgd variational_inference gradient_noise out_of_equilibrium
HyXBcYg0b,Residual Gated Graph ConvNets,3,"[""graph neural networks"", ""ConvNets"", ""RNNs"", ""pattern matching"", ""semi-supervised clustering""]",0.46654728935923345,0,5.333333333333333,2018, graph_neural_networks convnets rnns pattern_matching semi_supervised_clustering
HyXNCZbCZ,Hierarchical Adversarially Learned Inference,3,"[""generative"", ""hierarchical"", ""unsupervised"", ""semisupervised"", ""latent"", ""ALI"", ""GAN""]",0.5121379483363526,0,5.666666666666667,2018, generative hierarchical unsupervised semisupervised latent ali gan
HyY0Ff-AZ,Representing Entropy : A short proof of the equivalence between soft Q-learning and policy gradients,3,"[""soft Q-learning"", ""policy gradients"", ""entropy"", ""Legendre transformation"", ""duality"", ""convex analysis"", ""Donsker-Varadhan""]",0.4536198925144662,0,4.0,2018, soft_q_learning policy_gradients entropy legendre_transformation duality convex_analysis donsker_varadhan
HyY4Owjll,Boosted Generative Models,3,"[""Theory"", ""Deep learning"", ""Unsupervised Learning""]",0.4774881153427755,1,5.333333333333333,2017, theory deep_learning unsupervised_learning
HyZoi-WRb,Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference,3,"[""variational inference"", ""approximate inference"", ""generative models""]",0.5111123543650357,0,6.666666666666667,2018, variational_inference approximate_inference generative_models
Hy_o3x-0b,Feature Map Variational Auto-Encoders,3,"[""deep learning"", ""representation learning"", ""variational auto-encoders"", ""variational inference"", ""generative models""]",0.5286370330028239,0,4.666666666666667,2018, deep_learning representation_learning variational_auto_encoders variational_inference generative_models
Hyanrrqlg,HFH: Homologically Functional Hashing for Compressing Deep Neural Networks,3,[],0.4915888086534191,1,5.0,2017,
HycUbvcge,Deep Generalized Canonical Correlation Analysis,3,"[""Unsupervised Learning"", ""Deep learning"", ""Multi-modal learning""]",0.523141520018983,1,6.0,2017, unsupervised_learning deep_learning multi_modal_learning
HydnA1WCb,Gaussian Prototypical Networks for Few-Shot Learning on Omniglot,3,"[""one-shot learning"", ""few-shot learning"", ""Omniglot""]",0.4980319231875859,0,3.3333333333333335,2018, one_shot_learning few_shot_learning omniglot
HyecJGP5ge,NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ONLINE MODEL ADAPTION IN A CHANGING WORLD,3,"[""Unsupervised Learning"", ""Computer vision"", ""Transfer Learning"", ""Optimization"", ""Applications""]",0.45849787368829825,1,5.666666666666667,2017, unsupervised_learning computer_vision transfer_learning optimization applications
HyenWc5gx,Representation Stability as a Regularizer for Improved Text Analytics Transfer Learning,3,"[""Deep learning"", ""Transfer Learning"", ""Natural language processing""]",0.5155758354667785,1,6.0,2017, deep_learning transfer_learning natural_language_processing
HyfHgI6aW,Memory Augmented Control Networks,3,"[""planning"", ""memory networks"", ""deep learning"", ""robotics""]",0.42964771967892823,0,6.333333333333333,2018, planning memory_networks deep_learning robotics
Hyg0vbWC-,Generating Wikipedia by Summarizing Long Sequences,3,"[""abstractive summarization"", ""Transformer"", ""long sequences"", ""natural language processing"", ""sequence transduction"", ""Wikipedia"", ""extractive summarization""]",0.5440843366285624,0,7.333333333333333,2018, abstractive_summarization transformer long_sequences natural_language_processing sequence_transduction wikipedia extractive_summarization
HyiAuyb0b,TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning,3,"[""deep learning"", ""reinforcement learning"", ""temporal difference""]",0.43401476440349357,0,7.0,2018, deep_learning reinforcement_learning temporal_difference
HyiRazbRb,Demystifying overcomplete nonlinear auto-encoders: fast SGD convergence towards sparse representation from random initialization,3,"[""stochastic gradient descent"", ""autoencoders"", ""nonconvex optimization"", ""representation learning"", ""theory""]",0.5391412758939307,0,2.3333333333333335,2018, stochastic_gradient_descent autoencoders nonconvex_optimization representation_learning theory
Hyig0zb0Z,Gated ConvNets for Letter-Based ASR,4,"[""automatic speech recognition"", ""letter-based acoustic model"", ""gated convnets""]",0.610502294093656,0,4.333333333333333,2018, automatic_speech_recognition letter_based_acoustic_model gated_convnets
HyjC5yWCW,Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,3,"[""meta-learning"", ""learning to learn"", ""universal function approximation""]",0.48565700792957134,0,6.333333333333333,2018, meta_learning learning_to_learn universal_function_approximation
HylgYB3pZ,Linearly Constrained Weights: Resolving the Vanishing Gradient Problem by Reducing Angle Bias,3,"[""vanishing gradient problem"", ""multilayer perceptron"", ""angle bias""]",0.48058728476159396,0,4.666666666666667,2018, vanishing_gradient_problem multilayer_perceptron angle_bias
HymYLebCb,Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification,3,"[""deep learning"", ""transfer learning"", ""adjacency matrices"", ""image feature representation"", ""Caffe"", ""graph classification""]",0.4670432694700102,0,5.0,2018, deep_learning transfer_learning adjacency_matrices image_feature_representation caffe graph_classification
HymuJz-A-,Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks,3,"[""Visual Relations"", ""Visual Reasoning"", ""SVRT"", ""Attention"", ""Working Memory"", ""Convolutional Neural Network"", ""Deep Learning"", ""Relational Network""]",0.508879426756041,0,6.0,2018, visual_relations visual_reasoning svrt attention working_memory convolutional_neural_network deep_learning relational_network
HyoST_9xl,DSD: Dense-Sparse-Dense Training for Deep Neural Networks,3,"[""Deep learning""]",0.517049431325532,1,7.0,2017, deep_learning
Hyp-JJJRW,Style Memory: Making a Classifier Network Generative,3,"[""neural networks"", ""autoencoder"", ""generative"", ""feed-back""]",0.5646885798684289,0,3.3333333333333335,2018, neural_networks autoencoder generative feed_back
Hyp3i2xRb,Overcoming the vanishing gradient problem in plain recurrent networks,3,"[""vanishing gradient descent"", ""recurrent neural networks"", ""identity mapping""]",0.504593544627852,0,4.333333333333333,2018, vanishing_gradient_descent recurrent_neural_networks identity_mapping
HypkN9yRW,DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer,3,"[""CLEVR"", ""VQA"", ""Visual Question Answering"", ""Neural Programmer""]",0.5351857917912999,0,5.333333333333333,2018, clevr vqa visual_question_answering neural_programmer
Hyq4yhile,Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning,3,"[""Deep learning"", ""Reinforcement Learning"", ""Transfer Learning""]",0.45707557036829677,1,6.333333333333333,2017, deep_learning reinforcement_learning transfer_learning
HyrCWeWCb,Trust-PCL: An Off-Policy Trust Region Method for Continuous Control,3,"[""Reinforcement learning""]",0.40290847103046173,0,5.333333333333333,2018, reinforcement_learning
HysBZSqlx,Playing SNES in the Retro Learning Environment,3,"[""Reinforcement Learning"", ""Deep learning"", ""Games""]",0.5099528678453428,1,5.333333333333333,2017, reinforcement_learning deep_learning games
HytSvlWRZ,Subspace Network: Deep Multi-Task Censored Regression for Modeling Neurodegenerative Diseases,3,"[""subspace"", ""censor"", ""multi-task"", ""deep network""]",0.45434712899820473,0,4.666666666666667,2018, subspace censor multi_task deep_network
HyunpgbR-,Structured Exploration via Hierarchical Variational Policy Networks,3,"[""Deep Reinforcement Learning"", ""Structured Variational Inference"", ""Multi-agent Coordination"", ""Multi-agent Learning""]",0.4350795120388545,0,5.333333333333333,2018, deep_reinforcement_learning structured_variational_inference multi_agent_coordination multi_agent_learning
Hyvw0L9el,Generating Interpretable Images with Controllable Structure,3,"[""Deep learning"", ""Computer vision"", ""Multi-modal learning"", ""Natural language processing""]",0.5399130556061293,1,6.0,2017, deep_learning computer_vision multi_modal_learning natural_language_processing
HyxQzBceg,Deep Variational Information Bottleneck,3,"[""Theory"", ""Computer vision"", ""Deep learning"", ""Supervised Learning""]",0.4516255952565551,1,6.333333333333333,2017, theory computer_vision deep_learning supervised_learning
HyxjwgbRZ,Convergence rate of sign stochastic gradient descent for non-convex functions,3,"[""sign"", ""stochastic"", ""gradient"", ""non-convex"", ""optimization"", ""gradient"", ""quantization"", ""convergence"", ""rate""]",0.5250932745754099,0,4.333333333333333,2018, sign stochastic gradient non_convex optimization gradient quantization convergence rate
HyyP33gAZ,Activation Maximization Generative Adversarial Nets,2,"[""Generative Adversarial Nets"", ""GANs"", ""Evaluation Metrics"", ""Generative Model"", ""Deep Learning"", ""Adversarial Learning"", ""Inception Score"", ""AM Score""]",0.3784487636772187,0,6.666666666666667,2018, generative_adversarial_nets gans evaluation_metrics generative_model deep_learning adversarial_learning inception_score am_score
HyydRMZC-,Spatially Transformed Adversarial Examples,2,"[""adversarial examples"", ""spatial transformation""]",0.3621242964592959,0,7.666666666666667,2018, adversarial_examples spatial_transformation
HyzbhfWRW,Learn to Pay Attention,3,"[""deep learning"", ""attention-aware representations"", ""image classification"", ""weakly supervised segmentation"", ""domain shift"", ""classifier generalisation"", ""robustness to adversarial attack""]",0.5023926413876106,0,5.666666666666667,2018, deep_learning attention_aware_representations image_classification weakly_supervised_segmentation domain_shift classifier_generalisation robustness_to_adversarial_attack
S11KBYclx,Learning Curve Prediction with Bayesian Neural Networks,3,"[""Deep learning"", ""Applications""]",0.5020102400633266,1,7.0,2017, deep_learning applications
S1347ot3b,Exploring Sentence Vectors Through Automatic Summarization,3,"[""Sentence Vectors"", ""Vector Semantics"", ""Automatic Summarization""]",0.5847725986173983,0,2.3333333333333335,2018, sentence_vectors vector_semantics automatic_summarization
S13wCE9xx,Riemannian Optimization for Skip-Gram Negative Sampling,3,"[""Natural language processing"", ""Unsupervised Learning""]",0.5081298152256584,1,5.0,2017, natural_language_processing unsupervised_learning
S14EogZAZ,Acquiring Target Stacking Skills by Goal-Parameterized Deep Reinforcement Learning,3,[],0.44757744430343616,0,4.666666666666667,2018,
S1680_1Rb,CAYLEYNETS: SPECTRAL GRAPH CNNS WITH COMPLEX RATIONAL FILTERS,3,"[""Deep Learning"", ""Spectral Graph Convolutional Neural Networks""]",0.51514967027626,0,6.0,2018, deep_learning spectral_graph_convolutional_neural_networks
S16FPMgRZ,Tensor Contraction & Regression Networks,3,"[""tensor contraction"", ""tensor regression"", ""network compression"", ""deep neural networks""]",0.489768666220081,0,4.666666666666667,2018, tensor_contraction tensor_regression network_compression deep_neural_networks
S17mtzbRb,Forced Apart: Discovering Disentangled Representations Without Exhaustive Labels,3,"[""learning representation"", ""clustering"", ""loss""]",0.4648964260889307,0,4.666666666666667,2018, learning_representation clustering loss
S18Su--CW,Thermometer Encoding: One Hot Way To Resist Adversarial Examples,3,"[""Adversarial examples"", ""robust neural networks""]",0.4389579087973501,0,6.0,2018, adversarial_examples robust_neural_networks
S191YzbRZ,Prototype Matching Networks for Large-Scale Multi-label  Genomic Sequence Classification,3,"[""bioinformatics"", ""multi-label classification"", ""matching networks"", ""prototypes"", ""memory networks"", ""attention""]",0.492265504109731,0,5.0,2018, bioinformatics multi_label_classification matching_networks prototypes memory_networks attention
S19dR9x0b,Alternating Multi-bit Quantization for Recurrent Neural Networks,3,"[""Alternating Minimization"", ""Quantized Recurrent Neural Network"", ""Binary Search Tree""]",0.5922486080672232,0,7.333333333333333,2018, alternating_minimization quantized_recurrent_neural_network binary_search_tree
S19eAF9ee,Structured Sequence Modeling with Graph Convolutional Recurrent Networks,3,"[""Structured prediction""]",0.5592486206691052,1,4.0,2017, structured_prediction
S1AG8zYeg,Sentence Ordering using Recurrent Neural Networks,4,"[""Natural language processing"", ""Deep learning"", ""Applications""]",0.6056593514524791,1,6.333333333333333,2017, natural_language_processing deep_learning applications
S1ANxQW0b,Maximum a Posteriori Policy Optimisation,3,"[""Reinforcement Learning"", ""Variational Inference"", ""Control""]",0.41150971116382246,0,6.0,2018, reinforcement_learning variational_inference control
S1Auv-WRZ,Data Augmentation Generative Adversarial Networks,3,[],0.4275687768983627,0,6.333333333333333,2018,
S1Bb3D5gg,Learning End-to-End Goal-Oriented Dialog,3,[],0.4735573613765083,1,7.666666666666667,2017,
S1Bm3T_lg,Compositional Kernel Machines,3,"[""Computer vision"", ""Supervised Learning""]",0.5718160944998483,1,5.25,2017, computer_vision supervised_learning
S1CChZ-CZ,Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,3,"[""machine translation"", ""paraphrasing"", ""question answering"", ""reinforcement learning"", ""agents""]",0.5191468208168484,0,7.0,2018, machine_translation paraphrasing question_answering reinforcement_learning agents
S1D8MPxA-,Viterbi-based Pruning for Sparse Matrix with Fixed and High Index Compression Ratio,3,"[""pruning"", ""sparse matrix"", ""memory footprint"", ""model size"", ""model compression""]",0.523188014320704,0,6.333333333333333,2018, pruning sparse_matrix memory_footprint model_size model_compression
S1DWPP1A-,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,3,"[""exploration; autonomous goal setting; diversity; unsupervised learning; deep neural network""]",0.524688192110852,0,6.666666666666667,2018, exploration;_autonomous_goal_setting;_diversity;_unsupervised_learning;_deep_neural_network
S1Dh8Tg0-,Fix your classifier: the marginal value of training the last weight layer,3,[],0.5508612398756862,0,6.0,2018,
S1EfylZ0Z,Anomaly Detection with Generative Adversarial Networks,3,"[""Anomaly Detection"", ""Generative Adversarial Networks"", ""Deep Learning"", ""Inverse Problems""]",0.4272392815779436,0,4.666666666666667,2018, anomaly_detection generative_adversarial_networks deep_learning inverse_problems
S1Euwz-Rb,Compositional Attention Networks for Machine Reasoning,3,"[""Deep Learning"", ""Reasoning"", ""Memory"", ""Attention"", ""VQA"", ""CLEVR"", ""Recurrent Neural Networks"", ""Module Networks"", ""Compositionality""]",0.5640487086057077,0,6.666666666666667,2018, deep_learning reasoning memory attention vqa clevr recurrent_neural_networks module_networks compositionality
S1EwLkW0W,"Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",3,"[""Stochastic Optimization"", ""Deep Learning""]",0.5148478933205227,0,4.666666666666667,2018, stochastic_optimization deep_learning
S1EzRgb0W,Explaining the Mistakes of Neural Networks with Latent Sympathetic Examples,3,"[""Deep learning"", ""Adversarial Examples"", ""Difference Target Propagation"", ""Generative Modelling"", ""Classifiers"", ""Explaining"", ""Sympathetic Examples""]",0.47592001937554484,0,4.666666666666667,2018, deep_learning adversarial_examples difference_target_propagation generative_modelling classifiers explaining sympathetic_examples
S1FFLWWCZ,"LSD-Net: Look, Step and Detect for Joint Navigation and Multi-View Recognition with Deep Reinforcement Learning",3,[],0.5570220786172307,0,4.333333333333333,2018,
S1FQEfZA-,A Classification-Based Perspective on GAN Distributions,3,"[""Generative adversarial networks"", ""classification"", ""benchmark"", ""mode collapse"", ""diversity""]",0.44671162873835635,0,4.666666666666667,2018, generative_adversarial_networks classification benchmark mode_collapse diversity
S1GDXzb0b,Model-based imitation learning from state trajectories,3,"[""Model based reinforcement learning"", ""Imitation learning"", ""dynamics model""]",0.45187103328940975,0,4.666666666666667,2018, model_based_reinforcement_learning imitation_learning dynamics_model
S1GUgxgCW,Latent Topic Conversational Models,3,"[""conversational modeling"", ""dialogue"", ""chitchat"", ""open-domain dialogue"", ""topic model"", ""neural variational inference"", ""human evaluation"", ""latent variable model"", ""gaussian reparameterisation trick""]",0.5430688763661725,0,5.0,2018, conversational_modeling dialogue chitchat open_domain_dialogue topic_model neural_variational_inference human_evaluation latent_variable_model gaussian_reparameterisation_trick
S1HEBe_Jl,Learning to Protect Communications with Adversarial Neural Cryptography,2,[],0.3753041832469353,1,5.0,2017,
S1HcOI5le,OMG: Orthogonal Method of Grouping With Application of K-Shot Learning,3,[],0.47840605115387186,1,4.0,2017,
S1HlA-ZAZ,The Kanerva Machine: A Generative Distributed Memory,3,"[""memory"", ""generative model"", ""inference"", ""neural network"", ""hierarchical model""]",0.5380507997836846,0,6.666666666666667,2018, memory generative_model inference neural_network hierarchical_model
S1J0E-71l,Surprisal-Driven Feedback in Recurrent Networks,3,"[""Unsupervised Learning"", ""Applications"", ""Deep learning""]",0.517601492912024,1,3.3333333333333335,2017, unsupervised_learning applications deep_learning
S1J2ZyZ0Z,Interpretable Counting for Visual Question Answering,3,"[""Counting"", ""VQA"", ""Object detection""]",0.5383294063580648,0,6.666666666666667,2018, counting vqa object_detection
S1JG13oee,b-GAN: Unified Framework of Generative Adversarial Networks,3,"[""Deep learning"", ""Unsupervised Learning""]",0.4171234615937054,1,5.0,2017, deep_learning unsupervised_learning
S1JHhv6TW,Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions,3,"[""Deep Learning"", ""Expressive Efficiency"", ""Dilated Convolutions"", ""Tensor Decompositions""]",0.5218284431125452,0,8.0,2018, deep_learning expressive_efficiency dilated_convolutions tensor_decompositions
S1Jhfftgx,Enforcing constraints on outputs with unconstrained inference,3,"[""Natural language processing"", ""Structured prediction"", ""Deep learning""]",0.5345609496122691,1,3.3333333333333335,2017, natural_language_processing structured_prediction deep_learning
S1LVSrcge,Variable Computation in Recurrent Neural Networks,3,"[""Natural language processing"", ""Deep learning""]",0.5948399480685862,1,6.0,2017, natural_language_processing deep_learning
S1LXVnxRb,Cross-Corpus Training with TreeLSTM for the Extraction of Biomedical Relationships from Text,3,"[""Relationships Extraction"", ""Deep Learning"", ""TreeLSTM"", ""NLP""]",0.4899056631609537,0,4.0,2018, relationships_extraction deep_learning treelstm nlp
S1NHaMW0b,ShakeDrop regularization,3,[],0.4426159335671568,0,4.333333333333333,2018,
S1OufnIlx,Adversarial examples in the physical world,3,"[""Supervised Learning"", ""Computer vision""]",0.4562207355656006,1,5.666666666666667,2017, supervised_learning computer_vision
S1Ow_e-Rb,How do deep convolutional neural networks learn from raw audio waveforms?,3,"[""Convolutional neural networks"", ""Audio processing"", ""Speech processing""]",0.5305069335712046,0,2.6666666666666665,2018, convolutional_neural_networks audio_processing speech_processing
S1PWi_lC-,Multi-task Learning on MNIST Image Datasets,3,"[""multi-task learning"", ""MNIST"", ""image recognition""]",0.525411239754974,0,4.666666666666667,2018, multi_task_learning mnist image_recognition
S1Q79heRW,Unsupervised Learning of Entailment-Vector Word Embeddings,3,"[""word embeddings"", ""natural language semantics"", ""entailment"", ""unsupervised learning"", ""distributional semantics""]",0.5221897433456414,0,4.333333333333333,2018, word_embeddings natural_language_semantics entailment unsupervised_learning distributional_semantics
S1QefL5ge,Online Structure Learning for Sum-Product Networks with Gaussian Leaves,3,"[""Unsupervised Learning"", ""Deep learning""]",0.507231143667675,1,4.666666666666667,2017, unsupervised_learning deep_learning
S1RP6GLle,Amortised MAP Inference for Image Super-resolution,3,"[""Theory"", ""Computer vision"", ""Deep learning""]",0.5191226533576565,1,8.0,2017, theory computer_vision deep_learning
S1TER2oll,FILTER SHAPING FOR CONVOLUTIONAL NEURAL NETWORKS,3,[],0.4959594103678072,1,6.666666666666667,2017,
S1TgE7WR-,Covariant Compositional Networks For Learning Graphs,3,"[""graph neural networks"", ""message passing"", ""label propagation"", ""high order representation""]",0.5130653286422104,0,5.333333333333333,2018, graph_neural_networks message_passing label_propagation high_order_representation
S1VaB4cex,FractalNet: Ultra-Deep Neural Networks without Residuals,3,[],0.5178875239073433,1,5.666666666666667,2017,
S1WRibb0Z,Expressive power of recurrent neural networks,3,"[""Recurrent Neural Networks"", ""Tensor Train"", ""tensor decompositions"", ""expressive power""]",0.5288244606395752,0,6.0,2018, recurrent_neural_networks tensor_train tensor_decompositions expressive_power
S1X7nhsxl,Improving Generative Adversarial Networks with Denoising Feature Matching,3,"[""Deep learning"", ""Unsupervised Learning""]",0.4330411647412469,1,6.666666666666667,2017, deep_learning unsupervised_learning
S1XXq6lRW,Zero-shot Cross Language Text Classification,3,"[""Cross Language Text Classification"", ""Neural Networks"", ""Machine Learning""]",0.4635870465926512,0,3.0,2018, cross_language_text_classification neural_networks machine_learning
S1XolQbRW,Model compression via distillation and quantization,3,"[""quantization"", ""distillation"", ""model compression""]",0.5411195062113824,0,7.0,2018, quantization distillation model_compression
S1Y0td9ee,Shift Aggregate Extract Networks,3,"[""Supervised Learning""]",0.47020331360628514,1,4.333333333333333,2017, supervised_learning
S1Y7OOlRZ,Massively Parallel Hyperparameter Tuning,3,"[""parallel hyperparameter tuning"", ""deep learning""]",0.5652070042461393,0,5.333333333333333,2018, parallel_hyperparameter_tuning deep_learning
S1_pAu9xl,Trained Ternary Quantization,3,"[""Deep learning""]",0.5173063811252825,1,6.25,2017, deep_learning
S1c2cvqee,Designing Neural Network Architectures using Reinforcement Learning,3,"[""Deep learning"", ""Reinforcement Learning""]",0.4746640326718508,1,6.0,2017, deep_learning reinforcement_learning
S1cZsf-RW,WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling,3,[],0.47304349945954915,0,5.666666666666667,2018,
S1dIzvclg,A recurrent neural network without chaos,3,[],0.5882910491466428,1,7.333333333333333,2017,
S1di0sfgl,Hierarchical Multiscale Recurrent Neural Networks,3,"[""Natural language processing"", ""Deep learning""]",0.5639631287085876,1,7.666666666666667,2017, natural_language_processing deep_learning
S1fHmlbCW,Neural Networks for irregularly observed continuous-time Stochastic Processes,4,"[""Deep Learning"", ""Stochastic Processes"", ""Time Series Analysis""]",0.6023740283188443,0,4.0,2018, deep_learning stochastic_processes time_series_analysis
S1fcY-Z0-,Bayesian Hypernetworks,3,"[""variational inference"", ""bayesian inference"", ""deep networks""]",0.5113751075236052,0,6.0,2018, variational_inference bayesian_inference deep_networks
S1fduCl0b,Lifelong Generative Modeling,3,"[""Lifelong"", ""Generative Modeling"", ""Variational Autoencoder"", ""VAE"", ""Catastrophic Interference""]",0.4395997668330324,0,5.666666666666667,2018, lifelong generative_modeling variational_autoencoder vae catastrophic_interference
S1j4RqYxg,Efficient Calculation of Polynomial Features on Sparse Matrices,4,"[""Supervised Learning""]",0.6001062136881196,1,3.0,2017, supervised_learning
S1jBcueAb,Depthwise Separable Convolutions for Neural Machine Translation,4,"[""convolutions"", ""neural machine translation""]",0.6012729983788286,0,6.333333333333333,2018, convolutions neural_machine_translation
S1jE5L5gl,The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables,3,"[""Deep learning"", ""Unsupervised Learning"", ""Structured prediction""]",0.4847182353173691,1,8.0,2017, deep_learning unsupervised_learning structured_prediction
S1jmAotxg,Stick-Breaking Variational Autoencoders,3,"[""Deep learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",0.47725462680333197,1,6.666666666666667,2017, deep_learning unsupervised_learning semi_supervised_learning
S1lN69AT-,"To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression",3,"[""pruning"", ""model sparsity"", ""model compression"", ""deep learning""]",0.46276933067169634,0,5.0,2018, pruning model_sparsity model_compression deep_learning
S1m6h21Cb,The Cramer Distance as a Solution to Biased Wasserstein Gradients,3,"[""Probability metrics"", ""Wasserstein metric"", ""stochastic gradient descent"", ""GANs""]",0.45719455111103835,0,5.333333333333333,2018, probability_metrics wasserstein_metric stochastic_gradient_descent gans
S1nQvfgA-,Semantically Decomposing the Latent Spaces of Generative Adversarial Networks,3,"[""disentangled representations"", ""generative adversarial networks"", ""generative modeling"", ""image synthesis""]",0.47017503457211035,0,6.333333333333333,2018, disentangled_representations generative_adversarial_networks generative_modeling image_synthesis
S1oWlN9ll,Loss-aware Binarization of Deep Networks,3,"[""Deep learning"", ""Applications"", ""Optimization""]",0.49767715351804653,1,7.0,2017, deep_learning applications optimization
S1pWFzbAW,Weightless: Lossy Weight Encoding For Deep Neural Network Compression,3,"[""Deep Neural Network"", ""Compression"", ""Sparsity""]",0.5181958736160887,0,5.333333333333333,2018, deep_neural_network compression sparsity
S1q_Cz-Cb,Training Neural Machines with Partial Traces,3,"[""Neural Abstract Machines"", ""Neural Turing Machines"", ""Neural Random Access Machines"", ""Program Synthesis"", ""Program Induction""]",0.5147673944722175,0,4.333333333333333,2018, neural_abstract_machines neural_turing_machines neural_random_access_machines program_synthesis program_induction
S1sRrN-CW,Revisiting Knowledge Base Embedding as Tensor Decomposition,3,"[""Knowledge base embedding""]",0.47282729035352083,0,3.6666666666666665,2018, knowledge_base_embedding
S1sqHMZCb,NerveNet: Learning Structured Policy with Graph Neural Networks,3,"[""reinforcement learning"", ""transfer learning"", ""graph neural network""]",0.4357610086463963,0,6.666666666666667,2018, reinforcement_learning transfer_learning graph_neural_network
S1tWRJ-R-,Joint autoencoders: a flexible meta-learning framework,3,"[""transfer learning"", ""domain adaptation"", ""unsupervised learning"", ""autoencoders"", ""multi-task learning""]",0.5127053704670119,0,4.666666666666667,2018, transfer_learning domain_adaptation unsupervised_learning autoencoders multi_task_learning
S1uxsye0Z,Adaptive Dropout with Rademacher Complexity Regularization,3,"[""model complexity"", ""regularization"", ""deep learning"", ""model generalization"", ""adaptive dropout""]",0.43717312517141393,0,6.333333333333333,2018, model_complexity regularization deep_learning model_generalization adaptive_dropout
S1v4N2l0-,Unsupervised Representation Learning by Predicting Image Rotations,3,"[""Unsupervised representation learning""]",0.5716602621809211,0,6.0,2018, unsupervised_representation_learning
S1viikbCW,TCAV: Relative concept importance testing with Linear Concept Activation Vectors,3,[],0.47312407422906105,0,4.0,2018,
S1vuO-bCW,Leave no Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning,2,"[""manual reset"", ""continual learning"", ""reinforcement learning"", ""safety""]",0.38064774643147214,0,6.25,2018, manual_reset continual_learning reinforcement_learning safety
S1vyujVye,Deep unsupervised learning through spatial contrasting,3,"[""Unsupervised Learning"", ""Deep learning"", ""Computer vision""]",0.5311722041226971,1,6.0,2017, unsupervised_learning deep_learning computer_vision
S1xDcSR6W,Hybed: Hyperbolic Neural Graph Embedding,3,"[""embeddings"", ""hyperbolic space"", ""neural networks"", ""geometry""]",0.4637671177714858,0,5.0,2018, embeddings hyperbolic_space neural_networks geometry
S1xh5sYgx,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,3,"[""Computer vision"", ""Deep learning""]",0.5038201795016214,1,6.333333333333333,2017, computer_vision deep_learning
SJ-C6JbRW,Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,3,[],0.5822192365431186,0,7.333333333333333,2018,
SJ-uGHcee,Efficient iterative policy optimization,3,[],0.45166082447664213,1,5.0,2017,
SJ19eUg0-,BLOCK-DIAGONAL HESSIAN-FREE OPTIMIZATION FOR TRAINING NEURAL NETWORKS,3,"[""deep learning"", ""second-order optimization"", ""hessian free""]",0.5014035337330652,0,5.333333333333333,2018, deep_learning second_order_optimization hessian_free
SJ1Xmf-Rb,FearNet: Brain-Inspired Model for Incremental Learning,3,"[""Incremental Learning"", ""Lifelong Learning"", ""Supervised Learning"", ""Catastrophic Forgetting"", ""Brain-Inspired"", ""Neural Networks""]",0.4889400666887427,0,6.666666666666667,2018, incremental_learning lifelong_learning supervised_learning catastrophic_forgetting brain_inspired neural_networks
SJ1fQYlCZ,Training with Growing Sets: A Simple Alternative to Curriculum Learning and Self Paced Learning,3,"[""Neural networks"", ""Curriculum learning"", ""Self paced learning""]",0.5098530169217609,0,4.666666666666667,2018, neural_networks curriculum_learning self_paced_learning
SJ1nzBeA-,Multi-Task Learning for Document Ranking and Query Suggestion,3,"[""Multitask Learning"", ""Document Ranking"", ""Query Suggestion""]",0.47148706352502767,0,5.666666666666667,2018, multitask_learning document_ranking query_suggestion
SJ25-B5eg,The Neural Noisy Channel,3,"[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning""]",0.5624993638231416,1,6.666666666666667,2017, natural_language_processing deep_learning semi_supervised_learning
SJ3dBGZ0Z,LSH Softmax: Sub-Linear Learning and Inference of the Softmax Layer in Deep Architectures,3,"[""LSH"", ""softmax"", ""deep"", ""learning"", ""sub"", ""linear"", ""efficient"", ""GPU""]",0.5319629542738388,0,5.0,2018, lsh softmax deep learning sub linear efficient gpu
SJ3rcZcxl,Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic,2,"[""Deep learning"", ""Reinforcement Learning""]",0.3876338446370972,1,7.25,2017, deep_learning reinforcement_learning
SJ60SbW0b,Modeling Latent Attention Within Neural Networks,3,"[""deep learning"", ""neural network"", ""attention"", ""attention mechanism"", ""interpretability"", ""visualization""]",0.5440363145440995,0,5.333333333333333,2018, deep_learning neural_network attention attention_mechanism interpretability visualization
SJ6yPD5xg,Reinforcement Learning with Unsupervised Auxiliary Tasks,3,[],0.4849409248958019,1,7.666666666666667,2017,
SJ71VXZAZ,Learning To Generate Reviews and Discovering Sentiment,3,"[""unsupervised learning"", ""representation learning"", ""deep learning""]",0.5381836509244347,0,3.3333333333333335,2018, unsupervised_learning representation_learning deep_learning
SJ8BZTjeg,Unsupervised Learning Using Generative Adversarial Training And Clustering,3,[],0.4195972870136672,1,3.0,2017,
SJ8M9yup-,On Optimality Conditions for Auto-Encoder Signal Recovery,3,"[""Auto Encoder"", ""Signal Recovery"", ""Sparse Coding""]",0.4911300534456937,0,4.666666666666667,2018, auto_encoder signal_recovery sparse_coding
SJA7xfb0b,Sobolev GAN,3,"[""GAN theory"", ""Integral Probability Metrics"", ""elliptic PDE and diffusion"", ""GAN for discrete sequences"", ""semi-supervised learning.""]",0.44985274612316306,0,6.75,2018, gan_theory integral_probability_metrics elliptic_pde_and_diffusion gan_for_discrete_sequences semi_supervised_learning.
SJAr0QFxe,Demystifying ResNet,3,"[""Deep learning"", ""Optimization"", ""Theory""]",0.48400705003598404,1,4.333333333333333,2017, deep_learning optimization theory
SJBr9Mcxl,Understanding trained CNNs by indexing neuron selectivity,3,"[""Computer vision"", ""Deep learning""]",0.5780628687244179,1,5.666666666666667,2017, computer_vision deep_learning
SJCPLLpaW,Exploring the Hidden Dimension in Accelerating Convolutional Neural Networks,3,"[""Parallelism of Convolutional Neural Networks"", ""Accelerating Convolutional Neural Networks""]",0.5606626582374548,0,5.333333333333333,2018, parallelism_of_convolutional_neural_networks accelerating_convolutional_neural_networks
SJCq_fZ0Z,Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks,3,"[""recurrent neural networks"", ""long-term dependencies"", ""back-propagation through time"", ""truncated back-propagation"", ""biological inspiration"", ""self-attention""]",0.5179443033550991,0,6.0,2018, recurrent_neural_networks long_term_dependencies back_propagation_through_time truncated_back_propagation biological_inspiration self_attention
SJCscQcge,Simple Black-Box Adversarial Perturbations for Deep Networks,3,"[""Computer vision"", ""Deep learning""]",0.41909031907764155,1,4.0,2017, computer_vision deep_learning
SJD8YjCpW,Balanced and Deterministic Weight-sharing Helps Network Performance,3,"[""Weight-sharing"", ""Weight sharing"", ""Weight tying"", ""neural networks"", ""entropy"", ""hash function"", ""hash table"", ""balance"", ""sparse"", ""sparsity"", ""hashednets""]",0.4962345738819726,0,4.0,2018, weight_sharing weight_sharing weight_tying neural_networks entropy hash_function hash_table balance sparse sparsity hashednets
SJDJNzWAZ,Time-Dependent Representation for Neural Event Sequence Prediction,3,"[""Neural sequence prediction"", ""Embedding"", ""LSTM"", ""Regularization""]",0.5694062779931522,0,4.333333333333333,2018, neural_sequence_prediction embedding lstm regularization
SJDYgPgCZ,Understanding Local Minima in Neural Networks by Loss Surface Decomposition,3,"[""neural network"", ""local minima"", ""global minima"", ""saddle point"", ""optimization"", ""loss surface"", ""rectified linear unit"", ""loss surface decomposition"", ""gradient descent""]",0.47671839781121056,0,4.333333333333333,2018, neural_network local_minima global_minima saddle_point optimization loss_surface rectified_linear_unit loss_surface_decomposition gradient_descent
SJDaqqveg,An Actor-Critic Algorithm for Sequence Prediction,3,"[""Natural language processing"", ""Deep learning"", ""Reinforcement Learning"", ""Structured prediction""]",0.47191880512036294,1,6.666666666666667,2017, natural_language_processing deep_learning reinforcement_learning structured_prediction
SJFM0ZWCb,Deep Temporal Clustering: Fully unsupervised learning of time-domain features,3,"[""Unsupervised deep learning"", ""Temporal clustering"", ""Event Visualization""]",0.5275773495841146,0,4.0,2018, unsupervised_deep_learning temporal_clustering event_visualization
SJGCiw5gl,Pruning Convolutional Neural Networks for Resource Efficient Inference,3,"[""Deep learning"", ""Transfer Learning""]",0.4857261533042265,1,7.333333333333333,2017, deep_learning transfer_learning
SJGPL9Dex,Understanding Trainable Sparse Coding with Matrix Factorization,3,"[""Theory"", ""Deep learning"", ""Optimization""]",0.539407964945486,1,6.333333333333333,2017, theory deep_learning optimization
SJIA6ZWC-,Stochastic Hyperparameter Optimization through Hypernetworks,3,"[""hypernetworks"", ""hyperparameter optimization"", ""metalearning"", ""neural networks"", ""Bayesian optimization"", ""game theory"", ""optimization""]",0.44225898784903633,0,6.0,2018, hypernetworks hyperparameter_optimization metalearning neural_networks bayesian_optimization game_theory optimization
SJICXeWAb,Depth separation and weight-width trade-offs for sigmoidal neural networks,3,"[""depth separation"", ""neural networks"", ""weights-width trade-off""]",0.5391448363733176,0,4.666666666666667,2018, depth_separation neural_networks weights_width_trade_off
SJIMPr9eg,Boosted Residual Networks,3,[],0.5373735579852968,1,3.3333333333333335,2017,
SJJKxrsgl,Emergence of foveal image sampling from learning to attend in visual scenes,3,"[""Computer vision"", ""Deep learning"", ""Supervised Learning""]",0.530662578072894,1,5.666666666666667,2017, computer_vision deep_learning supervised_learning
SJJN38cge,Distributed Transfer Learning for Deep Convolutional Neural Networks by Basic Probability Assignment,3,"[""Deep learning"", ""Transfer Learning"", ""Supervised Learning"", ""Optimization""]",0.426735990699546,1,3.3333333333333335,2017, deep_learning transfer_learning supervised_learning optimization
SJJQVZW0b,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning,3,"[""Hierarchical Policy"", ""Interpretable Policy"", ""Deep Reinforcement Learning"", ""Multi-task Reinforcement Learning"", ""Skill Acquisition"", ""Language Grounding""]",0.4725942378931097,0,6.0,2018, hierarchical_policy interpretable_policy deep_reinforcement_learning multi_task_reinforcement_learning skill_acquisition language_grounding
SJJinbWRZ,Model-Ensemble Trust-Region Policy Optimization,2,"[""model-based reinforcement learning"", ""model ensemble"", ""reinforcement learning"", ""model bias""]",0.39429707418517773,0,6.666666666666667,2018, model_based_reinforcement_learning model_ensemble reinforcement_learning model_bias
SJJySbbAZ,Training GANs with Optimism,3,"[""GANs"", ""Optimistic Mirror Decent"", ""Cycling"", ""Last Iterate Convergence"", ""Optimistic Adam""]",0.4069308631092504,0,7.0,2018, gans optimistic_mirror_decent cycling last_iterate_convergence optimistic_adam
SJLlmG-AZ,Understanding image motion with group representations ,3,"[""vision"", ""motion"", ""recurrent neural networks"", ""self-supervised learning"", ""unsupervised learning"", ""group theory""]",0.5875010754479741,0,5.333333333333333,2018, vision motion recurrent_neural_networks self_supervised_learning unsupervised_learning group_theory
SJLy_SxC-,Log-DenseNet: How to Sparsify a DenseNet,3,"[""DenseNet"", ""sparse shortcut connections"", ""network architecture"", ""scene parsing"", ""image classification""]",0.497950813312626,0,5.666666666666667,2018, densenet sparse_shortcut_connections network_architecture scene_parsing image_classification
SJMGPrcle,Learning to Navigate in Complex Environments,3,"[""Deep learning"", ""Reinforcement Learning""]",0.44233067890189887,1,6.333333333333333,2017, deep_learning reinforcement_learning
SJNDWNOlg,What Is the Best Practice for CNNs Applied to Visual Instance Retrieval?,3,"[""Computer vision"", ""Deep learning""]",0.514879030338924,1,4.0,2017, computer_vision deep_learning
SJOl4DlCZ,Classifier-to-Generator Attack: Estimation of Training Data Distribution from Classifier,3,"[""Security"", ""Privacy"", ""Model Publication"", ""Generative Adversarial Networks""]",0.48404894799793935,0,5.0,2018, security privacy model_publication generative_adversarial_networks
SJPpHzW0-,Influence-Directed Explanations for Deep Convolutional Networks,3,"[""Deep neural networks"", ""convolutional networks"", ""influence measures"", ""explanations""]",0.5299480866036281,0,4.333333333333333,2018, deep_neural_networks convolutional_networks influence_measures explanations
SJQHjzZ0-,Quantitatively Evaluating GANs With Divergences Proposed for Training,3,"[""Generative adversarial networks""]",0.4722678410712949,0,6.0,2018, generative_adversarial_networks
SJQNqLFgl,Deep Convolutional Neural Network Design Patterns,3,[],0.549751328383187,1,3.3333333333333335,2017,
SJQO7UJCW,Adversarial Learning for Semi-Supervised Semantic Segmentation,2,"[""semantic segmentation"", ""adversarial learning"", ""semi-supervised learning"", ""self-taught learning""]",0.38723867922236377,0,5.0,2018, semantic_segmentation adversarial_learning semi_supervised_learning self_taught_learning
SJRpRfKxx,Recurrent Mixture Density Network for Spatiotemporal Visual Attention,3,"[""Computer vision"", ""Deep learning"", ""Applications""]",0.5109173463581299,1,6.333333333333333,2017, computer_vision deep_learning applications
SJSVuReCZ,SHADE: SHAnnon DEcay Information-Based Regularization for Deep Learning,3,[],0.45461828141229055,0,5.0,2018,
SJTB5GZCb,Extending the Framework of Equilibrium Propagation to General Dynamics,3,"[""Deep Learning"", ""Backpropagation"", ""Fixed Point Recurrent Neural Network"", ""Biologically Plausible Learning"", ""Feedback Alignment"", ""Dynamical System"", ""Gradient-Free Optimization""]",0.5046848274160819,0,4.333333333333333,2018, deep_learning backpropagation fixed_point_recurrent_neural_network biologically_plausible_learning feedback_alignment dynamical_system gradient_free_optimization
SJTQLdqlg,Learning to Remember Rare Events,3,"[""Deep learning""]",0.5357753511687868,1,7.0,2017, deep_learning
SJU4ayYgl,Semi-Supervised Classification with Graph Convolutional Networks,3,"[""Deep learning"", ""Semi-Supervised Learning""]",0.5269636288743792,1,7.0,2017, deep_learning semi_supervised_learning
SJUX_MWCZ,Predict Responsibly: Increasing Fairness by Learning to Defer,2,"[""Fairness"", ""IDK"", ""Calibration"", ""Automated decision-making"", ""Transparency"", ""Accountability""]",0.37821795605460035,0,5.0,2018, fairness idk calibration automated_decision_making transparency accountability
SJUdkecgx,,3,[],0.48851967072628755,1,6.0,2017,
SJVHY9lCb,"Learning to Select: Problem, Solution, and Applications",3,"[""Selection Problem"", ""Job Dispatching"", ""Convolution Neural Network""]",0.4492967485305948,0,4.0,2018, selection_problem job_dispatching convolution_neural_network
SJZ2Mf-0-,Adaptive Memory Networks,3,"[""Memory Networks"", ""Dynamic Networks"", ""Faster Inference"", ""Reasoning"", ""QA""]",0.5065124962124894,0,5.333333333333333,2018, memory_networks dynamic_networks faster_inference reasoning qa
SJZAb5cel,A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks,3,"[""Natural language processing"", ""Deep learning""]",0.5625777549929367,1,4.666666666666667,2017, natural_language_processing deep_learning
SJZsR7kCZ,Iterative Deep Compression : Compressing Deep Networks for Classification and Semantic Segmentation,3,[],0.46452153320025036,0,5.0,2018,
SJ_QCYqle,Semi-Supervised Detection of Extreme Weather Events in Large Climate Datasets,2,"[""Semi-Supervised Learning"", ""Applications"", ""Computer vision""]",0.38921644629334173,1,5.333333333333333,2017, semi_supervised_learning applications computer_vision
SJa1Nk10b,Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy,3,"[""anytime"", ""neural network"", ""adaptive prediction"", ""budgeted prediction""]",0.5134972749352036,0,5.666666666666667,2018, anytime neural_network adaptive_prediction budgeted_prediction
SJa9iHgAZ,Residual Connections Encourage Iterative Inference,3,"[""residual network"", ""iterative inference"", ""deep learning""]",0.45652607162189385,0,6.0,2018, residual_network iterative_inference deep_learning
SJaP_-xAb,Deep Learning with Logged Bandit Feedback,3,"[""Batch Learning from Bandit Feedback"", ""Counterfactual Learning""]",0.47604925146664856,0,7.0,2018, batch_learning_from_bandit_feedback counterfactual_learning
SJahqJZAW,Stabilizing GAN Training with Multiple Random Projections,2,"[""generative adversarial networks"", ""stable training"", ""low-dimensional projections"", ""deep learning""]",0.3842540791289762,0,5.333333333333333,2018, generative_adversarial_networks stable_training low_dimensional_projections deep_learning
SJc1hL5ee,FastText.zip: Compressing text classification models,3,"[""Natural language processing"", ""Supervised Learning"", ""Applications""]",0.47289177581396646,1,5.666666666666667,2017, natural_language_processing supervised_learning applications
SJcKhk-Ab,Can recurrent neural networks warp time?,3,"[""RNN""]",0.5040097473902825,0,8.0,2018, rnn
SJd0EAy0b,Generalized Graph Embedding Models,3,"[""representation learning"", ""knowledge graphs"", ""relational inference"", ""link prediction"", ""multi-label classification"", ""knowledge base completion""]",0.4433902083094745,0,4.333333333333333,2018, representation_learning knowledge_graphs relational_inference link_prediction multi_label_classification knowledge_base_completion
SJdCUMZAW,Data-efficient Deep Reinforcement Learning for Dexterous Manipulation,3,"[""Reinforcement learning"", ""robotics"", ""dexterous manipulation"", ""off-policy learning""]",0.48254494841781426,0,3.0,2018, reinforcement_learning robotics dexterous_manipulation off_policy_learning
SJg498clg,Neural Graph Machines: Learning Neural Networks Using Graphs,3,"[""Semi-Supervised Learning"", ""Natural language processing"", ""Applications""]",0.5170728924138769,1,3.3333333333333335,2017, semi_supervised_learning natural_language_processing applications
SJgWQPcxl,Multi-view Generative Adversarial Networks,3,"[""Deep learning"", ""Supervised Learning""]",0.411607452242624,1,4.666666666666667,2017, deep_learning supervised_learning
SJgf6Z-0W,Predicting Multiple Actions for Stochastic Continuous Control,3,"[""Reinforcement Learning"", ""DDPG"", ""Multiple Action Prediction""]",0.45907788121559573,0,4.666666666666667,2018, reinforcement_learning ddpg multiple_action_prediction
SJi9WOeRb,Gradient Estimators for Implicit Models,3,"[""Implicit Models"", ""Approximate Inference"", ""Deep Learning""]",0.4537664643696294,0,6.666666666666667,2018, implicit_models approximate_inference deep_learning
SJiFvr9el,Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants,3,"[""Unsupervised Learning"", ""Applications"", ""Deep learning""]",0.5639579110192953,1,4.333333333333333,2017, unsupervised_learning applications deep_learning
SJiHOSeR-,Contextual memory bandit for pro-active dialog engagement,3,"[""contextual bandit"", ""memory network"", ""proactive dialog engagement""]",0.548462606579962,0,2.6666666666666665,2018, contextual_bandit memory_network proactive_dialog_engagement
SJiHXGWAZ,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting,3,"[""Traffic prediction"", ""spatiotemporal forecasting"", ""diffusion"", ""graph convolution"", ""random walk"", ""long-term forecasting""]",0.41817468970730387,0,6.0,2018, traffic_prediction spatiotemporal_forecasting diffusion graph_convolution random_walk long_term_forecasting
SJk01vogl,Adversarial examples for generative models,3,"[""Computer vision"", ""Unsupervised Learning""]",0.42568763936057313,1,5.333333333333333,2017, computer_vision unsupervised_learning
SJkXfE5xx,Revisiting Classifier Two-Sample Tests,3,"[""Theory"", ""Unsupervised Learning""]",0.444594874998404,1,7.333333333333333,2017, theory unsupervised_learning
SJky6Ry0W,Learning Independent Causal Mechanisms,3,[],0.4245282415126746,0,5.333333333333333,2018,
SJlhPMWAW,GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders,3,"[""graph"", ""generative model"", ""autoencoder""]",0.445213537343241,0,6.333333333333333,2018, graph generative_model autoencoder
SJmAXkgCb,DNN Feature Map Compression using Learned Representation over GF(2),3,"[""feature map"", ""representation"", ""compression"", ""quantization"", ""finite-field""]",0.5780130148963467,0,5.333333333333333,2018, feature_map representation compression quantization finite_field
SJme6-ZR-,A Deep Learning Approach for Survival Clustering without End-of-life Signals,3,"[""Survival Analysis"", ""Kuiper statistics"", ""model-free""]",0.47965814308593857,0,5.333333333333333,2018, survival_analysis kuiper_statistics model_free
SJn0sLgRb,Data Augmentation by Pairing Samples for Images Classification,3,"[""Data augmentation"", ""Image classification""]",0.5036877785719354,0,5.0,2018, data_augmentation image_classification
SJqaCVLxx,New Learning Approach By Genetic Algorithm In A Convolutional Neural Network For Pattern Recognition,3,"[""Deep learning"", ""Supervised Learning"", ""Optimization"", ""Computer vision""]",0.4919307608290327,1,2.6666666666666665,2017, deep_learning supervised_learning optimization computer_vision
SJtChcgAW,Cheap DNN Pruning with Performance Guarantees ,3,"[""pruning"", ""generalisation error"", ""DC optimisation""]",0.5011713326107665,0,5.333333333333333,2018, pruning generalisation_error dc_optimisation
SJtfOEn6-,ResBinNet: Residual Binary Neural Network,3,"[""Binary Neural Networks"", ""Residual Binarization"", ""Deep Learning""]",0.5305198237884573,0,4.0,2018, binary_neural_networks residual_binarization deep_learning
SJttqw5ge,Communicating Hierarchical Neural Controllers for Learning Zero-shot Task Generalization,3,"[""Reinforcement Learning"", ""Deep learning""]",0.45791230296966745,1,4.75,2017, reinforcement_learning deep_learning
SJu63o10b,UNSUPERVISED METRIC LEARNING VIA NONLINEAR FEATURE SPACE TRANSFORMATIONS,3,"[""Metric Learning"", ""K-means"", ""CPD"", ""Clustering""]",0.4588276793277475,0,4.666666666666667,2018, metric_learning k_means cpd clustering
SJvYgH9xe,Automatic Rule Extraction from Long Short Term Memory Networks,3,"[""Natural language processing"", ""Deep learning"", ""Applications""]",0.5451208649511946,1,7.0,2017, natural_language_processing deep_learning applications
SJvrXqvaZ,Adversary A3C for Robust Reinforcement Learning,2,"[""Adversary"", ""Robust"", ""Reinforcement Learning"", ""A3C""]",0.3900424992656935,0,4.0,2018, adversary robust reinforcement_learning a3c
SJvu-GW0b,Graph2Seq: Scalable Learning Dynamics for Graphs,3,[],0.47502482823691444,0,4.0,2018,
SJw03ceRW,GENERATIVE LOW-SHOT NETWORK EXPANSION,3,"[""Low-Shot Learning"", ""class incremental learning"", ""Network expansion"", ""Generative model"", ""Distillation""]",0.456402072839364,0,4.666666666666667,2018, low_shot_learning class_incremental_learning network_expansion generative_model distillation
SJx7Jrtgl,Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders,3,"[""Unsupervised Learning"", ""Deep learning""]",0.4957581253224439,1,5.333333333333333,2017, unsupervised_learning deep_learning
SJx9GQb0-,Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect,3,"[""GAN"", ""WGAN""]",0.41506887278058113,0,5.666666666666667,2018, gan wgan
SJxE3jlA-,Now I Remember! Episodic Memory For Reinforcement Learning,3,"[""Reinforcement learning"", ""Deep learning"", ""Episodic memory""]",0.510166896825308,0,4.0,2018, reinforcement_learning deep_learning episodic_memory
SJyEH91A-,Learning Wasserstein Embeddings,3,"[""Wasserstein distance"", ""metric embedding"", ""Siamese architecture""]",0.4415407304915672,0,7.0,2018, wasserstein_distance metric_embedding siamese_architecture
SJyVzQ-C-,Fraternal Dropout,3,"[""fraternal dropout"", ""activity regularization"", ""recurrent neural networks"", ""RNN"", ""LSTM"", ""faster convergence""]",0.55708073157802,0,5.333333333333333,2018, fraternal_dropout activity_regularization recurrent_neural_networks rnn lstm faster_convergence
SJyfrl-0b,Fast Node Embeddings: Learning Ego-Centric Representations,3,"[""Graph"", ""Node Embeddings"", ""Distributed Representations"", ""Learning Representations""]",0.48093646685727237,0,5.0,2018, graph node_embeddings distributed_representations learning_representations
SJzCSf9xg,On Detecting Adversarial Perturbations,3,"[""Computer vision"", ""Deep learning"", ""Supervised Learning""]",0.42617769185010235,1,6.333333333333333,2017, computer_vision deep_learning supervised_learning
SJzMATlAZ,Deep Continuous Clustering,3,"[""clustering"", ""dimensionality reduction""]",0.45801261828455847,0,5.333333333333333,2018, clustering dimensionality_reduction
SJzRZ-WCZ,Latent Space Oddity: on the Curvature of Deep Generative Models,3,"[""Generative models"", ""Riemannian Geometry"", ""Latent Space""]",0.4849039055815509,0,5.666666666666667,2018, generative_models riemannian_geometry latent_space
SJzmJEq6W,Learning non-linear transform with discriminative and minimum information loss priors,3,"[""transform learning"", ""sparse representation"", ""discrimininative prior"", ""information preservation"", ""discrimination power""]",0.5244019557607894,0,4.666666666666667,2018, transform_learning sparse_representation discrimininative_prior information_preservation discrimination_power
Sk-oDY9ge,Diet Networks: Thin Parameters for Fat Genomics,3,"[""Deep learning"", ""Unsupervised Learning"", ""Supervised Learning"", ""Applications""]",0.4731340247070802,1,7.0,2017, deep_learning unsupervised_learning supervised_learning applications
Sk03Yi10Z,An Ensemble of Retrieval-Based and Generation-Based Human-Computer Conversation Systems.,3,"[""conversation systems"", ""retrieval method"", ""generation method""]",0.5449170289590891,0,5.333333333333333,2018, conversation_systems retrieval_method generation_method
Sk0pHeZAW,Sparse Regularized Deep Neural Networks For Efficient Embedded Learning,3,"[""Sparse representation"", ""Compression Deep Learning Models"", ""L1 regularisation"", ""Optimisation.""]",0.5422302164312112,0,3.3333333333333335,2018, sparse_representation compression_deep_learning_models l1_regularisation optimisation.
Sk1NTfZAb,Key Protected Classification for GAN Attack Resilient Collaborative Learning,3,"[""privacy preserving deep learning"", ""collaborative learning"", ""adversarial attack""]",0.40023765556843066,0,4.0,2018, privacy_preserving_deep_learning collaborative_learning adversarial_attack
Sk2Im59ex,Unsupervised Cross-Domain Image Generation,3,"[""Computer vision"", ""Deep learning"", ""Unsupervised Learning"", ""Transfer Learning""]",0.4910964436668322,1,6.666666666666667,2017, computer_vision deep_learning unsupervised_learning transfer_learning
Sk2iistgg,Non-linear Dimensionality Regularizer for Solving Inverse Problems,3,"[""Computer vision"", ""Optimization"", ""Structured prediction""]",0.5222202622358233,1,3.6666666666666665,2017, computer_vision optimization structured_prediction
Sk2u1g-0-,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments,3,"[""reinforcement learning"", ""nonstationarity"", ""meta-learning"", ""transfer learning"", ""multi-agent""]",0.422019485739234,0,8.0,2018, reinforcement_learning nonstationarity meta_learning transfer_learning multi_agent
Sk36NgFeg,Filling in the details: Perceiving from low fidelity visual input,3,"[""Deep learning"", ""Computer vision"", ""Semi-Supervised Learning""]",0.49531323071847616,1,5.0,2017, deep_learning computer_vision semi_supervised_learning
Sk4w0A0Tb,Rotational Unit of Memory ,3,"[""RNN"", ""unitary approach"", ""associative memory"", ""language modeling""]",0.5406497138359743,0,5.0,2018, rnn unitary_approach associative_memory language_modeling
Sk6fD5yCb,Espresso: Efficient Forward Propagation for Binary Deep Neural Networks,3,"[""binary deep neural networks"", ""optimized implementation"", ""bitwise computations""]",0.5766751262673265,0,6.666666666666667,2018, binary_deep_neural_networks optimized_implementation bitwise_computations
Sk7KsfW0-,Lifelong Learning with Dynamically Expandable Networks,3,"[""Transfer learning"", ""Lifelong learning"", ""Selective retraining"", ""Dynamic network expansion""]",0.4702778117417701,0,7.0,2018, transfer_learning lifelong_learning selective_retraining dynamic_network_expansion
Sk7cHb-C-,Representing dynamically: An active process for describing sequential data,3,"[""Generative Models"", ""Latent representations"", ""Predictive coding"", ""Recurrent networks"", ""Sequential data""]",0.5238552588264759,0,4.25,2018, generative_models latent_representations predictive_coding recurrent_networks sequential_data
Sk8J83oee,Generative Adversarial Parallelization,2,"[""Unsupervised Learning""]",0.37374262905217015,1,4.0,2017, unsupervised_learning
Sk8csP5ex,The loss surface of residual networks: Ensembles and the role of batch normalization,3,"[""Deep learning"", ""Theory""]",0.5073610595899559,1,5.666666666666667,2017, deep_learning theory
Sk9yuql0Z,Mitigating Adversarial Effects Through Randomization,3,"[""adversarial examples""]",0.4267640535992879,0,6.333333333333333,2018, adversarial_examples
SkA-IE06W,When is a Convolutional Filter Easy to Learn?,3,"[""deep learning"", ""convolutional neural network"", ""non-convex optimization"", ""convergence analysis""]",0.4884423914117154,0,7.666666666666667,2018, deep_learning convolutional_neural_network non_convex_optimization convergence_analysis
SkAK2jg0b,An Out-of-the-box Full-network Embedding for Convolutional Neural Networks,3,"[""Embedding spaces"", ""feature extraction"", ""transfer learning.""]",0.49885992653480105,0,3.6666666666666665,2018, embedding_spaces feature_extraction transfer_learning.
SkB-_mcel,Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning,3,"[""Transfer Learning"", ""Deep learning"", ""Computer vision""]",0.4721506730479859,1,7.333333333333333,2017, transfer_learning deep_learning computer_vision
SkBHr1WRW,Ego-CNN: An Ego Network-based Representation of Graphs Detecting Critical Structures,3,"[""graph embedding"", ""CNN""]",0.4352016347097169,0,5.0,2018, graph_embedding cnn
SkBYYyZRZ,Searching for Activation Functions,3,"[""meta learning"", ""activation functions""]",0.48581899880856994,0,5.333333333333333,2018, meta_learning activation_functions
SkBcLugC-,Fast and Accurate Inference with Adaptive Ensemble Prediction for Deep Networks,3,"[""ensemble"", ""confidence level""]",0.5917158103589704,0,5.333333333333333,2018, ensemble confidence_level
SkBsEQYll,Learning similarity preserving representations with neural similarity and context encoders,3,"[""Natural language processing"", ""Unsupervised Learning"", ""Supervised Learning""]",0.5391739414140392,1,2.6666666666666665,2017, natural_language_processing unsupervised_learning supervised_learning
SkCILwqex,Exploring LOTS in Deep Neural Networks,3,"[""Deep learning"", ""Computer vision""]",0.4207057845042249,1,6.0,2017, deep_learning computer_vision
SkC_7v5gx,The Power of Sparsity in Convolutional Neural Networks,3,"[""Deep learning"", ""Supervised Learning""]",0.5400547134803012,1,5.333333333333333,2017, deep_learning supervised_learning
SkERSm-0-,Preliminary theoretical troubleshooting in Variational Autoencoder,3,"[""variational autoencoder"", ""information theory"", ""noise modelling"", ""representation learning"", ""generative model"", ""disentanglement""]",0.49146756861259416,0,3.3333333333333335,2018, variational_autoencoder information_theory noise_modelling representation_learning generative_model disentanglement
SkF2D7g0b,Exploring the Space of Black-box Attacks on Deep Neural Networks,2,"[""adversarial machine learning"", ""black-box attacks""]",0.3779253583796996,0,6.0,2018, adversarial_machine_learning black_box_attacks
SkFAWax0-,VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,3,"[""Voice Synthesis"", ""Multi-Speaker"", ""Differentiable Memory"", ""Text-to-Speech""]",0.5656689311428414,0,6.333333333333333,2018, voice_synthesis multi_speaker differentiable_memory text_to_speech
SkFEGHx0Z,Nearest Neighbour Radial Basis Function Solvers for Deep Neural Networks,3,[],0.5419737208396472,0,4.0,2018,
SkFqf0lAZ,Memory Architectures in Recurrent Neural Network Language Models,4,[],0.6187884012749445,0,6.333333333333333,2018,
SkFvV0yC-,Network Iterative Learning for Dynamic Deep Neural Networks via Morphism,3,"[""Network Iterative Learning"", ""Morphism""]",0.4584666639915863,0,5.666666666666667,2018, network_iterative_learning morphism
SkHDoG-Cb,Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings,3,[],0.40543483728594365,0,5.0,2018,
SkHkeixAW,Regularization for Deep Learning: A Taxonomy,3,"[""neural networks"", ""deep learning"", ""regularization"", ""data augmentation"", ""network architecture"", ""loss function"", ""dropout"", ""residual learning"", ""optimization""]",0.46474985790311,0,4.333333333333333,2018, neural_networks deep_learning regularization data_augmentation network_architecture loss_function dropout residual_learning optimization
SkHl6MWC-,Regularization Neural Networks via Constrained Virtual  Movement Field,2,[],0.3961754950170497,0,5.333333333333333,2018,
SkJKHMW0Z,Recurrent Relational Networks for complex relational reasoning,3,"[""relational reasoning"", ""graph neural networks""]",0.5572492002923535,0,4.333333333333333,2018, relational_reasoning graph_neural_networks
SkJd_y-Cb,Word2net: Deep Representations of Language,3,"[""neural language models"", ""word embeddings"", ""neural networks""]",0.5497357556223404,0,4.333333333333333,2018, neural_language_models word_embeddings neural_networks
SkJeEtclx,Memory-augmented Attention Modelling for Videos,3,"[""Deep learning"", ""Multi-modal learning"", ""Computer vision""]",0.5460050378541634,1,4.0,2017, deep_learning multi_modal_learning computer_vision
SkNQeiRpb,Training Deep AutoEncoders for Recommender Systems,3,"[""autoencoder"", ""recommendations"", ""collaborative filtering"", ""selu""]",0.49835496726408957,0,4.333333333333333,2018, autoencoder recommendations collaborative_filtering selu
SkOb1Fl0Z,A Flexible Approach to Automated RNN Architecture Generation,3,"[""reinforcement learning"", ""architecture search"", ""ranking function"", ""recurrent neural networks"", ""recursive neural networks""]",0.56459903891921,0,5.0,2018, reinforcement_learning architecture_search ranking_function recurrent_neural_networks recursive_neural_networks
SkPoRg10b,Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior,3,[],0.4727686845772676,0,5.333333333333333,2018,
SkRsFSRpb,GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks,3,[],0.5416601759697108,0,4.666666666666667,2018,
SkT5Yg-RZ,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play,3,"[""self-play"", ""automatic curriculum"", ""intrinsic motivation"", ""unsupervised learning"", ""reinforcement learning""]",0.5070888375866894,0,7.0,2018, self_play automatic_curriculum intrinsic_motivation unsupervised_learning reinforcement_learning
SkVqXOxCb,Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields,2,"[""Deep Learning"", ""Generative Adversarial Network"", ""GAN"", ""Generative Model"", ""Potential Field""]",0.3546409856199282,0,6.333333333333333,2018, deep_learning generative_adversarial_network gan generative_model potential_field
SkXIrV9le,Perception Updating Networks: On architectural constraints for interpretable video generative models,3,"[""Structured prediction"", ""Unsupervised Learning""]",0.5286798163713535,1,4.0,2017, structured_prediction unsupervised_learning
SkYMnLxRW,Weighted Transformer Network for Machine Translation,3,"[""transformer"", ""branching"", ""attention"", ""machine translation""]",0.5127283042311558,0,6.333333333333333,2018, transformer branching attention machine_translation
SkYXvCR6W,Compact Encoding of Words for Efficient Character-level Convolutional Neural Networks Text Classification,4,"[""Character Level Convolutional Networks"", ""Text Classification"", ""Word Compressing""]",0.6143775899922489,0,3.0,2018, character_level_convolutional_networks text_classification word_compressing
SkYbF1slg,An Information-Theoretic Framework for Fast and Robust Unsupervised Learning via Neural Population Infomax,3,"[""Unsupervised Learning"", ""Theory"", ""Deep learning""]",0.4770797575884208,1,6.666666666666667,2017, unsupervised_learning theory deep_learning
SkYibHlRb,SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning,3,[],0.5731707452514551,0,5.333333333333333,2018,
SkZ-BnyCW,Learning Deep Generative Models With Discrete Latent Variables,3,"[""deep generative models"", ""deep learning""]",0.536428542665373,0,4.333333333333333,2018, deep_generative_models deep_learning
SkZxCk-0Z,Can Neural Networks Understand Logical Entailment?,3,"[""structure"", ""neural networks"", ""logic"", ""dataset""]",0.5616008967874635,0,6.0,2018, structure neural_networks logic dataset
SkaPsfZ0W,Network of Graph Convolutional Networks Trained on Random Walks,3,"[""Graph Convolution"", ""Deep Learning"", ""Network of Networks""]",0.46089537822590776,0,5.333333333333333,2018, graph_convolution deep_learning network_of_networks
Skdvd2xAZ,A Scalable Laplace Approximation for Neural Networks,3,"[""deep learning"", ""neural networks"", ""laplace approximation"", ""bayesian deep learning""]",0.4503917519456282,0,7.0,2018, deep_learning neural_networks laplace_approximation bayesian_deep_learning
SkfNU2e0Z,Statestream: A toolbox to explore layerwise-parallel deep neural networks,3,"[""model-parallel"", ""parallelization"", ""software platform""]",0.5391210795048299,0,4.333333333333333,2018, model_parallel parallelization software_platform
SkffVjUaW,Building effective deep neural networks one feature at a time,3,"[""convolution neural networks"", ""architecture search"", ""meta-learning"", ""representational capacity""]",0.47237467494187546,0,5.666666666666667,2018, convolution_neural_networks architecture_search meta_learning representational_capacity
SkgSXUKxx,An Analysis of Feature Regularization for Low-shot Learning,3,"[""Deep learning"", ""Computer vision""]",0.5220517641813229,1,5.666666666666667,2017, deep_learning computer_vision
SkgewU5ll,GRAM: Graph-based Attention Model for Healthcare Representation Learning,3,"[""Deep learning"", ""Applications""]",0.4712647269086224,1,6.0,2017, deep_learning applications
SkhQHMW0W,Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training,3,"[""distributed training""]",0.4798443040465455,0,6.666666666666667,2018, distributed_training
SkhU2fcll,Deep Multi-task Representation Learning: A Tensor Factorisation Approach,3,[],0.4528659095527331,1,6.666666666666667,2017,
SkiCjzNTZ,Spontaneous Symmetry Breaking in Deep Neural Networks,3,"[""deep learning"", ""physics"", ""field theory""]",0.41274255891485034,0,3.0,2018, deep_learning physics field_theory
Skj8Kag0Z,Stabilizing Adversarial Nets with Prediction Methods,3,"[""adversarial networks"", ""optimization""]",0.44601141924022203,0,6.666666666666667,2018, adversarial_networks optimization
Skk3Jm96W,Some Considerations on Learning to Explore via Meta-Reinforcement Learning,3,"[""reinforcement learning"", ""rl"", ""exploration"", ""meta learning"", ""meta reinforcement learning"", ""curiosity""]",0.48709971632294463,0,5.666666666666667,2018, reinforcement_learning rl exploration meta_learning meta_reinforcement_learning curiosity
SkkTMpjex,Distributed Second-Order Optimization using Kronecker-Factored Approximations,3,"[""Deep learning"", ""Optimization""]",0.5280182637219998,1,6.5,2017, deep_learning optimization
SkmM6M_pW,Egocentric Spatial Memory Network,4,"[""spatial memory"", ""egocentric vision"", ""deep neural network"", ""navigation""]",0.6015947657106115,0,4.0,2018, spatial_memory egocentric_vision deep_neural_network navigation
SkmiegW0b,Challenges in Disentangling Independent Factors of Variation,3,"[""disentangling"", ""factors"", ""attribute"", ""transfer"", ""autoencoder"", ""GAN""]",0.4714786145807377,0,5.333333333333333,2018, disentangling factors attribute transfer autoencoder gan
Skn9Shcxe,Highway and Residual Networks learn Unrolled Iterative Estimation,3,"[""Theory"", ""Deep learning"", ""Supervised Learning""]",0.5016978410274049,1,7.0,2017, theory deep_learning supervised_learning
SknC0bW0-,Continuous-fidelity Bayesian Optimization with Knowledge Gradient,3,"[""Continuous fidelity"", ""Bayesian optimization"", ""fast"", ""knowledge gradient"", ""hyperparameter optimization""]",0.4312493102073201,0,5.0,2018, continuous_fidelity bayesian_optimization fast knowledge_gradient hyperparameter_optimization
Skp1ESxRZ,Towards Synthesizing Complex Programs From Input-Output Examples,3,[],0.5511819660512677,0,6.666666666666667,2018,
SkpSlKIel,Why Deep Neural Networks for Function Approximation?,3,[],0.5242407547939868,1,7.0,2017,
Skq89Scxx,SGDR: Stochastic Gradient Descent with Warm Restarts,3,"[""Deep learning"", ""Optimization""]",0.5039399940294595,1,7.0,2017, deep_learning optimization
SkqMSCHxe,PREDICTION OF POTENTIAL HUMAN INTENTION USING SUPERVISED COMPETITIVE LEARNING,3,"[""Computer vision"", ""Deep learning"", ""Supervised Learning"", ""Applications""]",0.4751819276149103,1,2.6666666666666665,2017, computer_vision deep_learning supervised_learning applications
SkqV-XZRZ,Variational Bi-LSTMs,3,[],0.5289461509797919,0,5.666666666666667,2018,
SkrHeXbCW,Learning Representations for Faster Similarity Search,3,[],0.5448508563689508,0,4.0,2018,
Sks3zF9eg,Taming the waves: sine as activation function in deep neural networks,3,"[""Theory"", ""Deep learning"", ""Optimization"", ""Supervised Learning""]",0.4916400961620889,1,4.0,2017, theory deep_learning optimization supervised_learning
Sks9_ajex,Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer,3,"[""Computer vision"", ""Deep learning"", ""Supervised Learning""]",0.5586186062477773,1,6.0,2017, computer_vision deep_learning supervised_learning
SksY3deAW,Learning Deep ResNet Blocks Sequentially using Boosting Theory,3,"[""residual network"", ""boosting theory"", ""training error guarantee""]",0.5437158606507863,0,4.666666666666667,2018, residual_network boosting_theory training_error_guarantee
SktLlGbRZ,CyCADA: Cycle-Consistent Adversarial Domain Adaptation,3,"[""domain adaptation"", ""unsupervised learning"", ""classification"", ""semantic segmentation""]",0.45435379344681165,0,6.333333333333333,2018, domain_adaptation unsupervised_learning classification semantic_segmentation
Sktm4zWRb,Soft Value Iteration Networks for Planetary Rover Path Planning,3,"[""value iteration networks"", ""robotics"", ""space robotics"", ""imitation learning"", ""convolutional neural networks"", ""path planning""]",0.4734551837469037,0,3.3333333333333335,2018, value_iteration_networks robotics space_robotics imitation_learning convolutional_neural_networks path_planning
SkuqA_cgx,Automated Generation of Multilingual Clusters for the Evaluation of Distributed Representations,3,"[""Natural language processing"", ""Applications""]",0.5460370078882084,1,6.333333333333333,2017, natural_language_processing applications
Skvd-myR-,Learning Non-Metric Visual Similarity for Image Retrieval,3,"[""image retrieval"", ""visual similarity"", ""non-metric learning""]",0.5540735711254995,0,4.666666666666667,2018, image_retrieval visual_similarity non_metric_learning
Skvgqgqxe,Learning to Compose Words into Sentences with Reinforcement Learning,3,[],0.5442311689552359,1,7.0,2017,
Skw0n-W0Z,Temporal Difference Models: Model-Free Deep RL for Model-Based Control,3,"[""model-based reinforcement learning"", ""model-free reinforcement learning"", ""temporal difference learning"", ""predictive learning"", ""predictive models"", ""optimal control"", ""off-policy reinforcement learning"", ""deep learning"", ""deep reinforcement learning"", ""q learning""]",0.4558971402553784,0,6.0,2018, model_based_reinforcement_learning model_free_reinforcement_learning temporal_difference_learning predictive_learning predictive_models optimal_control off_policy_reinforcement_learning deep_learning deep_reinforcement_learning q_learning
SkwAEQbAb,A novel method to determine the number of latent dimensions with SVD,3,"[""SVD"", ""Latent Dimensions"", ""Dimension Reductions"", ""Machine Learning""]",0.5064388237668193,0,2.0,2018, svd latent_dimensions dimension_reductions machine_learning
SkwSJ99ex,DeepRebirth: A General Approach for Accelerating Deep Neural Network Execution on Mobile Devices,3,[],0.5015862470193654,1,4.0,2017,
Skx5txzb0W,A Boo(n) for Evaluating Architecture Performance,3,"[""evaluation"", ""methodology""]",0.507447881513295,0,4.666666666666667,2018, evaluation methodology
SkxKPDv5xl,SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,3,"[""Speech"", ""Deep learning"", ""Unsupervised Learning"", ""Applications""]",0.5065712109290514,1,8.333333333333334,2017, speech deep_learning unsupervised_learning applications
SkxqZngC-,A Bayesian Nonparametric Topic Model with Variational Auto-Encoders,3,"[""topic model"", ""Bayesian nonparametric"", ""variational auto-encoder"", ""document modeling""]",0.4921958988713827,0,5.0,2018, topic_model bayesian_nonparametric variational_auto_encoder document_modeling
SkyQWDcex,A Context-aware Attention Network for Interactive Question Answering,3,"[""Deep learning"", ""Natural language processing"", ""Applications""]",0.5292891410935983,1,4.333333333333333,2017, deep_learning natural_language_processing applications
SkymMAxAb,AirNet: a machine learning dataset for air quality forecasting,3,[],0.475227413289256,0,4.333333333333333,2018,
Skz_WfbCZ,A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks,3,"[""Neural Networks"", ""Generalization"", ""PAC-Bayes"", ""Sharpness""]",0.4773171236427445,0,7.333333333333333,2018, neural_networks generalization pac_bayes sharpness
Sy-dQG-Rb,Neural Speed Reading via Skim-RNN,3,"[""Natural Language Processing"", ""RNN"", ""Inference Speed""]",0.5827240482630377,0,7.333333333333333,2018, natural_language_processing rnn inference_speed
Sy-tszZRZ,Bounding and Counting Linear Regions of Deep Neural Networks,3,"[""rectifier networks"", ""maxout networks"", ""piecewise linear functions"", ""linear regions"", ""mixed-integer programming""]",0.47592678207332506,0,5.333333333333333,2018, rectifier_networks maxout_networks piecewise_linear_functions linear_regions mixed_integer_programming
Sy0GnUxCb,Emergent Complexity via Multi-Agent Competition,3,"[""multi-agent systems"", ""multi-agent competition"", ""self-play"", ""deep reinforcement learning""]",0.4722149855542869,0,6.333333333333333,2018, multi_agent_systems multi_agent_competition self_play deep_reinforcement_learning
Sy1f0e-R-,An empirical study on evaluation metrics of generative adversarial networks,2,"[""generative adversarial networks"", ""evaluation metric""]",0.37377567697423264,0,6.25,2018, generative_adversarial_networks evaluation_metric
Sy1rwtKxg,Parallel Stochastic Gradient Descent with Sound Combiners,3,[],0.5699729382751227,1,4.666666666666667,2017,
Sy21R9JAW,Towards better understanding of gradient-based attribution methods for Deep Neural Networks,3,"[""Deep Neural Networks"", ""Attribution methods"", ""Theory of deep learning""]",0.44306376245722506,0,6.666666666666667,2018, deep_neural_networks attribution_methods theory_of_deep_learning
Sy2fzU9gl,beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework,3,[],0.5091892253668169,1,6.0,2017,
Sy2ogebAW,Unsupervised Neural Machine Translation,3,"[""neural machine translation"", ""unsupervised learning""]",0.5177524807816594,0,6.0,2018, neural_machine_translation unsupervised_learning
Sy3XxCx0Z,Natural Language Inference with External Knowledge,3,"[""natural language inference"", ""external knowledge"", ""state of the art""]",0.528606080170448,0,5.25,2018, natural_language_inference external_knowledge state_of_the_art
Sy3fJXbA-,Connectivity Learning in Multi-Branch Networks,3,"[""connectivity learning"", ""multi-branch networks"", ""image categorization""]",0.5095030849376596,0,5.0,2018, connectivity_learning multi_branch_networks image_categorization
Sy4c-3xRW,DropMax: Adaptive Stochastic Softmax,3,[],0.5208185623887267,0,5.333333333333333,2018,
Sy4tzwqxe,Two Methods for Wild Variational Inference,3,"[""Theory""]",0.4751480958514201,1,3.0,2017, theory
Sy5OAyZC-,On the Use of Word Embeddings Alone to Represent Natural Language Sequences,3,"[""Natural Language Processing"", ""Deep Learning""]",0.5835988459226482,0,6.0,2018, natural_language_processing deep_learning
Sy6iJDqlx,"Attend, Adapt and Transfer: Attentive Deep Architecture for Adaptive Transfer from multiple sources in the same domain",3,"[""Deep learning"", ""Reinforcement Learning"", ""Transfer Learning""]",0.4261160631371473,1,7.0,2017, deep_learning reinforcement_learning transfer_learning
Sy7m72Ogg,An Actor-critic Algorithm for Learning Rate Learning,3,"[""Deep learning"", ""Reinforcement Learning""]",0.4265381748109735,1,4.0,2017, deep_learning reinforcement_learning
Sy8XvGb0-,Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models,3,"[""VAE"", ""GAN"", ""generative networks"", ""conditional generation"", ""latent-variable models""]",0.45399479414806776,0,7.0,2018, vae gan generative_networks conditional_generation latent_variable_models
Sy8gdB9xx,Understanding deep learning requires rethinking generalization,3,"[""Deep learning""]",0.5076905118098419,1,9.666666666666666,2017, deep_learning
SyAbZb-0Z,Transfer Learning to Learn with Multitask Neural Model Search,3,"[""Learning to Learn"", ""Meta learning"", ""Reinforcement learning"", ""Transfer learning""]",0.4251752894943098,0,5.333333333333333,2018, learning_to_learn meta_learning reinforcement_learning transfer_learning
SyBBgXWAZ,Optimal transport maps for distribution preserving operations on latent spaces of Generative Models,2,"[""Generative Models"", ""GANs"", ""latent space operations"", ""optimal transport""]",0.3964312532139634,0,5.333333333333333,2018, generative_models gans latent_space_operations optimal_transport
SyCSsUDee,Semantic Noise Modeling for Better Representation Learning,3,"[""Deep learning"", ""Supervised Learning""]",0.4924252936564739,1,3.0,2017, deep_learning supervised_learning
SyELrEeAb,Implicit Causal Models for Genome-wide Association Studies,3,[],0.4653647947230456,0,5.666666666666667,2018,
SyEiHNKxx,A Differentiable Physics Engine for Deep Learning in Robotics,3,"[""Deep learning""]",0.5230574313545926,1,5.333333333333333,2017, deep_learning
SyF7Erp6W,Learning to play slot cars and Atari 2600 games in just minutes,3,"[""Artificial Intelligence"", ""Signal processing"", ""Philosophy"", ""Analogy"", ""ALE"", ""Slot Car""]",0.5069121939761807,0,2.6666666666666665,2018, artificial_intelligence signal_processing philosophy analogy ale slot_car
SyGT_6yCZ,Simple Fast Convolutional Feature Learning,3,"[""Feature Learning"", ""Convolutional Neural Networks"", ""Visual Recognition""]",0.572270926074719,0,2.6666666666666665,2018, feature_learning convolutional_neural_networks visual_recognition
SyJ7ClWCb,Countering Adversarial Images using Input Transformations,3,"[""adversarial example"", ""machine learning security"", ""computer vision"", ""image classification""]",0.49688548688847267,0,6.333333333333333,2018, adversarial_example machine_learning_security computer_vision image_classification
SyJNmVqgg,Neural Data Filter for Bootstrapping Stochastic Gradient Descent,3,"[""Reinforcement Learning"", ""Deep learning"", ""Optimization""]",0.4766545107699727,1,5.666666666666667,2017, reinforcement_learning deep_learning optimization
SyJS-OgR-,Multi-level Residual Networks from Dynamical Systems View,3,"[""residual networks"", ""dynamical systems""]",0.5432449871566178,0,7.0,2018, residual_networks dynamical_systems
SyK00v5xx,A Simple but Tough-to-Beat Baseline for Sentence Embeddings,3,"[""Natural language processing"", ""Unsupervised Learning""]",0.49892925054307546,1,7.333333333333333,2017, natural_language_processing unsupervised_learning
SyKoKWbC-,Distributional Adversarial Networks,3,"[""adversarial learning"", ""generative model"", ""domain adaptation"", ""two-sample test""]",0.4003388423595189,0,6.0,2018, adversarial_learning generative_model domain_adaptation two_sample_test
SyL9u-WA-,Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization,3,"[""Recurrent Neural Network"", ""Vanishing Gradient"", ""Exploding Gradient"", ""Linear Algebra"", ""Householder Reflections""]",0.47733754446498844,0,5.666666666666667,2018, recurrent_neural_network vanishing_gradient exploding_gradient linear_algebra householder_reflections
SyMvJrdaW,Decoupling the Layers in Residual Networks,3,"[""Warped residual networks"", ""residual networks""]",0.5029242352471945,0,6.333333333333333,2018, warped_residual_networks residual_networks
SyOK1Sg0W,Adaptive Quantization of Neural Networks,3,"[""Deep Neural Networks"", ""Model Quantization"", ""Model Compression""]",0.507467639482899,0,6.0,2018, deep_neural_networks model_quantization model_compression
SyOvg6jxx,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,3,"[""Deep learning"", ""Reinforcement Learning"", ""Games""]",0.4282746834132419,1,5.666666666666667,2017, deep_learning reinforcement_learning games
SyPMT6gAb,Variance Regularized Counterfactual Risk Minimization via Variational Divergence Minimization,3,"[""Counterfactual Inference"", ""Off-Policy Learning"", ""Variance Regularization""]",0.43103923171331154,0,5.333333333333333,2018, counterfactual_inference off_policy_learning variance_regularization
SyProzZAW,The power of deeper networks for expressing natural functions,3,"[""expressivity of neural networks"", ""depth of neural networks"", ""universal approximators"", ""function approximation"", ""deep learning""]",0.5728691069069562,0,6.333333333333333,2018, expressivity_of_neural_networks depth_of_neural_networks universal_approximators function_approximation deep_learning
SyQq185lg,Latent Sequence Decompositions,3,"[""Speech"", ""Applications"", ""Natural language processing"", ""Deep learning""]",0.5339044041737093,1,7.333333333333333,2017, speech applications natural_language_processing deep_learning
SySaJ0xCZ,Simple and efficient architecture search for Convolutional Neural Networks,3,"[""Deep Learning"", ""Hyperparameter Optimization"", ""Architecture Search"", ""Convolutional Neural Networks"", ""Network Morphism"", ""Network Transformation"", ""SGDR"", ""Cosine annealing"", ""hill climbing""]",0.4665527457108553,0,5.0,2018, deep_learning hyperparameter_optimization architecture_search convolutional_neural_networks network_morphism network_transformation sgdr cosine_annealing hill_climbing
SySisz-CW,On the difference between building and extracting patterns: a causal analysis of deep generative models.,3,"[""GAN"", ""VAE"", ""causality""]",0.46509546436851473,0,5.333333333333333,2018, gan vae causality
SySpa-Z0Z,From Information Bottleneck To Activation Norm Penalty,3,"[""Deep Learning"", ""Natural Language Processing""]",0.4949323834328606,0,5.0,2018, deep_learning natural_language_processing
SyUkxxZ0b,Adversarial Spheres,3,"[""Adversarial Examples"", ""Deep Learning""]",0.4297885300826031,0,4.0,2018, adversarial_examples deep_learning
SyVOjfbRb,LSH-SAMPLING BREAKS THE COMPUTATIONAL CHICKEN-AND-EGG LOOP IN ADAPTIVE STOCHASTIC GRADIENT ESTIMATION,3,"[""Stochastic Gradient Descent"", ""Optimization"", ""Sampling"", ""Estimation""]",0.46487873659169204,0,5.333333333333333,2018, stochastic_gradient_descent optimization sampling estimation
SyVVJ85lg,Paleo: A Performance Model for Deep Neural Networks,3,"[""Deep learning""]",0.5183674728361093,1,6.333333333333333,2017, deep_learning
SyVVXngRW,Deep Asymmetric Multi-task Feature Learning,3,[],0.4528833088981378,0,4.666666666666667,2018,
SyW2QSige,Towards Information-Seeking Agents,3,[],0.46962611318472647,1,4.666666666666667,2017,
SyW4Gjg0W,Kernel Graph Convolutional Neural Nets,3,[],0.5615643924264645,0,4.666666666666667,2018,
SyWvgP5el,EPOpt: Learning Robust Neural Network Policies Using Model Ensembles,2,"[""Reinforcement Learning"", ""Applications""]",0.36932201325117714,1,7.333333333333333,2017, reinforcement_learning applications
SyX0IeWAW,META LEARNING SHARED HIERARCHIES,3,"[""hierarchal reinforcement learning"", ""meta-learning""]",0.4838673763522786,0,5.666666666666667,2018, hierarchal_reinforcement_learning meta_learning
SyYYPdg0-,Counterfactual Image Networks,3,"[""computer vision"", ""image segmentation"", ""generative models"", ""adversarial networks"", ""unsupervised learning""]",0.42478722027510507,0,4.333333333333333,2018, computer_vision image_segmentation generative_models adversarial_networks unsupervised_learning
SyYe6k-CW,Deep Bayesian Bandits Showdown:  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,3,"[""exploration"", ""Thompson Sampling"", ""Bayesian neural networks"", ""bandits"", ""reinforcement learning"", ""variational inference"", ""Monte Carlo""]",0.42665091426137414,0,6.0,2018, exploration thompson_sampling bayesian_neural_networks bandits reinforcement_learning variational_inference monte_carlo
SyZI0GWCZ,Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,2,"[""adversarial attacks"", ""adversarial examples"", ""adversarials"", ""robustness"", ""security""]",0.39770240785557637,0,7.333333333333333,2018, adversarial_attacks adversarial_examples adversarials robustness security
SyZipzbCb,Distributed Distributional Deterministic Policy Gradients,3,"[""policy gradient"", ""continuous control"", ""actor critic"", ""reinforcement learning""]",0.4672016568850482,0,6.666666666666667,2018, policy_gradient continuous_control actor_critic reinforcement_learning
SyZprb5xg,On Robust Concepts and Small Neural Nets,3,"[""Theory""]",0.5530187962681333,1,5.333333333333333,2017, theory
Sy_MK3lAZ,PARAMETRIZED DEEP Q-NETWORKS LEARNING: PLAYING ONLINE BATTLE ARENA WITH DISCRETE-CONTINUOUS HYBRID ACTION SPACE,3,"[""Deep reinforcement learning"", ""Hybrid action space"", ""DQN"", ""DDPG""]",0.4717734449562361,0,4.666666666666667,2018, deep_reinforcement_learning hybrid_action_space dqn ddpg
SybqeKgA-,On Batch Adaptive Training for Deep Learning: Lower Loss and Larger Step Size,3,"[""deep learning"", ""optimization""]",0.5146113190574345,0,4.666666666666667,2018, deep_learning optimization
SyfiiMZA-,Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning,3,"[""robot locomotion"", ""reinforcement learning"", ""policy gradients"", ""physical design"", ""deep learning""]",0.46329369392106357,0,6.0,2018, robot_locomotion reinforcement_learning policy_gradients physical_design deep_learning
Syfkm6cgx,Improving Invariance and Equivariance Properties of Convolutional Neural Networks,3,"[""Deep learning""]",0.4886782841921995,1,4.333333333333333,2017, deep_learning
Syg-YfWCW,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,3,"[""Knowledge Graphs"", ""Reinforcement Learning"", ""Query Answering""]",0.4430387551191029,0,6.0,2018, knowledge_graphs reinforcement_learning query_answering
SygGlIBcel,Opening the vocabulary of  neural language models with character-level word representations,3,"[""Natural language processing"", ""Deep learning""]",0.5642846482453465,1,3.0,2017, natural_language_processing deep_learning
SygvTcYee,"ParMAC: distributed optimisation of nested functions, with application to binary autoencoders",3,"[""Optimization"", ""Deep learning""]",0.500433346870372,1,5.25,2017, optimization deep_learning
SygwwGbRW,Semi-parametric topological memory for navigation,3,"[""deep learning"", ""navigation"", ""memory""]",0.43328718698440394,0,5.666666666666667,2018, deep_learning navigation memory
SyhRVm-Rb,Automatic Goal Generation for Reinforcement Learning Agents,2,"[""Reinforcement Learning"", ""Multi-task Learning"", ""Curriculum Learning""]",0.3927882381592006,0,6.0,2018, reinforcement_learning multi_task_learning curriculum_learning
SyhcXjy0Z,APPLICATION OF DEEP CONVOLUTIONAL NEURAL NETWORK TO PREVENT ATM FRAUD BY FACIAL DISGUISE IDENTIFICATION,3,"[""Deep Convolutional Neural Network"", ""Disguised Face Identification"", ""Fraudulent Transaction"", ""ATM"", ""Impersonation;""]",0.5695218638658874,0,2.0,2018, deep_convolutional_neural_network disguised_face_identification fraudulent_transaction atm impersonation;
Syhr6pxCW,PixelNN: Example-based Image Synthesis,3,"[""conditional image synthesis"", ""nearest neighbors""]",0.5402108221999751,0,7.0,2018, conditional_image_synthesis nearest_neighbors
Syjha0gAZ,Loss Functions for Multiset Prediction,3,"[""machine learning"", ""deep learning"", ""structured prediction"", ""sequential prediction""]",0.46573480005367573,0,5.333333333333333,2018, machine_learning deep_learning structured_prediction sequential_prediction
SyjjD1WRb,Evolutionary Expectation Maximization for Generative Models with Binary Latents,3,"[""unsupervised"", ""learning"", ""evolutionary"", ""sparse"", ""coding"", ""noisyOR"", ""BSC"", ""EM"", ""expectation-maximization"", ""variational EM"", ""optimization""]",0.531124809347868,0,4.0,2018, unsupervised learning evolutionary sparse coding noisyor bsc em expectation_maximization variational_em optimization
SyjsLqxR-,"Universality, Robustness, and Detectability of Adversarial Perturbations under Adversarial Training",3,"[""adversarial examples"", ""adversarial training"", ""universal perturbations"", ""safety"", ""deep learning""]",0.43517511301350964,0,5.0,2018, adversarial_examples adversarial_training universal_perturbations safety deep_learning
Syl3_2JCZ,A Self-Organizing Memory Network,3,"[""Working Memory"", ""Learning Rules"", ""Stimulus Representations""]",0.579418775907536,0,3.6666666666666665,2018, working_memory learning_rules stimulus_representations
SylJ1D1C-,PDE-Net: Learning PDEs from Data,3,"[""deep convolution network"", ""partial differential equation"", ""physical laws""]",0.5265717768475492,0,6.666666666666667,2018, deep_convolution_network partial_differential_equation physical_laws
SyoDInJ0-,Reinforcement Learning Algorithm Selection,3,"[""Reinforcement Learning"", ""Multi-Armed Bandit"", ""Algorithm Selection""]",0.48694381124379155,0,6.333333333333333,2018, reinforcement_learning multi_armed_bandit algorithm_selection
Syoiqwcxx,Local minima in training of deep networks,3,"[""Theory"", ""Deep learning"", ""Supervised Learning"", ""Optimization""]",0.474350490680602,1,4.333333333333333,2017, theory deep_learning supervised_learning optimization
SypU81Ole,Sampling Generative Networks,3,"[""Unsupervised Learning"", ""Deep learning"", ""Computer vision""]",0.46098155268497315,1,5.333333333333333,2017, unsupervised_learning deep_learning computer_vision
SyqAPeWAZ,CNNs as Inverse Problem Solvers and Double Network Superresolution,3,"[""superresolution"", ""convolutional neural network"", ""sparse representation"", ""inverse problem""]",0.5891389042932015,0,4.333333333333333,2018, superresolution convolutional_neural_network sparse_representation inverse_problem
SyqShMZRb,Syntax-Directed Variational Autoencoder for Structured Data,3,"[""generative model for structured data"", ""syntax-directed generation"", ""molecule and program optimization"", ""variational autoencoder""]",0.52030655069082,0,5.0,2018, generative_model_for_structured_data syntax_directed_generation molecule_and_program_optimization variational_autoencoder
Syr8Qc1CW,DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images,3,"[""disentangled representations"", ""multi-attribute images"", ""generative adversarial networks""]",0.43942917326252817,0,5.0,2018, disentangled_representations multi_attribute_images generative_adversarial_networks
SyrGJYlRZ,YellowFin and the Art of Momentum Tuning,3,"[""adaptive optimizer"", ""momentum"", ""hyperparameter tuning""]",0.5270982789269888,0,4.666666666666667,2018, adaptive_optimizer momentum hyperparameter_tuning
Sys6GJqxl,Delving into Transferable Adversarial Examples and Black-box Attacks,3,"[""Computer vision"", ""Deep learning"", ""Applications""]",0.4048074815261809,1,6.0,2017, computer_vision deep_learning applications
SysEexbRb,Critical Points of Linear Neural Networks: Analytical Forms and Landscape Properties,3,"[""neural networks"", ""critical points"", ""analytical form"", ""landscape""]",0.4361976003313087,0,6.666666666666667,2018, neural_networks critical_points analytical_form landscape
Syt0r4bRZ,Tree2Tree Learning with Memory Unit,3,[],0.557767682020009,0,3.6666666666666665,2018,
SyuWNMZ0W,Directing Generative Networks with Weighted Maximum Mean Discrepancy,3,"[""generative networks"", ""two sample tests"", ""bias correction"", ""maximum mean discrepancy""]",0.4348256326698529,0,4.0,2018, generative_networks two_sample_tests bias_correction maximum_mean_discrepancy
SyunbfbAb,FigureQA: An Annotated Figure Dataset for Visual Reasoning,3,"[""dataset"", ""computer vision"", ""deep learning"", ""visual reasoning"", ""relational reasoning""]",0.47487249665166975,0,6.0,2018, dataset computer_vision deep_learning visual_reasoning relational_reasoning
SyvCD-b0W,Autostacker: an Automatic Evolutionary Hierarchical  Machine Learning System,3,"[""Machine Learning"", ""AutoML""]",0.5256674305016142,0,3.6666666666666665,2018, machine_learning automl
SywUHFcge, A Theoretical Framework for Robustness of (Deep) Classifiers against Adversarial Samples,3,"[""Deep learning""]",0.44451349135778406,1,4.333333333333333,2017, deep_learning
SywXXwJAb,Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design,3,"[""deep learning"", ""quantum entanglement"", ""quantum physics"", ""many body physics"", ""data correlations"", ""inductive bias"", ""tensor networks""]",0.47816050929539805,0,6.75,2018, deep_learning quantum_entanglement quantum_physics many_body_physics data_correlations inductive_bias tensor_networks
Sywh5KYex,Learning Identity Mappings with Residual Gates,3,"[""Computer vision"", ""Deep learning"", ""Optimization""]",0.4549209493923576,1,5.333333333333333,2017, computer_vision deep_learning optimization
Syx6bz-Ab,Seq2SQL: Generating Structured Queries From Natural Language Using Reinforcement Learning ,3,"[""deep learning"", ""reinforcement learning"", ""dataset"", ""natural language processing"", ""natural language interface"", ""sql""]",0.46200057778874365,0,4.666666666666667,2018, deep_learning reinforcement_learning dataset natural_language_processing natural_language_interface sql
SyxCqGbRZ,Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks,3,"[""Healthcare"", ""Gaussian Process"", ""Deep Reinforcement Learning""]",0.445533863286278,0,4.333333333333333,2018, healthcare gaussian_process deep_reinforcement_learning
SyxeqhP9ll,Calibrating Energy-based Generative Adversarial Networks,3,"[""Deep learning""]",0.4084977991391208,1,7.666666666666667,2017, deep_learning
SyyGPP0TZ,Regularizing and Optimizing LSTM Language Models,3,"[""language model"", ""LSTM"", ""regularization"", ""optimization"", ""ASGD"", ""dropconnect""]",0.540404612162272,0,7.0,2018, language_model lstm regularization optimization asgd dropconnect
SyzKd1bCW,Backpropagation through the Void: Optimizing control variates for black-box gradient estimation,3,"[""optimization"", ""machine learning"", ""variational inference"", ""reinforcement learning"", ""gradient estimation"", ""deep learning"", ""discrete optimization""]",0.45705310554834905,0,7.0,2018, optimization machine_learning variational_inference reinforcement_learning gradient_estimation deep_learning discrete_optimization
r10FA8Kxg,Do Deep Convolutional Nets Really Need to be Deep and Convolutional?,3,"[""Deep learning"", ""Transfer Learning""]",0.5222238892336263,1,7.0,2017, deep_learning transfer_learning
r111KtCp-,Taking Apart Autoencoders: How do They Encode Geometric Shapes ?,3,"[""autoencoders"", ""CNN"", ""image synthesis"", ""latent space""]",0.5023831846786351,0,4.0,2018, autoencoders cnn image_synthesis latent_space
r11Q2SlRW,Auto-Conditioned Recurrent Networks for Extended Complex Human Motion Synthesis,3,"[""motion synthesis"", ""motion prediction"", ""human pose"", ""human motion"", ""recurrent networks"", ""lstm""]",0.545193011700893,0,6.666666666666667,2018, motion_synthesis motion_prediction human_pose human_motion recurrent_networks lstm
r154_g-Rb,Composable Planning with Attributes,3,"[""Planning"", ""Compositionality"", ""Attributes"", ""Reinforcement learning""]",0.47130776722678963,0,5.333333333333333,2018, planning compositionality attributes reinforcement_learning
r15kjpHa-,Reward Design in Cooperative Multi-agent Reinforcement Learning for Packet Routing,2,"[""Reward Design"", ""Cooperative Multi-agent Reinforcement Learning"", ""Packet Routing""]",0.3981891125689799,0,4.0,2018, reward_design cooperative_multi_agent_reinforcement_learning packet_routing
r16Vyf-0-,Image Transformer,3,"[""image generation"", ""super-resolution"", ""self-attention"", ""transformer""]",0.5044699575940264,0,4.666666666666667,2018, image_generation super_resolution self_attention transformer
r17Q6WWA-,Multi-Task Learning by Deep Collaboration and Application in Facial Landmark Detection,3,"[""multi-task learning"", ""soft parameter sharing"", ""facial landmark detection""]",0.47170832937693,0,5.666666666666667,2018, multi_task_learning soft_parameter_sharing facial_landmark_detection
r17RD2oxe,Deep Neural Networks and the Tree of Life,3,"[""Deep learning"", ""Computer vision"", ""Applications""]",0.5521114034159527,1,3.6666666666666665,2017, deep_learning computer_vision applications
r17lFgZ0Z,Relevance of Unsupervised Metrics in Task-Oriented Dialogue for Evaluating Natural Language Generation,3,"[""task-oriented dialog"", ""goal-oriented dialog"", ""nlg evaluation"", ""natural language generation"", ""automated metrics for nlg""]",0.5886147897002878,0,4.666666666666667,2018, task_oriented_dialog goal_oriented_dialog nlg_evaluation natural_language_generation automated_metrics_for_nlg
r1AMITFaW,Dependent Bidirectional RNN with Extended-long Short-term Memory,3,"[""RNN"", ""memory"", ""LSTM"", ""GRU"", ""BRNN"", ""encoder-decoder"", ""Natural language processing""]",0.5416213578144735,0,3.6666666666666665,2018, rnn memory lstm gru brnn encoder_decoder natural_language_processing
r1Aab85gg,"Offline bilingual word vectors, orthogonal transformations and the inverted softmax",3,"[""Natural language processing"", ""Transfer Learning"", ""Applications""]",0.5612403211122338,1,7.0,2017, natural_language_processing transfer_learning applications
r1AoGNlC-,Code Synthesis with Priority Queue Training,3,"[""code synthesis"", ""program synthesis"", ""genetic algorithm"", ""reinforcement learning"", ""policy gradient"", ""reinforce"", ""priority queue"", ""topk buffer"", ""bf"", ""code golf"", ""rnn""]",0.5143040304485343,0,5.666666666666667,2018, code_synthesis program_synthesis genetic_algorithm reinforcement_learning policy_gradient reinforce priority_queue topk_buffer bf code_golf rnn
r1BJLw9ex,Adjusting for Dropout Variance in Batch Normalization and Weight Initialization,3,[],0.4895410195299376,1,6.0,2017,
r1BRfhiab,The Principle of Logit Separation,3,[],0.5298246024826575,0,4.333333333333333,2018,
r1Bjj8qge,Encoding and Decoding Representations with Sum- and Max-Product Networks,3,[],0.5428894319911749,1,5.0,2017,
r1CE9GWR-,Understanding GANs: the LQG Setting,3,"[""Generative Adversarial Networks"", ""Wasserstein"", ""Generalization"", ""PCA""]",0.42326237196493516,0,4.333333333333333,2018, generative_adversarial_networks wasserstein generalization pca
r1Chut9xl,Inference and Introspection in Deep Generative Models of Sparse Data,3,"[""Unsupervised Learning"", ""Deep learning""]",0.48320036517554144,1,5.75,2017, unsupervised_learning deep_learning
r1DPFCyA-,Discriminative k-shot learning using probabilistic models,3,"[""discriminative k-shot learning"", ""probabilistic inference""]",0.5020361387255585,0,5.0,2018, discriminative_k_shot_learning probabilistic_inference
r1Ddp1-Rb,mixup: Beyond Empirical Risk Minimization,3,"[""empirical risk minimization"", ""vicinal risk minimization"", ""generalization"", ""data augmentation"", ""image classification"", ""generative adversarial networks"", ""adversarial examples"", ""random labels""]",0.404119403379233,0,6.333333333333333,2018, empirical_risk_minimization vicinal_risk_minimization generalization data_augmentation image_classification generative_adversarial_networks adversarial_examples random_labels
r1Dx7fbCW,Generalizing Across Domains via Cross-Gradient Training,3,"[""domain generalization"", ""domain adaptation"", ""adversarial learning"", ""adversarial examples""]",0.40162054345716697,0,7.25,2018, domain_generalization domain_adaptation adversarial_learning adversarial_examples
r1G4z8cge,Mollifying Networks,3,"[""Deep learning"", ""Optimization""]",0.4293028339985573,1,6.333333333333333,2017, deep_learning optimization
r1GKzP5xx,Recurrent Normalization Propagation,3,"[""Deep learning"", ""Optimization""]",0.540225669354619,1,5.333333333333333,2017, deep_learning optimization
r1HNP0eCW,Estimation of cross-lingual news similarities using text-mining methods,3,[],0.5747740718173594,0,3.3333333333333335,2018,
r1HhRfWRZ,Learning Awareness Models,3,"[""Awareness"", ""Prediction"", ""Seq2seq"", ""Robots""]",0.4523999371492066,0,5.0,2018, awareness prediction seq2seq robots
r1IRctqxg,Sample Importance in Training Deep Neural Networks,3,"[""Deep learning"", ""Supervised Learning""]",0.46852323016736963,1,4.0,2017, deep_learning supervised_learning
r1ISxGZRb,Generation and Consolidation of Recollections for Efficient Deep Lifelong Learning,3,[],0.4880226555146524,0,5.0,2018,
r1Kr3TyAb,ANALYSIS ON GRADIENT PROPAGATION IN BATCH NORMALIZED RESIDUAL NETWORKS,3,"[""Batch normalization"", ""gradient backpropagation"", ""Residual network"", ""wide residual network""]",0.5005032887394772,0,3.0,2018, batch_normalization gradient_backpropagation residual_network wide_residual_network
r1LXit5ee,Episodic Exploration for Deep Deterministic Policies for StarCraft Micromanagement,3,"[""Deep learning"", ""Reinforcement Learning"", ""Games""]",0.47193811986347206,1,7.333333333333333,2017, deep_learning reinforcement_learning games
r1NYjfbR-,Generative networks as inverse problems with Scattering transforms,3,"[""Unsupervised Learning"", ""Inverse Problems"", ""Convolutional Networks"", ""Generative Models"", ""Scattering Transform""]",0.46256409626618894,0,7.0,2018, unsupervised_learning inverse_problems convolutional_networks generative_models scattering_transform
r1Oen--RW,The (Un)reliability of saliency methods,3,"[""Deep learning interpretability"", ""understanding""]",0.5505126812850754,0,4.333333333333333,2018, deep_learning_interpretability understanding
r1PRvK9el,Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory,3,"[""Deep learning"", ""Reinforcement Learning""]",0.46558395549361037,1,6.0,2017, deep_learning reinforcement_learning
r1QZ3zbAZ,Adversarial Examples for Natural Language Classification Problems,3,[],0.49493554623296815,0,4.666666666666667,2018,
r1R5Z19le,Semi-supervised deep learning by metric embedding,3,"[""Deep learning"", ""Semi-Supervised Learning""]",0.5274028812722918,1,5.0,2017, deep_learning semi_supervised_learning
r1RF3ExCb,Transformation Autoregressive Networks,3,"[""density estimation"", ""autoregressive models"", ""RNNs""]",0.47028075636286604,0,6.0,2018, density_estimation autoregressive_models rnns
r1RQdCg0W,"MACH: Embarrassingly parallel $K$-class classification in $O(d\log{K})$ memory and $O(K\log{K} + d\log{K})$ time, instead of $O(Kd)$",3,"[""Extreme Classification"", ""Large-scale learning"", ""hashing"", ""GPU"", ""High Performance Computing""]",0.5219200633760032,0,6.0,2018, extreme_classification large_scale_learning hashing gpu high_performance_computing
r1S083cgx,Sequence generation with a physiologically plausible model of handwriting and Recurrent Mixture Density Networks,3,"[""Deep learning"", ""Supervised Learning"", ""Applications""]",0.5675641763830802,1,3.0,2017, deep_learning supervised_learning applications
r1SnX5xCb,Deep Sensing: Active Sensing using Multi-directional Recurrent Neural Networks,3,"[""Active Sensing"", ""Timely Prediction"", ""Irregular Sampling"", ""Missing Data""]",0.48726181995843154,0,7.0,2018, active_sensing timely_prediction irregular_sampling missing_data
r1SuFjkRW,Discrete Sequential Prediction of Continuous Actions for Deep RL,3,"[""Reinforcement learning"", ""continuous control"", ""deep learning""]",0.49331986115047555,0,5.333333333333333,2018, reinforcement_learning continuous_control deep_learning
r1TA9ZbA-,Learning to search with MCTSnets,3,"[""Monte-Carlo Tree Search"", ""search"", ""planning""]",0.49915149781207924,0,5.333333333333333,2018, monte_carlo_tree_search search planning
r1Ue8Hcxg,Neural Architecture Search with Reinforcement Learning,3,[],0.5539283696010403,1,9.0,2017,
r1Usiwcex,Counterpoint by Convolution,3,"[""Deep learning"", ""Applications"", ""Unsupervised Learning""]",0.5155622732047758,1,5.666666666666667,2017, deep_learning applications unsupervised_learning
r1VGvBcxl,Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU,2,"[""Reinforcement Learning""]",0.3929098519545883,1,6.666666666666667,2017, reinforcement_learning
r1VVsebAZ,Synthesizing realistic neural population activity patterns using Generative Adversarial Networks,3,"[""GANs"", ""Wasserstein-GANs"", ""convolutional networks"", ""neuroscience"", ""spike train patterns"", ""spike train analysis""]",0.4713827437263385,0,6.0,2018, gans wasserstein_gans convolutional_networks neuroscience spike_train_patterns spike_train_analysis
r1VdcHcxx,Recurrent Batch Normalization,3,"[""Deep learning"", ""Optimization""]",0.5168910995920779,1,7.333333333333333,2017, deep_learning optimization
r1WUqIceg,Improving Stochastic Gradient Descent with Feedback,3,"[""Deep learning"", ""Optimization""]",0.5561209264720139,1,5.333333333333333,2017, deep_learning optimization
r1X3g2_xl,Adversarial Training Methods for Semi-Supervised Text Classification,3,"[""Natural language processing"", ""Deep learning"", ""Semi-Supervised Learning""]",0.41448172461385535,1,6.666666666666667,2017, natural_language_processing deep_learning semi_supervised_learning
r1YNw6sxg,Learning Visual Servoing with Deep Features and Fitted Q-Iteration,3,"[""Computer vision"", ""Deep learning"", ""Reinforcement Learning""]",0.4993951692633314,1,7.333333333333333,2017, computer_vision deep_learning reinforcement_learning
r1YUtYx0-,Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms,3,"[""Robustness"", ""Generalization"", ""Deep Learning"", ""Adversarial Learning""]",0.43621503488957974,0,5.333333333333333,2018, robustness generalization deep_learning adversarial_learning
r1ZdKJ-0W,Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking,3,"[""node embeddings"", ""graphs"", ""unsupervised learning"", ""inductive learning"", ""uncertainty"", ""deep learning""]",0.44683680553542005,0,6.666666666666667,2018, node_embeddings graphs unsupervised_learning inductive_learning uncertainty deep_learning
r1Zi2Mb0-,EXPLORING NEURAL ARCHITECTURE SEARCH FOR LANGUAGE TASKS,3,"[""Neural architecture search"", ""language tasks"", ""neural machine translation"", ""reading comprehension"", ""SQuAD""]",0.53048582956801,0,3.3333333333333335,2018, neural_architecture_search language_tasks neural_machine_translation reading_comprehension squad
r1aGWUqgg,Unsupervised Learning of State Representations for Multiple Tasks,3,"[""Reinforcement Learning"", ""Unsupervised Learning""]",0.5252647349301328,1,5.666666666666667,2017, reinforcement_learning unsupervised_learning
r1aPbsFle,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,3,"[""Natural language processing"", ""Deep learning""]",0.5537169790189341,1,7.0,2017, natural_language_processing deep_learning
r1ayG7WRZ,Don't encrypt the data; just approximate the model \ Towards Secure Transaction and Fair Pricing of Training Data,2,"[""Applications"", ""Security in Machine Learning"", ""Fairness and Security"", ""Model Compression""]",0.3498137785784135,0,3.0,2018, applications security_in_machine_learning fairness_and_security model_compression
r1br_2Kge,Short and Deep: Sketching and Neural Networks,3,"[""Theory""]",0.5867917346511887,1,4.666666666666667,2017, theory
r1cLblgCZ,Recurrent Auto-Encoder Model for Multidimensional Time Series Representation,3,"[""recurrent autoencoder"", ""seq2seq"", ""rnn"", ""multidimensional time series"", ""clustering"", ""sensor"", ""signal analysis"", ""industrial application""]",0.52434515224574,0,2.6666666666666665,2018, recurrent_autoencoder seq2seq rnn multidimensional_time_series clustering sensor signal_analysis industrial_application
r1dHXnH6-,Natural Language Inference over Interaction Space,3,"[""natural language inference"", ""attention"", ""SoTA"", ""natural language understanding""]",0.5340177462036031,0,5.666666666666667,2018, natural_language_inference attention sota natural_language_understanding
r1drp-WCZ,State Space LSTM Models with Particle MCMC Inference,3,"[""recurrent neural networks"", ""state space models"", ""sequential Monte Carlo""]",0.5762712049939299,0,5.0,2018, recurrent_neural_networks state_space_models sequential_monte_carlo
r1fYuytex,Sparsely-Connected Neural Networks: Towards Efficient VLSI Implementation of Deep Neural Networks,3,"[""Deep learning"", ""Applications"", ""Optimization""]",0.5308891755842897,1,6.333333333333333,2017, deep_learning applications optimization
r1gs9JgRZ,Mixed Precision Training,3,"[""Half precision"", ""float16"", ""Convolutional neural networks"", ""Recurrent neural networks""]",0.5294902169966341,0,6.666666666666667,2018, half_precision float16 convolutional_neural_networks recurrent_neural_networks
r1h2DllAW,Discrete-Valued Neural Networks Using Variational Inference,3,"[""low-precision"", ""neural networks"", ""resource efficient"", ""variational inference"", ""Bayesian""]",0.4773248590588093,0,5.333333333333333,2018, low_precision neural_networks resource_efficient variational_inference bayesian
r1hsJCe0Z,Semantic Code Repair using Neuro-Symbolic Transformation Networks,3,"[""semantic program repair"", ""neural program embeddings"", ""deep learning""]",0.552100194012034,0,5.333333333333333,2018, semantic_program_repair neural_program_embeddings deep_learning
r1iuQjxCZ,On the importance of single directions for generalization,3,"[""generalization"", ""analysis"", ""deep learning"", ""selectivity""]",0.4624144354968321,0,7.0,2018, generalization analysis deep_learning selectivity
r1kGbydxg,Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space Matter?,3,"[""Reinforcement Learning"", ""Applications""]",0.5279495507737438,1,6.0,2017, reinforcement_learning applications
r1kNDlbCb,Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks,3,"[""unsupervised learning"", ""text summarization"", ""adversarial training""]",0.5401230948779437,0,5.0,2018, unsupervised_learning text_summarization adversarial_training
r1kP7vlRb,Toward learning better metrics for sequence generation training with policy gradient,3,"[""sequence generation"", ""reinforcement learning"", ""unsupervised learning"", ""RNN""]",0.4577414279160011,0,6.0,2018, sequence_generation reinforcement_learning unsupervised_learning rnn
r1kQkVFgl,Learning Python Code Suggestion with a Sparse Pointer Network,3,[],0.5944273319021233,1,5.666666666666667,2017,
r1kj4ACp-,Understanding Deep Learning Generalization by Maximum Entropy,3,"[""generalization"", ""maximum entropy"", ""deep learning""]",0.4988465293348652,0,3.6666666666666665,2018, generalization maximum_entropy deep_learning
r1kjEuHpZ,Learning Less-Overlapping Representations,3,"[""Less-overlapness"", ""regularization"", ""near-orthogonality"", ""sparsity""]",0.4635739023799423,0,4.0,2018, less_overlapness regularization near_orthogonality sparsity
r1l4eQW0Z,Kernel Implicit Variational Inference,3,"[""Variational inference"", ""Bayesian neural networks"", ""Implicit distribution""]",0.4571064690985819,0,6.333333333333333,2018, variational_inference bayesian_neural_networks implicit_distribution
r1lUOzWCW,Demystifying MMD GANs,2,"[""gans"", ""mmd"", ""ipms"", ""wgan"", ""gradient penalty"", ""unbiased gradients""]",0.3485453517006086,0,5.666666666666667,2018, gans mmd ipms wgan gradient_penalty unbiased_gradients
r1lfpfZAb,Learning to Write by Learning the Objective,3,"[""natural language generation""]",0.5263092126449841,0,5.0,2018, natural_language_generation
r1nTpv9eg,Learning to Perform Physics Experiments via Deep Reinforcement Learning,3,"[""Deep learning"", ""Reinforcement Learning""]",0.4813106638753982,1,6.75,2017, deep_learning reinforcement_learning
r1nmx5l0W,SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs,3,"[""RNNs"", ""GANs"", ""Variational RNNs"", ""Sketch RNNs""]",0.5098388677436487,0,5.333333333333333,2018, rnns gans variational_rnns sketch_rnns
r1nzLmWAb,Video Action Segmentation with Hybrid Temporal Networks,3,"[""action segmentation"", ""video labeling"", ""temporal networks""]",0.5719774946629796,0,3.3333333333333335,2018, action_segmentation video_labeling temporal_networks
r1osyr_xg,Fuzzy paraphrases in learning word representations with a lexicon,3,"[""Natural language processing"", ""Unsupervised Learning""]",0.5489365476724154,1,4.666666666666667,2017, natural_language_processing unsupervised_learning
r1pW0WZAW,Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies,3,"[""recurrent neural networks"", ""long-term dependencies"", ""long short-term memory"", ""LSTM""]",0.5621669461647292,0,5.333333333333333,2018, recurrent_neural_networks long_term_dependencies long_short_term_memory lstm
r1q7n9gAb,The Implicit Bias of Gradient Descent on Separable Data,3,"[""gradient descent"", ""implicit regularization"", ""generalization"", ""margin"", ""logistic regression"", ""loss functions"", ""optimization"", ""exponential tail"", ""cross-entropy""]",0.5113377871162742,0,6.666666666666667,2018, gradient_descent implicit_regularization generalization margin logistic_regression loss_functions optimization exponential_tail cross_entropy
r1rhWnZkg,Hadamard Product for Low-rank Bilinear Pooling,3,"[""Deep learning"", ""Supervised Learning"", ""Multi-modal learning""]",0.5072869424727655,1,6.666666666666667,2017, deep_learning supervised_learning multi_modal_learning
r1rz6U5lg,Learning to superoptimize programs,3,[],0.5435836990639299,1,7.0,2017,
r1saNM-RW,Small Coresets to Represent Large Training Data for Support Vector Machines,3,"[""coresets"", ""data compression""]",0.5471938181890873,0,5.666666666666667,2018, coresets data_compression
r1tHvHKge,Combating Deep Reinforcement Learning's Sisyphean Curse with Intrinsic Fear,3,"[""Deep learning"", ""Reinforcement Learning"", ""Applications""]",0.4406322261246571,1,4.333333333333333,2017, deep_learning reinforcement_learning applications
r1tJKuyRZ,The Set Autoencoder: Unsupervised Representation Learning for Sets,3,"[""set"", ""unsupervised learning"", ""representation learning""]",0.5340134101234033,0,4.666666666666667,2018, set unsupervised_learning representation_learning
r1te3Fqel,End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5812425024494836,1,5.0,2017, natural_language_processing deep_learning supervised_learning
r1uOhfb0W,Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning,3,"[""ensemble learning"", ""SG-MCMC"", ""group sparse prior"", ""network pruning""]",0.5012296705165956,0,5.333333333333333,2018, ensemble_learning sg_mcmc group_sparse_prior network_pruning
r1vccClCb,Neighbor-encoder,3,"[""unsupervised learning"", ""representation learning"", ""autoencoder""]",0.5337579681317427,0,5.0,2018, unsupervised_learning representation_learning autoencoder
r1vuQG-CW,HexaConv,3,"[""hexagonal"", ""group"", ""symmetry"", ""representation learning"", ""rotation"", ""equivariance"", ""invariance""]",0.5004530145537278,0,7.0,2018, hexagonal group symmetry representation_learning rotation equivariance invariance
r1w7Jdqxl,Collaborative Deep Embedding via Dual Networks,3,[],0.4494242495178519,1,4.666666666666667,2017,
r1wEFyWCW,Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions,3,"[""few-shot learning"", ""density models"", ""meta learning""]",0.4751321813254096,0,6.333333333333333,2018, few_shot_learning density_models meta_learning
r1xUYDYgg,Development of JavaScript-based deep learning platform and application to distributed training,3,"[""Deep learning""]",0.49288553712064065,1,5.666666666666667,2017, deep_learning
r1y1aawlg,Iterative Refinement for Machine Translation,3,"[""Natural language processing""]",0.5013383032778822,1,5.25,2017, natural_language_processing
r1yjkAtxe,Spatio-Temporal Abstractions in Reinforcement Learning Through Neural Encoding,3,"[""Reinforcement Learning"", ""Deep learning""]",0.46596977844352444,1,4.0,2017, reinforcement_learning deep_learning
rJ0-tY5xe,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts",3,"[""Natural language processing"", ""Deep learning"", ""Reinforcement Learning""]",0.524973455619358,1,6.666666666666667,2017, natural_language_processing deep_learning reinforcement_learning
rJ0JwFcex,Neuro-Symbolic Program Synthesis,3,"[""Deep learning"", ""Structured prediction""]",0.5673891287086545,1,6.666666666666667,2017, deep_learning structured_prediction
rJ1RPJWAW,Learnability of Learned Neural Networks,3,"[""Learnability"", ""Generalizability"", ""Understanding Deep Learning""]",0.4812606950256042,0,5.666666666666667,2018, learnability generalizability understanding_deep_learning
rJ33wwxRb,SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data,3,"[""Deep Learning"", ""Non-convex Optmization"", ""Generalization"", ""Learning Theory"", ""Neural Networks""]",0.4608412540141995,0,7.333333333333333,2018, deep_learning non_convex_optmization generalization learning_theory neural_networks
rJ3fy0k0Z,Deterministic Policy Imitation Gradient Algorithm,2,"[""Imitation Learning""]",0.39835708003769,0,5.333333333333333,2018, imitation_learning
rJ4uaX2aW,Large Batch Training of Convolutional Networks with Layer-wise Adaptive Rate Scaling,3,"[""large batch"", ""LARS"", ""adaptive rate scaling""]",0.49204126092328754,0,4.666666666666667,2018, large_batch lars adaptive_rate_scaling
rJ5C67-C-,Hyperedge2vec: Distributed Representations for Hyperedges,3,"[""hypergraph"", ""representation learning"", ""tensors""]",0.5271713059852934,0,5.0,2018, hypergraph representation_learning tensors
rJ695PxRW,Discovering Order in Unordered Datasets: Generative Markov Networks,3,"[""Markov chain"", ""discovering orders"", ""generative model"", ""one-shot""]",0.4957223180360055,0,4.0,2018, markov_chain discovering_orders generative_model one_shot
rJ6DhP5xe,Generalizable Features From Unsupervised Learning,3,"[""Unsupervised Learning"", ""Deep learning""]",0.46780713480711855,1,4.333333333333333,2017, unsupervised_learning deep_learning
rJ6iJmWCW,POLICY DRIVEN GENERATIVE ADVERSARIAL NETWORKS FOR ACCENTED SPEECH GENERATION,3,"[""speech"", ""generation"", ""accent"", ""gan"", ""adversarial"", ""reinforcement"", ""memory"", ""lstm"", ""policy"", ""gradients"", ""human""]",0.48366433711905005,0,4.0,2018, speech generation accent gan adversarial reinforcement memory lstm policy gradients human
rJ7RBNe0-,Generative Models for Alignment and Data Efficiency in Language,3,[],0.5243266336797409,0,3.6666666666666665,2018,
rJ7yZ2P6-,Enhance Word Representation for Out-of-Vocabulary on Ubuntu Dialogue Corpus,3,"[""next utterance selection"", ""ubuntu dialogue corpus"", ""out-of-vocabulary"", ""word representation""]",0.5732313934743505,0,4.666666666666667,2018, next_utterance_selection ubuntu_dialogue_corpus out_of_vocabulary word_representation
rJ8Je4clg,Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening,3,"[""Reinforcement Learning"", ""Optimization"", ""Games""]",0.41093048299766993,1,7.333333333333333,2017, reinforcement_learning optimization games
rJ8rHkWRb,A Simple Fully Connected Network for Composing Word Embeddings from Characters,3,"[""natural language processing"", ""word embeddings"", ""language models"", ""neural network"", ""deep learning"", ""sparsity"", ""dropout""]",0.5421143889709727,0,4.0,2018, natural_language_processing word_embeddings language_models neural_network deep_learning sparsity dropout
rJ8uNptgl,Towards the Limit of Network Quantization,3,"[""Theory"", ""Deep learning""]",0.53645313851202,1,7.0,2017, theory deep_learning
rJBiunlAW,Training RNNs as Fast as CNNs,4,"[""recurrent neural networks"", ""natural language processing""]",0.6088145331720897,0,6.333333333333333,2018, recurrent_neural_networks natural_language_processing
rJBwoM-Cb,Neural Tree Transducers for Tree to Tree Learning,3,"[""deep learning"", ""tree transduction""]",0.5741116431093691,0,4.0,2018, deep_learning tree_transduction
rJEgeXFex,Predicting Medications from Diagnostic Codes with Recurrent Neural Networks,3,"[""Deep learning"", ""Supervised Learning"", ""Applications""]",0.5282164157232976,1,7.0,2017, deep_learning supervised_learning applications
rJFOptp6Z,Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification,3,"[""distill"", ""transfer"", ""classification"", ""alignment"", ""verification""]",0.4575376206020127,0,3.6666666666666665,2018, distill transfer classification alignment verification
rJGY8GbR-,Deep Mean Field Theory: Layerwise Variance and Width Variation as Methods to Control Gradient Explosion,3,"[""mean field"", ""dynamics"", ""residual network"", ""variance variation"", ""width variation"", ""initialization""]",0.44408970112105006,0,5.666666666666667,2018, mean_field dynamics residual_network variance_variation width_variation initialization
rJGZq6g0-,"Emergent Communication in a Multi-Modal, Multi-Step Referential Game",3,"[""emergent communication"", ""multi-agent systems"", ""multi-modal""]",0.5155040536089658,0,7.0,2018, emergent_communication multi_agent_systems multi_modal
rJHcpW-CW,NOVEL AND EFFECTIVE PARALLEL MIX-GENERATOR GENERATIVE ADVERSARIAL NETWORKS,3,"[""neural networks"", ""generative adversarial networks"", ""parallel""]",0.4311412498905866,0,4.666666666666667,2018, neural_networks generative_adversarial_networks parallel
rJIN_4lA-,Maintaining cooperation in complex social dilemmas using deep reinforcement learning,3,"[""reinforcement learning"", ""cooperation"", ""social dilemmas"", ""game theory""]",0.49214417043954883,0,3.6666666666666665,2018, reinforcement_learning cooperation social_dilemmas game_theory
rJIgf7bAZ,An inference-based policy gradient method for learning options,3,"[""reinforcement learning"", ""hierarchy"", ""options"", ""inference""]",0.49823081881316317,0,3.3333333333333335,2018, reinforcement_learning hierarchy options inference
rJJ3YU5ge,Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce,3,"[""Multi-modal learning"", ""Deep learning""]",0.5756484369934616,1,4.666666666666667,2017, multi_modal_learning deep_learning
rJJRDvcex,Layer Recurrent Neural Networks,3,"[""Deep learning"", ""Computer vision""]",0.5496130415263193,1,6.0,2017, deep_learning computer_vision
rJJzTyWCZ,Large-scale Cloze Test Dataset Designed by Teachers,3,"[""dataset"", ""human-designed"", ""language understanding""]",0.5673282521783757,0,5.0,2018, dataset human_designed language_understanding
rJL6pz-CZ,Transfer Learning on Manifolds via Learned Transport Operators,3,"[""manifold learning"", ""transfer learning""]",0.47079464724988357,0,4.333333333333333,2018, manifold_learning transfer_learning
rJLS7qKel,Learning to Act by Predicting the Future,3,[],0.5005295103111975,1,7.666666666666667,2017,
rJLTTe-0W,Bayesian Time Series Forecasting with Change Point and Anomaly Detection,3,"[""Time Series Forecasting"", ""Change Point Detection"", ""Anomaly Detection"", ""State Space Model"", ""Bayesian""]",0.44863056975700216,0,5.0,2018, time_series_forecasting change_point_detection anomaly_detection state_space_model bayesian
rJM69B5xx,Finding a Jack-of-All-Trades: An Examination of Semi-supervised Learning in Reading Comprehension,3,"[""Natural language processing"", ""Semi-Supervised Learning"", ""Deep learning"", ""Transfer Learning""]",0.545072024454666,1,4.333333333333333,2017, natural_language_processing semi_supervised_learning deep_learning transfer_learning
rJNpifWAb,Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches,3,"[""weight perturbation"", ""reparameterization gradient"", ""gradient variance reduction"", ""evolution strategies"", ""LSTM"", ""regularization"", ""optimization""]",0.4313885023589932,0,6.666666666666667,2018, weight_perturbation reparameterization_gradient gradient_variance_reduction evolution_strategies lstm regularization optimization
rJPcZ3txx,Faster CNNs with Direct Sparse Convolutions and Guided Pruning,3,"[""Deep learning"", ""Optimization""]",0.5268772580037023,1,6.333333333333333,2017, deep_learning optimization
rJQDjk-0b,Unbiased Online Recurrent Optimization,3,"[""RNN""]",0.4985590931501145,0,7.0,2018, rnn
rJQKYt5ll,Steerable CNNs,3,[],0.5402117548807863,1,7.0,2017,
rJR2ylbRb,Spectral Graph Wavelets for Structural Role Similarity in Networks,3,"[""Graphs"", ""Structural Similarities"", ""Spectral Graph Wavelets"", ""Graph Signal Processing"", ""Unsupervised Learning""]",0.4878910442839712,0,4.333333333333333,2018, graphs structural_similarities spectral_graph_wavelets graph_signal_processing unsupervised_learning
rJRhzzKxl,Knowledge Adaptation: Teaching to Adapt,3,"[""Natural language processing"", ""Deep learning"", ""Transfer Learning"", ""Unsupervised Learning""]",0.48305971147166415,1,6.0,2017, natural_language_processing deep_learning transfer_learning unsupervised_learning
rJSr0GZR-,Learning Priors for Adversarial Autoencoders,3,"[""deep learning"", ""computer vision"", ""generative adversarial networks""]",0.4288562169312804,0,5.666666666666667,2018, deep_learning computer_vision generative_adversarial_networks
rJTGkKxAZ,Learning Generative Models with Locally Disentangled Latent Factors,3,"[""Generative Models"", ""Hierarchical Models"", ""Latent Variable Models""]",0.4979124988847676,0,4.333333333333333,2018, generative_models hierarchical_models latent_variable_models
rJTKKKqeg,Tracking the World State with Recurrent Entity Networks,3,"[""Natural language processing"", ""Deep learning""]",0.5221030233697675,1,7.0,2017, natural_language_processing deep_learning
rJTutzbA-,On the insufficiency of existing momentum schemes for Stochastic Optimization,3,"[""Stochastic Gradient Descent"", ""Deep Learning"", ""Momentum"", ""Acceleration"", ""Heavy Ball"", ""Nesterov Acceleration"", ""Stochastic Optimization"", ""SGD"", ""Accelerated Stochastic Gradient Descent""]",0.48125375563815265,0,7.333333333333333,2018, stochastic_gradient_descent deep_learning momentum acceleration heavy_ball nesterov_acceleration stochastic_optimization sgd accelerated_stochastic_gradient_descent
rJUBryZ0W,Lifelong Learning by Adjusting Priors,3,"[""Lifelong learning"", ""Transfer learning"", ""PAC-Bayes theory""]",0.46202974671939756,0,6.0,2018, lifelong_learning transfer_learning pac_bayes_theory
rJUYGxbCW,PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples,3,"[""Adversarial Examples"", ""Generative Models"", ""Purification"", ""Hypothesis Testing""]",0.46968253842687624,0,7.0,2018, adversarial_examples generative_models purification hypothesis_testing
rJVruWZRW,Dense Recurrent Neural Network with Attention Gate,3,"[""recurrent neural network"", ""language modeling"", ""dense connection""]",0.5211094020317457,0,3.3333333333333335,2018, recurrent_neural_network language_modeling dense_connection
rJWechg0Z,Minimal-Entropy Correlation Alignment for Unsupervised Deep Domain Adaptation,3,"[""unsupervised domain adaptation"", ""entropy minimization"", ""image classification"", ""deep transfer learning""]",0.4243631004773978,0,7.0,2018, unsupervised_domain_adaptation entropy_minimization image_classification deep_transfer_learning
rJWrK9lAb,Autoregressive Generative Adversarial Networks,3,"[""Generative Adversarial Networks"", ""Latent Space Modeling""]",0.46570098513172736,0,4.333333333333333,2018, generative_adversarial_networks latent_space_modeling
rJXMpikCZ,Graph Attention Networks,3,"[""Deep Learning"", ""Graph Convolutions"", ""Attention"", ""Self-Attention""]",0.45817737010469395,0,6.0,2018, deep_learning graph_convolutions attention self_attention
rJXTf9Bxg,Conditional Image Synthesis With Auxiliary Classifier GANs,3,"[""Deep learning""]",0.4715176054562698,1,5.0,2017, deep_learning
rJY0-Kcll,Optimization as a Model for Few-Shot Learning,3,[],0.4959938751080693,1,7.666666666666667,2017,
rJY3vK9eg,Neural Combinatorial Optimization with Reinforcement Learning,3,"[""Reinforcement Learning"", ""Deep learning""]",0.4604187505419751,1,6.0,2017, reinforcement_learning deep_learning
rJYFzMZC-,Simulating Action Dynamics with Neural Process Networks,3,"[""representation learning"", ""memory networks"", ""state tracking""]",0.564511264804905,0,7.666666666666667,2018, representation_learning memory_networks state_tracking
rJa90ceAb,Learning to Generate Filters for Convolutional Neural Networks,3,"[""filter generation"", ""meta-learning"", ""filter repository"", ""image classification"", ""dynamic generation""]",0.48764564088396994,0,4.333333333333333,2018, filter_generation meta_learning filter_repository image_classification dynamic_generation
rJaE2alRW,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,3,"[""neural networks"", ""convolutional neural networks"", ""time series"", ""asynchronous data"", ""regression""]",0.5026115430246184,0,4.666666666666667,2018, neural_networks convolutional_neural_networks time_series asynchronous_data regression
rJbPBt9lg,Neural Code Completion,3,"[""Deep learning"", ""Applications""]",0.5957445816125876,1,4.666666666666667,2017, deep_learning applications
rJbbOLcex,TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency,3,"[""Natural language processing"", ""Deep learning""]",0.5176986561109707,1,7.0,2017, natural_language_processing deep_learning
rJbs5gbRW,On the Generalization Effects of DenseNet Model Structures ,3,"[""Skip connection"", ""generalization"", ""gegularization"", ""deep network"", ""representation.""]",0.44313573216508784,0,2.6666666666666665,2018, skip_connection generalization gegularization deep_network representation.
rJe-Pr9le,Multi-task learning with deep model based reinforcement learning,3,"[""Reinforcement Learning"", ""Deep learning"", ""Games"", ""Transfer Learning""]",0.44085844704644467,1,3.3333333333333335,2017, reinforcement_learning deep_learning games transfer_learning
rJe7FW-Cb,A Painless Attention Mechanism for Convolutional Neural Networks,3,"[""computer vision"", ""deep learning"", ""convolutional neural networks"", ""attention""]",0.5130905981258926,0,5.333333333333333,2018, computer_vision deep_learning convolutional_neural_networks attention
rJeKjwvclx,Dynamic Coattention Networks For Question Answering,3,"[""Natural language processing"", ""Deep learning"", ""Applications""]",0.5287907114795493,1,8.0,2017, natural_language_processing deep_learning applications
rJfMusFll,Batch Policy Gradient  Methods for  Improving Neural Conversation Models,3,"[""Natural language processing"", ""Reinforcement Learning""]",0.4286373698318536,1,7.0,2017, natural_language_processing reinforcement_learning
rJg4YGWRb,Attention-based Graph Neural Network for Semi-supervised Learning,3,"[""Graph Neural Network"", ""Attention"", ""Semi-supervised Learning""]",0.4699352495100003,0,6.333333333333333,2018, graph_neural_network attention semi_supervised_learning
rJg_1L5gg,Incremental Sequence Learning,3,"[""Deep learning"", ""Supervised Learning""]",0.553555689183455,1,4.333333333333333,2017, deep_learning supervised_learning
rJhR_pxCZ,Interpretable Classification via Supervised Variational Autoencoders and Differentiable Decision Trees,3,"[""interpretable classification"", ""decision trees"", ""deep learning"", ""variational autoencoder""]",0.523042796461705,0,4.0,2018, interpretable_classification decision_trees deep_learning variational_autoencoder
rJiNwv9gg,Lossy Image Compression with Compressive Autoencoders,3,"[""Computer vision"", ""Deep learning"", ""Applications""]",0.5056565901536899,1,6.666666666666667,2017, computer_vision deep_learning applications
rJiaRbk0-,Towards Binary-Valued Gates for Robust LSTM Training ,3,"[""recurrent neural network"", ""LSTM"", ""long-short term memory network"", ""machine translation"", ""generalization""]",0.5122547705824638,0,5.333333333333333,2018, recurrent_neural_network lstm long_short_term_memory_network machine_translation generalization
rJk51gJRb,Adversarial Policy Gradient for Alternating Markov Games,3,[],0.4224181313978281,0,5.0,2018,
rJl3yM-Ab,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,3,"[""Question Answering"", ""Deep Learning""]",0.5622481937635121,0,6.666666666666667,2018, question_answering deep_learning
rJl63fZRb,Parametrized Hierarchical Procedures for Neural Programming,3,"[""Neural programming"", ""Hierarchical Control""]",0.5173525579759216,0,6.0,2018, neural_programming hierarchical_control
rJlMAAeC-,Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction,3,"[""neural programming"", ""Neural Programmer-Interpreter""]",0.5354830919017649,0,5.666666666666667,2018, neural_programming neural_programmer_interpreter
rJm7VfZA-,Learning Parametric Closed-Loop Policies for Markov Potential Games,3,"[""Stochastic games"", ""potential games"", ""closed loop"", ""reinforcement learning"", ""multiagent systems""]",0.4697968463395382,0,6.333333333333333,2018, stochastic_games potential_games closed_loop reinforcement_learning multiagent_systems
rJma2bZCW,Three factors influencing minima in SGD,3,"[""SGD"", ""Deep Learning"", ""Generalization""]",0.4927136630405474,0,4.666666666666667,2018, sgd deep_learning generalization
rJo9n9Feg,Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe,3,"[""Semi-Supervised Learning""]",0.5136051073360177,1,3.0,2017, semi_supervised_learning
rJoXrxZAZ,HybridNet: A Hybrid Neural Architecture to Speed-up Autoregressive  Models,3,"[""neural architecture"", ""inference time reduction"", ""hybrid model""]",0.5467835234349209,0,4.666666666666667,2018, neural_architecture inference_time_reduction hybrid_model
rJqBEPcxe,Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations,3,"[""Deep learning""]",0.5232028173761317,1,7.666666666666667,2017, deep_learning
rJqFGTslg,Pruning Filters for Efficient ConvNets,3,"[""Computer vision"", ""Deep learning""]",0.46172938660390467,1,6.75,2017, computer_vision deep_learning
rJq_YBqxx,Deep Character-Level Neural Machine Translation By Learning Morphology,3,"[""Natural language processing"", ""Deep learning""]",0.5737461638214908,1,6.0,2017, natural_language_processing deep_learning
rJqfKPJ0Z,Clipping Free Attacks Against Neural Networks,3,"[""Adversarial examples"", ""Neural Networks"", ""Clipping""]",0.42743604711100097,0,4.0,2018, adversarial_examples neural_networks clipping
rJr4kfWCb,Lung Tumor Location and Identification with AlexNet and a Custom CNN,3,[],0.5065410092845519,0,2.6666666666666665,2018,
rJrTwxbCb,Empirical Analysis of the Hessian of Over-Parametrized Neural Networks,3,"[""Deep Learning"", ""Over-parametrization"", ""Hessian"", ""Eigenvalues"", ""Flat minima"", ""Large batch Small batch""]",0.45420457578300055,0,4.666666666666667,2018, deep_learning over_parametrization hessian eigenvalues flat_minima large_batch_small_batch
rJsiFTYex,A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5296822494659892,1,5.0,2017, natural_language_processing deep_learning supervised_learning
rJssAZ-0-,TRL: Discriminative Hints for Scalable Reverse Curriculum Learning,3,"[""deep learning"", ""deep reinforcement learning"", ""robotics"", ""perception""]",0.4712370182914056,0,4.333333333333333,2018, deep_learning deep_reinforcement_learning robotics perception
rJv4XWZA-,Generating Differentially Private Datasets Using GANs,2,"[""generative adversarial networks"", ""differential privacy"", ""synthetic data""]",0.37978953643529034,0,5.0,2018, generative_adversarial_networks differential_privacy synthetic_data
rJvJXZb0W,An efficient framework for learning sentence representations,3,"[""sentence"", ""embeddings"", ""unsupervised"", ""representations"", ""learning"", ""efficient""]",0.5725210023677265,0,6.666666666666667,2018, sentence embeddings unsupervised representations learning efficient
rJwelMbR-,Divide-and-Conquer Reinforcement Learning,3,"[""deep reinforcement learning"", ""reinforcement learning"", ""policy gradients"", ""model-free""]",0.4542284859985637,0,6.0,2018, deep_reinforcement_learning reinforcement_learning policy_gradients model_free
rJxDkvqee,Multi-view Recurrent Neural Acoustic Word Embeddings,3,[],0.537442603626436,1,5.666666666666667,2017,
rJxdQ3jeg,End-to-end Optimized Image Compression,3,[],0.5857941128094101,1,8.25,2017,
rJzIBfZAb,Towards Deep Learning Models Resistant to Adversarial Attacks,3,"[""adversarial examples"", ""robust optimization"", ""ML security""]",0.4307913906659065,0,6.666666666666667,2018, adversarial_examples robust_optimization ml_security
rJzaDdYxx,Gradients of Counterfactuals,3,"[""Deep learning"", ""Computer vision"", ""Theory""]",0.4325627543000853,1,3.6666666666666665,2017, deep_learning computer_vision theory
rk07ZXZRb,Learning an Embedding Space for Transferable Robot Skills,3,"[""Deep Reinforcement Learning"", ""Variational Inference"", ""Control"", ""Robotics""]",0.4739035514731911,0,7.0,2018, deep_reinforcement_learning variational_inference control robotics
rk1FQA0pW,End-to-End Abnormality Detection in Medical Imaging,3,"[""End-to-End training"", ""deep neural networks"", ""medical imaging"", ""image reconstruction""]",0.5457408770830702,0,5.0,2018, end_to_end_training deep_neural_networks medical_imaging image_reconstruction
rk3b2qxCW,Policy Gradient For Multidimensional Action Spaces: Action Sampling and Entropy Bonus,3,"[""deep reinforcement learning"", ""policy gradient"", ""multidimensional action space"", ""entropy bonus"", ""entropy regularization"", ""discrete action space""]",0.4683932680981821,0,5.333333333333333,2018, deep_reinforcement_learning policy_gradient multidimensional_action_space entropy_bonus entropy_regularization discrete_action_space
rk3mjYRp-,Diffusing Policies : Towards Wasserstein Policy Gradient Flows,2,"[""Optimal transport"", ""policy gradients"", ""entropy regularization"", ""reinforcement learning"", ""heat equation"", ""Wasserstein"", ""JKO"", ""gradient flows""]",0.37934450289810173,0,4.333333333333333,2018, optimal_transport policy_gradients entropy_regularization reinforcement_learning heat_equation wasserstein jko gradient_flows
rk3pnae0b,Topic-Based Question Generation,3,[],0.5105470954482791,0,5.0,2018,
rk49Mg-CW,Stochastic Variational Video Prediction,3,"[""video prediction"", ""stochastic prediction"", ""variational inference"", ""unsupervised learning""]",0.4494791553589391,0,7.0,2018, video_prediction stochastic_prediction variational_inference unsupervised_learning
rk4Fz2e0b,Graph Partition Neural Networks for Semi-Supervised Classification,3,[],0.5013625475444469,0,5.666666666666667,2018,
rk5upnsxe,Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes,3,[],0.5472046785487188,1,7.0,2017,
rk6H0ZbRb,Intriguing Properties of Adversarial Examples,3,"[""adversarial examples"", ""universality"", ""neural architecture search""]",0.41818502694083637,0,5.333333333333333,2018, adversarial_examples universality neural_architecture_search
rk6cfpRjZ,Learning Intrinsic Sparse Structures within Long Short-Term Memory,3,"[""Sparsity"", ""Model Compression"", ""Acceleration"", ""LSTMs"", ""Recurrent Neural Networks"", ""Structural Learning""]",0.5010510412200949,0,6.666666666666667,2018, sparsity model_compression acceleration lstms recurrent_neural_networks structural_learning
rk6qdGgCZ,Fixing Weight Decay Regularization in Adam,3,"[""Adam"", ""Adaptive Gradient Methods"", ""weight decay"", ""L2 regularization""]",0.4669362154359139,0,6.333333333333333,2018, adam adaptive_gradient_methods weight_decay l2_regularization
rk8R_JWRW,Gating out sensory noise in a spike-based Long Short-Term Memory network,3,"[""spiking neural networks"", ""LSTM"", ""recurrent neural networks""]",0.5014056484183903,0,4.666666666666667,2018, spiking_neural_networks lstm recurrent_neural_networks
rk8wKk-R-,Convolutional Sequence Modeling Revisited,3,"[""Temporal Convolutional Network"", ""Sequence Modeling"", ""Deep Learning""]",0.5636475754312734,0,5.666666666666667,2018, temporal_convolutional_network sequence_modeling deep_learning
rk9eAFcxg,Variational Recurrent Adversarial Deep Domain Adaptation,3,"[""Deep learning"", ""Transfer Learning""]",0.40327125482550785,1,5.666666666666667,2017, deep_learning transfer_learning
rk9kKMZ0-,LEAP: Learning Embeddings for Adaptive Pace,3,"[""deep metric learning"", ""self-paced learning"", ""representation learning"", ""cnn""]",0.45844072465335983,0,4.333333333333333,2018, deep_metric_learning self_paced_learning representation_learning cnn
rkA1f3NpZ,Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks,3,"[""Ensemble Method"", ""Adversarial Perturbations"", ""Deep Neural Networks"", ""Defense"", ""Attack""]",0.4869427354842417,0,5.333333333333333,2018, ensemble_method adversarial_perturbations deep_neural_networks defense attack
rkE3y85ee,Categorical Reparameterization with Gumbel-Softmax,3,"[""Deep learning"", ""Semi-Supervised Learning"", ""Optimization"", ""Structured prediction""]",0.4558483508960336,1,6.333333333333333,2017, deep_learning semi_supervised_learning optimization structured_prediction
rkE8pVcle,Learning through Dialogue Interactions by Asking Questions,3,"[""Natural language processing""]",0.46789691197278466,1,7.333333333333333,2017, natural_language_processing
rkEFLFqee,Decomposing Motion and Content for Natural Video Sequence Prediction,3,"[""Computer vision"", ""Deep learning"", ""Unsupervised Learning""]",0.5001773581822405,1,6.666666666666667,2017, computer_vision deep_learning unsupervised_learning
rkEfPeZRb,Variance-based Gradient Compression for Efficient Distributed Deep Learning,3,"[""distributed deep learning"", ""gradient compression"", ""collective communication"", ""data parallel distributed sgd"", ""image classification""]",0.4664335805147963,0,5.666666666666667,2018, distributed_deep_learning gradient_compression collective_communication data_parallel_distributed_sgd image_classification
rkEtzzWAb,Parametric Adversarial Divergences are Good Task Losses for Generative Modeling,3,"[""parametric"", ""adversarial"", ""divergence"", ""generative"", ""modeling"", ""gan"", ""neural"", ""network"", ""task"", ""loss"", ""structured"", ""prediction""]",0.4654468185756226,0,4.666666666666667,2018, parametric adversarial divergence generative modeling gan neural network task loss structured prediction
rkFBJv9gg,Learning Features of Music From Scratch,3,"[""Applications""]",0.5601557437775092,1,6.666666666666667,2017, applications
rkFd2P5gl,Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning,3,"[""Deep learning""]",0.556188696488905,1,3.6666666666666665,2017, deep_learning
rkGZuJb0b,Compact Neural Networks based on the Multiscale Entanglement Renormalization Ansatz,3,"[""Neural Networks"", ""Tensor Networks"", ""Tensor Trains""]",0.5198877877155658,0,4.666666666666667,2018, neural_networks tensor_networks tensor_trains
rkGabzZgl,Dropout with Expectation-linear Regularization,3,"[""Theory"", ""Deep learning"", ""Supervised Learning""]",0.4848559144150886,1,7.666666666666667,2017, theory deep_learning supervised_learning
rkHVZWZAZ,The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning,3,"[""reinforcement learning"", ""policy gradient"", ""distributional reinforcement learning"", ""distributed computing""]",0.4575499881227094,0,7.0,2018, reinforcement_learning policy_gradient distributional_reinforcement_learning distributed_computing
rkHywl-A-,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning,3,"[""inverse reinforcement learning"", ""deep reinforcement learning""]",0.40701521859761164,0,6.333333333333333,2018, inverse_reinforcement_learning deep_reinforcement_learning
rkKCdAdgx,Compact Embedding of Binary-coded Inputs and Outputs using Bloom Filters,3,"[""Applications"", ""Deep learning"", ""Unsupervised Learning""]",0.5481870429620145,1,5.0,2017, applications deep_learning unsupervised_learning
rkLyJl-0-,Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks,3,"[""Deep Learning"", ""Optimization""]",0.5445273839949506,0,6.0,2018, deep_learning optimization
rkMt1bWAZ,Bias-Variance Decomposition for Boltzmann Machines,3,"[""Boltzmann machine"", ""bias-variance decomposition"", ""information geometry""]",0.5544270636993546,0,5.666666666666667,2018, boltzmann_machine bias_variance_decomposition information_geometry
rkN2Il-RZ,SCAN: Learning Hierarchical Compositional Visual Concepts,3,"[""grounded visual concepts"", ""compositional representation"", ""concept hierarchy"", ""disentangling"", ""beta-VAE"", ""variational autoencoder"", ""deep learning"", ""generative model""]",0.553091049571967,0,6.0,2018, grounded_visual_concepts compositional_representation concept_hierarchy disentangling beta_vae variational_autoencoder deep_learning generative_model
rkO3uTkAZ,Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks,3,"[""Generative Adversarial Networks"", ""Memory Networks""]",0.4332120124787942,0,6.333333333333333,2018, generative_adversarial_networks memory_networks
rkONG0xAW,Recursive Binary Neural Network Learning Model  with 2-bit/weight Storage Requirement,4,[],0.6303864638706465,0,6.0,2018,
rkPLzgZAZ,Modular Continual Learning in a Unified Visual Environment,3,"[""Continual Learning"", ""Neural Modules"", ""Interface Learning"", ""Task Switching"", ""Reinforcement Learning"", ""Visual Decision Making""]",0.523180904538895,0,7.333333333333333,2018, continual_learning neural_modules interface_learning task_switching reinforcement_learning visual_decision_making
rkQkBnJAb,Improving GANs Using Optimal Transport,3,"[""GAN"", ""generative modeling"", ""adversarial"", ""optimal transport""]",0.4450193763224218,0,6.666666666666667,2018, gan generative_modeling adversarial optimal_transport
rkQsMCJCb,Generative Adversarial Networks using Adaptive Convolution,3,"[""Generative Adversarial Networks"", ""Unsupervised Learning"", ""GANs""]",0.4301834125185348,0,4.0,2018, generative_adversarial_networks unsupervised_learning gans
rkQu4Wb0Z,DNN Representations as Codewords: Manipulating Statistical Properties via Penalty Regularization,3,"[""DNN representation"", ""penalty regularization"", ""channel coding""]",0.5060836584069549,0,5.0,2018, dnn_representation penalty_regularization channel_coding
rkRwGg-0Z,Beyond Word Importance:  Contextual Decomposition to Extract Interactions from LSTMs,3,"[""interpretability"", ""LSTM"", ""natural language processing"", ""sentiment analysis"", ""interactions""]",0.5645242449437423,0,7.0,2018, interpretability lstm natural_language_processing sentiment_analysis interactions
rkTBjG-AZ,DeepArchitect: Automatically Designing and Training Deep Architectures,3,"[""architecture search"", ""deep learning"", ""hyperparameter tuning""]",0.543902850023885,0,4.333333333333333,2018, architecture_search deep_learning hyperparameter_tuning
rkTS8lZAb,Boundary Seeking GANs,2,"[""Generative adversarial networks"", ""generative learning"", ""deep learning"", ""neural networks"", ""adversarial learning"", ""discrete data""]",0.38483781597600075,0,6.0,2018, generative_adversarial_networks generative_learning deep_learning neural_networks adversarial_learning discrete_data
rkWN3g-AZ,XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings,3,"[""unsupervised"", ""gan"", ""domain adaptation"", ""style transfer"", ""semantic"", ""image translation"", ""dataset""]",0.5228240105578569,0,3.6666666666666665,2018, unsupervised gan domain_adaptation style_transfer semantic image_translation dataset
rkYTTf-AZ,Unsupervised Machine Translation Using Monolingual Corpora Only,3,"[""unsupervised"", ""machine translation"", ""adversarial""]",0.569290324433293,0,7.333333333333333,2018, unsupervised machine_translation adversarial
rkYgAJWCZ,One-shot and few-shot learning of word embeddings,3,"[""One-shot learning"", ""embeddings"", ""word embeddings"", ""natural language processing"", ""NLP""]",0.552826440372713,0,3.6666666666666665,2018, one_shot_learning embeddings word_embeddings natural_language_processing nlp
rkYmiD9lg,Exponential Machines,3,"[""Supervised Learning"", ""Optimization""]",0.5757724237693043,1,6.0,2017, supervised_learning optimization
rkZB1XbRZ,Scalable Private Learning with PATE,3,"[""privacy"", ""differential privacy"", ""machine learning"", ""deep learning""]",0.5052150550610286,0,6.333333333333333,2018, privacy differential_privacy machine_learning deep_learning
rkZvSe-RZ,Ensemble Adversarial Training: Attacks and Defenses,3,"[""Adversarial Examples"", ""Adversarial Training"", ""Attacks"", ""Defenses"", ""ImageNet""]",0.41384147228280543,0,6.0,2018, adversarial_examples adversarial_training attacks defenses imagenet
rkZzY-lCb,Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features,3,"[""unsupervised learning"", ""supervised learning"", ""knowledge representation"", ""deep learning""]",0.48731610936101166,0,5.333333333333333,2018, unsupervised_learning supervised_learning knowledge_representation deep_learning
rkaRFYcgl,Low-rank passthrough neural networks,3,"[""Deep learning""]",0.5604177956902453,1,5.0,2017, deep_learning
rkaT3zWCZ,Building Generalizable Agents with a Realistic and Rich 3D Environment,3,"[""reinforcement learning"", ""generalization"", ""navigation"", ""3D scenes""]",0.4018072802013154,0,5.666666666666667,2018, reinforcement_learning generalization navigation 3d_scenes
rkaqxm-0b,Neural Compositional Denotational Semantics for Question Answering,3,"[""question answering"", ""knowledge graph"", ""compositional model"", ""semantics""]",0.5499204960569268,0,5.333333333333333,2018, question_answering knowledge_graph compositional_model semantics
rkcQFMZRb,Variational image compression with a scale hyperprior,3,[],0.5127293476533218,0,7.0,2018,
rkc_hGb0Z,A dynamic game approach to training robust deep policies,3,"[""game-theory"", ""reinforcement-learning"", ""guided-policy-search"", ""dynamic-programming""]",0.4012830837216345,0,4.333333333333333,2018, game_theory reinforcement_learning guided_policy_search dynamic_programming
rkcya1ZAW,Continuous-Time Flows for Efficient Inference and Density Estimation,2,"[""continuous-time flows"", ""efficient inference"", ""density estimation"", ""deep generative models""]",0.3764792673084035,0,5.0,2018, continuous_time_flows efficient_inference density_estimation deep_generative_models
rkdU7tCaZ,Dynamic Evaluation of Neural Sequence Models,3,"[""sequence modelling"", ""language"", ""recurrent neural networks"", ""adaptation""]",0.5500638307234698,0,5.666666666666667,2018, sequence_modelling language recurrent_neural_networks adaptation
rkeZRGbRW,Variance Regularizing Adversarial Learning,2,"[""Generative Adversarial Network"", ""Integral Probability Metric"", ""Meta-Adversarial Learning""]",0.38197068061754574,0,5.0,2018, generative_adversarial_network integral_probability_metric meta_adversarial_learning
rkfOvGbCW,Memory-based Parameter Adaptation,3,[],0.5660269570542525,0,6.666666666666667,2018,
rkfbLilAb,Improving Search Through A3C Reinforcement Learning Based Conversational Agent,3,"[""Subjective search"", ""Reinforcement Learning"", ""Conversational Agent"", ""Virtual user model"", ""A3C"", ""Context aggregation""]",0.4611709991911328,0,3.3333333333333335,2018, subjective_search reinforcement_learning conversational_agent virtual_user_model a3c context_aggregation
rkgOLb-0W,Neural Language Modeling by Jointly Learning Syntax and Lexicon,3,"[""Language model"", ""unsupervised parsing""]",0.5885290147568968,0,7.333333333333333,2018, language_model unsupervised_parsing
rkhCSO4T-,Distributed non-parametric deep and wide networks,3,[],0.5306606751535099,0,3.0,2018,
rkhlb8lCZ,Wavelet Pooling for Convolutional Neural Networks,3,"[""Pooling"", ""Wavelet"", ""CNN"", ""Neural Network"", ""Deep Learning"", ""Classification"", ""Machine Learning"", ""Object Recognition""]",0.5782896046479716,0,6.666666666666667,2018, pooling wavelet cnn neural_network deep_learning classification machine_learning object_recognition
rkhxwltab,AANN: Absolute Artificial Neural Network,3,"[""Neural Network architecture"", ""Learned representation space"", ""absolute valued function"", ""bidirectional neuron""]",0.5273369455844666,0,3.6666666666666665,2018, neural_network_architecture learned_representation_space absolute_valued_function bidirectional_neuron
rkjZ2Pcxe,Adding Gradient Noise Improves Learning for Very Deep Networks,3,[],0.5482498419175716,1,5.0,2017,
rkmDI85ge,Efficient Softmax Approximation for GPUs,3,"[""Natural language processing""]",0.4982987253208617,1,6.666666666666667,2017, natural_language_processing
rkmoiMbCb,Tandem Blocks in Deep Convolutional Neural Networks,3,"[""resnet"", ""residual"", ""shortcut"", ""convolutional"", ""linear"", ""skip"", ""highway""]",0.5131471824108923,0,5.333333333333333,2018, resnet residual shortcut convolutional linear skip highway
rkmtTJZCb,Unsupervised Hierarchical Video Prediction,3,"[""video prediction"", ""visual analogy network"", ""unsupervised"", ""hierarchical""]",0.5271998837570316,0,4.0,2018, video_prediction visual_analogy_network unsupervised hierarchical
rkmu5b0a-,MGAN: Training Generative Adversarial Nets with Multiple Generators,3,"[""GANs"", ""Mode Collapse"", ""Mixture"", ""Jensen-Shannon Divergence"", ""Inception Score"", ""Generator"", ""Discriminator"", ""CIFAR-10"", ""STL-10"", ""ImageNet""]",0.423037222754586,0,6.0,2018, gans mode_collapse mixture jensen_shannon_divergence inception_score generator discriminator cifar_10 stl_10 imagenet
rknt2Be0-,Compositional Obverter Communication Learning from Raw Visual Input,3,"[""compositional language"", ""obverter"", ""multi-agent communication"", ""raw pixel input""]",0.5416158934837315,0,6.0,2018, compositional_language obverter multi_agent_communication raw_pixel_input
rkpACe1lx,HyperNetworks,3,"[""Natural language processing"", ""Deep learning"", ""Supervised Learning""]",0.5438881623615753,1,7.0,2017, natural_language_processing deep_learning supervised_learning
rkpdnIqlx,The Variational Walkback Algorithm,3,"[""Unsupervised Learning""]",0.5119871551754405,1,4.333333333333333,2017, unsupervised_learning
rkpoTaxA-,Self-ensembling for visual domain adaptation,3,"[""deep learning"", ""neural networks"", ""domain adaptation"", ""images"", ""visual"", ""computer vision""]",0.4932774257965206,0,7.0,2018, deep_learning neural_networks domain_adaptation images visual computer_vision
rkr1UDeC-,Large scale distributed neural network training through online distillation,3,"[""distillation"", ""distributed training"", ""neural networks"", ""deep learning""]",0.5473171629797607,0,6.0,2018, distillation distributed_training neural_networks deep_learning
rkrC3GbRW,Learning a Generative Model for Validity in Complex Discrete Structures,3,"[""Active learning"", ""Reinforcement learning"", ""Molecules""]",0.4741293221232772,0,6.666666666666667,2018, active_learning reinforcement_learning molecules
rkrWCJWAW,Unbiasing Truncated Backpropagation Through Time,3,"[""RNN""]",0.5013440612640582,0,5.333333333333333,2018, rnn
rksfwnFxl,LSTM-Based System-Call Language Modeling and Ensemble Method for Host-Based Intrusion Detection,3,[],0.5663398936385917,1,6.0,2017,
rkuDV6iex,An Empirical Analysis of Deep Network Loss Surfaces,3,"[""Deep learning""]",0.46303063275688566,1,4.666666666666667,2017, deep_learning
rkvDssyRb,Multi-Advisor Reinforcement Learning,3,"[""Reinforcement Learning""]",0.4456839077928225,0,4.0,2018, reinforcement_learning
rkw-jlb0W,Deep Lipschitz networks and Dudley GANs,2,"[""GAN"", ""Lipschitz neural network""]",0.32508546303807545,0,6.0,2018, gan lipschitz_neural_network
rkxY-sl0W,Tree-to-tree Neural Networks for Program Translation,3,[],0.5411620887229837,0,4.666666666666667,2018,
rky3QW9le,Transformational Sparse Coding,3,"[""Unsupervised Learning"", ""Computer vision"", ""Optimization""]",0.5803687609295681,1,4.333333333333333,2017, unsupervised_learning computer_vision optimization
ry-TW-WAb,Variational Network Quantization,3,"[""Network compression"", ""variational inferene"", ""ternary network"", ""Bayesian neural network"", ""weight quantization"", ""weight sharing""]",0.4954964036966996,0,7.0,2018, network_compression variational_inferene ternary_network bayesian_neural_network weight_quantization weight_sharing
ry018WZAZ,Deep Active Learning for Named Entity Recognition,3,"[""active learning"", ""deep learning"", ""named entity recognition""]",0.5182843884712052,0,6.333333333333333,2018, active_learning deep_learning named_entity_recognition
ry0WOxbRZ,IVE-GAN: Invariant Encoding Generative Adversarial Networks,3,"[""Deep learning"", ""Unsupervised Learning""]",0.40180648847315276,0,4.666666666666667,2018, deep_learning unsupervised_learning
ry18Ww5ee,Hyperband: Bandit-Based Configuration Evaluation for Hyperparameter Optimization,3,[],0.526035016953458,1,7.333333333333333,2017,
ry1arUgCW,DORA The Explorer: Directed Outreaching Reinforcement Action-Selection,3,"[""Reinforcement Learning"", ""Exploration"", ""Model-Free""]",0.4686871904741369,0,6.333333333333333,2018, reinforcement_learning exploration model_free
ry2YOrcge,Learning a Natural Language Interface with Neural Programmer,3,"[""Natural language processing"", ""Deep learning""]",0.55308247108379,1,6.333333333333333,2017, natural_language_processing deep_learning
ry3iBFqgl,NEWSQA: A MACHINE COMPREHENSION DATASET,4,"[""Natural language processing"", ""Deep learning""]",0.6027719684042997,1,6.0,2017, natural_language_processing deep_learning
ry4S90l0b,A Self-Training Method for Semi-Supervised GANs,3,"[""self-training"", ""generative adversarial networks"", ""semi-supervised""]",0.45764114079515655,0,3.3333333333333335,2018, self_training generative_adversarial_networks semi_supervised
ry4SNTe0-,Improve Training Stability of Semi-supervised Generative Adversarial Networks with Collaborative Training,2,"[""generative adversarial training"", ""semi-supervised training"", ""collaborative training""]",0.3435491808125622,0,2.6666666666666665,2018, generative_adversarial_training semi_supervised_training collaborative_training
ry4Vrt5gl,Learning to Optimize,3,"[""Reinforcement Learning"", ""Optimization""]",0.40928017388074855,1,6.666666666666667,2017, reinforcement_learning optimization
ry54RWtxx,Learning a Static Analyzer: A Case Study on a Toy Language,3,[],0.5155399614881361,1,3.3333333333333335,2017,
ry6-G_66b,Active Neural Localization,3,[],0.5260921688409077,0,7.0,2018,
ry7O1ssex,Generative Adversarial Networks as Variational Training of Energy Based Models,2,[],0.39396597091757823,1,4.0,2017,
ry80wMW0W,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization,3,"[""Reinforcement Learning"", ""Hierarchy"", ""Subtask Discovery"", ""Linear Markov Decision Process""]",0.5044818483519117,0,6.0,2018, reinforcement_learning hierarchy subtask_discovery linear_markov_decision_process
ry831QWAb,BLOCK-NORMALIZED GRADIENT METHOD: AN EMPIRICAL STUDY FOR TRAINING DEEP NEURAL NETWORK,3,[],0.48839235936132086,0,5.0,2018,
ry8dvM-R-,Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning,3,"[""multi-task"", ""transfer"", ""routing"", ""marl"", ""multi-agent"", ""reinforcement"", ""self-organizing""]",0.4391138698773868,0,7.0,2018, multi_task transfer routing marl multi_agent reinforcement self_organizing
ry9tUX_6-,Entropy-SGD optimizes the prior of a PAC-Bayes bound: Data-dependent PAC-Bayes priors via differential privacy,3,"[""generalization error"", ""neural networks"", ""statistical learning theory"", ""PAC-Bayes theory""]",0.43311778998197176,0,6.0,2018, generalization_error neural_networks statistical_learning_theory pac_bayes_theory
ryA-jdlA-,A closer look at the word analogy problem,3,"[""word2vec"", ""glove"", ""word analogy"", ""word relationships"", ""word vectors""]",0.5276728524007994,0,2.6666666666666665,2018, word2vec glove word_analogy word_relationships word_vectors
ryALZdAT-,Feature Incay for Representation Regularization,3,"[""feature norm"", ""regularization"", ""softmax loss"", ""feature incay""]",0.4795570576790378,0,6.0,2018, feature_norm regularization softmax_loss feature_incay
ryAe2WBee,Multi-label learning with semantic embeddings,3,"[""Supervised Learning""]",0.49513806600401133,1,4.333333333333333,2017, supervised_learning
ryBnUWb0b,Predicting Floor-Level for 911 Calls with Neural Networks and Smartphone Sensor Data,3,"[""Recurrent Neural Networks"", ""RNN"", ""LSTM"", ""Mobile Device"", ""Sensors""]",0.563399026438689,0,6.333333333333333,2018, recurrent_neural_networks rnn lstm mobile_device sensors
ryCM8zWRb,Recurrent Neural Networks with Top-k Gains for Session-based Recommendations,4,"[""gru4rec"", ""session-based recommendations"", ""recommender systems"", ""recurrent neural network""]",0.6184695186340421,0,6.0,2018, gru4rec session_based_recommendations recommender_systems recurrent_neural_network
ryCcJaqgl,TreNet: Hybrid Neural Networks for Learning the Local Trend in Time Series,3,[],0.4809910233799201,1,5.0,2017,
ryDNZZZAW,Multiple Source Domain Adaptation with Adversarial Learning,3,"[""adversarial learning"", ""domain adaptation""]",0.4092892766411787,0,6.0,2018, adversarial_learning domain_adaptation
ryEGFD9gl,Submodular Sum-product Networks for Scene Understanding,3,"[""Computer vision"", ""Structured prediction""]",0.5620888617808795,1,4.333333333333333,2017, computer_vision structured_prediction
ryF-cQ6T-,Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures,3,"[""quantum machine learning"", ""tensor network"", ""quantum information""]",0.515565748774976,0,4.333333333333333,2018, quantum_machine_learning tensor_network quantum_information
ryF7rTqgl,Understanding intermediate layers using linear classifier probes,3,[],0.550785320537534,1,4.333333333333333,2017,
ryG6xZ-RZ,DLVM: A modern compiler infrastructure for deep learning systems,3,"[""deep learning"", ""automatic differentiation"", ""algorithmic differentiation"", ""domain specific languages"", ""neural networks"", ""programming languages"", ""DSLs""]",0.5372219364225251,0,5.666666666666667,2018, deep_learning automatic_differentiation algorithmic_differentiation domain_specific_languages neural_networks programming_languages dsls
ryH20GbRW,Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions,3,"[""Common-sense Physical Reasoning"", ""Intuitive Physics"", ""Representation Learning"", ""Model building""]",0.5089231021071047,0,7.333333333333333,2018, common_sense_physical_reasoning intuitive_physics representation_learning model_building
ryHM_fbA-,Learning Document Embeddings With CNNs,3,"[""unsupervised embedding"", ""convolutional neural network""]",0.5923215578386751,0,4.0,2018, unsupervised_embedding convolutional_neural_network
ryH_bShhW,DOUBLY STOCHASTIC ADVERSARIAL AUTOENCODER,3,"[""Generative adversarial Networks"", ""Deep Generative models"", ""Kernel Methods""]",0.4553321436994289,0,2.6666666666666665,2018, generative_adversarial_networks deep_generative_models kernel_methods
ryHlUtqge,Generalizing Skills with Semi-Supervised Reinforcement Learning,3,"[""Reinforcement Learning""]",0.47836039698562277,1,7.0,2017, reinforcement_learning
ryMxXPFex,Discrete Variational Autoencoders,3,"[""Deep learning"", ""Unsupervised Learning""]",0.5593427247198078,1,8.333333333333334,2017, deep_learning unsupervised_learning
ryOG3fWCW,"Model Specialization for Inference Via End-to-End Distillation, Pruning, and Cascades",3,[],0.4919600084493277,0,4.333333333333333,2018,
ryPx38qge,A hybrid network: Scattering and Convnet,3,"[""Computer vision"", ""Unsupervised Learning"", ""Deep learning""]",0.45498903688590747,1,6.333333333333333,2017, computer_vision unsupervised_learning deep_learning
ryQbbFile,CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS,3,[],0.47538251848782975,1,4.0,2017,
ryQu7f-RZ,On the Convergence of Adam and Beyond,3,"[""optimization"", ""deep learning"", ""adam"", ""rmsprop""]",0.4744211782433455,0,8.333333333333334,2018, optimization deep_learning adam rmsprop
ryRh0bb0Z,Multi-View Data Generation Without View Supervision,3,"[""multi-view"", ""adversarial learning"", ""generative model""]",0.45947146464346167,0,6.333333333333333,2018, multi_view adversarial_learning generative_model
ryT4pvqll,Improving Policy Gradient by Exploring Under-appreciated Rewards,3,"[""Reinforcement Learning""]",0.4445993207608463,1,7.333333333333333,2017, reinforcement_learning
ryT9R3Yxe,Generative Paragraph Vector,3,"[""Natural language processing"", ""Deep learning"", ""Unsupervised Learning"", ""Supervised Learning""]",0.512027982064592,1,3.0,2017, natural_language_processing deep_learning unsupervised_learning supervised_learning
ryTYxh5ll,CONTENT2VEC: SPECIALIZING JOINT REPRESENTATIONS OF PRODUCT IMAGES AND TEXT FOR THE TASK OF PRODUCT RECOMMENDATION,3,"[""Applications""]",0.5592334779035458,1,3.6666666666666665,2017, applications
ryTp3f-0-,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration,3,"[""reinforcement learning"", ""sparse rewards"", ""web"", ""exploration""]",0.47139590538934467,0,6.666666666666667,2018, reinforcement_learning sparse_rewards web exploration
ryUPiRvge,Extrapolation and learning equations,3,"[""Supervised Learning"", ""Deep learning"", ""Structured prediction""]",0.4919240014302017,1,5.333333333333333,2017, supervised_learning deep_learning structured_prediction
ryUlhzWCZ,TRUNCATED HORIZON POLICY SEARCH: COMBINING REINFORCEMENT LEARNING & IMITATION LEARNING,3,"[""Imitation Learning"", ""Reinforcement Learning""]",0.40204741092274293,0,5.333333333333333,2018, imitation_learning reinforcement_learning
ryWKREqxx,Emergent Predication Structure in Vector Representations of Neural Readers,3,"[""Natural language processing"", ""Deep learning"", ""Applications""]",0.5757258060864524,1,5.666666666666667,2017, natural_language_processing deep_learning applications
ryXZmzNeg,Improving Sampling from Generative Autoencoders with Markov Chains,3,"[""Deep learning"", ""Unsupervised Learning"", ""Theory""]",0.5033317576726068,1,3.0,2017, deep_learning unsupervised_learning theory
ryY4RhkCZ,DEEP DENSITY NETWORKS AND UNCERTAINTY IN RECOMMENDER SYSTEMS,3,"[""deep learning"", ""recommendation system"", ""uncertainty"", ""context-based and collaborative filtering""]",0.4748026056721688,0,3.6666666666666665,2018, deep_learning recommendation_system uncertainty context_based_and_collaborative_filtering
ryZ283gAZ,Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations,3,"[""deep convolutional network"", ""residual network"", ""dynamic system"", ""stochastic dynamic system"", ""modified equation""]",0.48934482073195207,0,5.75,2018, deep_convolutional_network residual_network dynamic_system stochastic_dynamic_system modified_equation
ryZ3KCy0W,Link Weight Prediction with Node Embeddings,3,[],0.48079107527743703,0,3.3333333333333335,2018,
ryZ8sz-Ab,"Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping",3,"[""Topic Classification"", ""Sentiment Analysis"", ""Natural Language Processing""]",0.5469813772625802,0,5.666666666666667,2018, topic_classification sentiment_analysis natural_language_processing
ryZERzWCZ,The Information-Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Modeling,3,"[""Generative Models"", ""Variational Autoencoder"", ""Generative Adversarial Network""]",0.45084560396907464,0,5.0,2018, generative_models variational_autoencoder generative_adversarial_network
ryZElGZ0Z,Discovery of Predictive Representations With a Network of General Value Functions,3,"[""Reinforcement Learning"", ""General Value Functions"", ""Predictive Representations""]",0.5382884592751862,0,4.333333333333333,2018, reinforcement_learning general_value_functions predictive_representations
ryZqPN5xe,Beyond Fine Tuning: A Modular Approach to Learning on Small Data,3,"[""Deep learning"", ""Supervised Learning"", ""Transfer Learning""]",0.50004307215109,1,5.333333333333333,2017, deep_learning supervised_learning transfer_learning
ry_4vpixl,Rotation Plane Doubly Orthogonal Recurrent Neural Networks,3,"[""Deep learning"", ""Theory""]",0.5434453456523518,1,4.333333333333333,2017, deep_learning theory
ry_WPG-A-,On the Information Bottleneck Theory of Deep Learning,3,"[""information bottleneck"", ""deep learning"", ""deep linear networks""]",0.45757398034944124,0,6.666666666666667,2018, information_bottleneck deep_learning deep_linear_networks
ry_sjFqgx,Program Synthesis for Character Level Language Modeling,3,[],0.5623787502600563,1,7.0,2017,
ryaFG5ige,Introducing Active Learning for CNN under the light of Variational Inference,3,"[""Deep learning"", ""Supervised Learning"", ""Optimization""]",0.42376149039297,1,6.0,2017, deep_learning supervised_learning optimization
ryacTMZRZ,Jiffy: A Convolutional Approach to Learning Time Series Similarity,3,"[""Time Series"", ""Time Series Classification""]",0.5281578276426361,0,6.0,2018, time_series time_series_classification
ryazCMbR-,Communication Algorithms via Deep Learning,3,"[""coding theory"", ""recurrent neural network"", ""communication""]",0.5717597174500809,0,5.666666666666667,2018, coding_theory recurrent_neural_network communication
ryb-q1Olg,Rectified Factor Networks for Biclustering,3,"[""Deep learning"", ""Unsupervised Learning"", ""Applications""]",0.4877461692389282,1,4.666666666666667,2017, deep_learning unsupervised_learning applications
ryb83alCZ,Towards Unsupervised Classification with Deep Generative Models,3,"[""variational inference"", ""vae"", ""variational autoencoders"", ""generative modeling"", ""representation learning"", ""classification""]",0.47114864523424904,0,4.0,2018, variational_inference vae variational_autoencoders generative_modeling representation_learning classification
rybAWfx0b,COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS,3,"[""Sequence-to-Sequence Models"", ""Speech Recognition"", ""Language Models""]",0.5171571240967753,0,5.333333333333333,2018, sequence_to_sequence_models speech_recognition language_models
rybDdHe0Z,Sequence Transfer Learning for Neural Decoding,3,"[""Transfer Learning"", ""Applications"", ""Neural decoding""]",0.5593591959192188,0,4.333333333333333,2018, transfer_learning applications neural_decoding
rydeCEhs-,SMASH: One-Shot Model Architecture Search through HyperNetworks,3,"[""meta-learning"", ""architecture search"", ""deep learning"", ""computer vision""]",0.508812383779804,0,6.666666666666667,2018, meta_learning architecture_search deep_learning computer_vision
rye7IMbAZ, Explicit Induction Bias for Transfer Learning with Convolutional Networks,3,"[""transfer Learning"", ""convolutional networks"", ""fine-tuning"", ""regularization"", ""induction bias""]",0.4575663126314093,0,6.333333333333333,2018, transfer_learning convolutional_networks fine_tuning regularization induction_bias
rye9LT8cee,Alternating Direction Method of Multipliers for Sparse Convolutional Neural Networks,3,"[""Deep learning"", ""Computer vision"", ""Optimization""]",0.505356407043869,1,6.25,2017, deep_learning computer_vision optimization
ryelgY5eg,Optimal Binary Autoencoding with Pairwise Correlations,3,"[""Theory"", ""Unsupervised Learning"", ""Games""]",0.4689322874296958,1,6.666666666666667,2017, theory unsupervised_learning games
ryepFJbA-,On Convergence and Stability of GANs,3,"[""GAN"", ""Generative Adversarial Networks"", ""Mode Collapse"", ""Stability"", ""Game Theory"", ""Regret Minimization"", ""Convergence"", ""Gradient Penalty""]",0.4021517320463445,0,4.0,2018, gan generative_adversarial_networks mode_collapse stability game_theory regret_minimization convergence gradient_penalty
ryh9pmcee,Energy-based Generative Adversarial Networks,3,"[""Deep learning"", ""Unsupervised Learning"", ""Semi-Supervised Learning""]",0.476829681901585,1,7.333333333333333,2017, deep_learning unsupervised_learning semi_supervised_learning
ryh_8f9lg,Classless Association using Neural Networks,3,[],0.4932927441105404,1,5.333333333333333,2017,
ryhqQFKgl,Towards Deep Interpretability (MUS-ROVER II): Learning Hierarchical Representations of Tonal Music,3,[],0.5739980681648411,1,6.666666666666667,2017,
ryiAv2xAZ,Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples,3,[],0.49943596244468436,0,6.333333333333333,2018,
ryj0790hb,Incremental Learning through Deep Adaptation,3,"[""Transfer Learning"", ""Learning without forgetting"", ""Multitask Learning""]",0.5046669011642099,0,5.0,2018, transfer_learning learning_without_forgetting multitask_learning
ryj38zWRb,Optimizing the Latent Space of Generative Networks,2,"[""generative models"", ""latent variable models"", ""image generation"", ""generative adversarial networks"", ""convolutional neural networks""]",0.38980941271122815,0,5.333333333333333,2018, generative_models latent_variable_models image_generation generative_adversarial_networks convolutional_neural_networks
ryjp1c9xg,Extensions and Limitations of the Neural GPU,3,[],0.5041395158674875,1,4.666666666666667,2017,
ryjw_eAaZ,Unsupervised Deep Structure Learning by Recursive Dependency Analysis,3,"[""unsupervised learning"", ""structure learning"", ""deep belief networks"", ""probabilistic graphical models"", ""Bayesian networks""]",0.4990933299387595,0,4.666666666666667,2018, unsupervised_learning structure_learning deep_belief_networks probabilistic_graphical_models bayesian_networks
ryk77mbRZ,Noise-Based Regularizers for Recurrent Neural Networks,3,[],0.5463334723889889,0,3.3333333333333335,2018,
rylSzl-R-,On Unifying Deep Generative Models,3,"[""deep generative models"", ""generative adversarial networks"", ""variational autoencoders"", ""variational inference""]",0.4124816340959893,0,6.666666666666667,2018, deep_generative_models generative_adversarial_networks variational_autoencoders variational_inference
rylejExC-,Stochastic Training of Graph Convolutional Networks,3,"[""Graph convolutional networks"", ""stochastic gradient descent"", ""variance reduction"", ""control variate""]",0.4746836535356927,0,4.666666666666667,2018, graph_convolutional_networks stochastic_gradient_descent variance_reduction control_variate
rypT3fb0b,LEARNING TO SHARE: SIMULTANEOUS PARAMETER TYING AND SPARSIFICATION IN DEEP LEARNING,3,"[""Compressing neural network"", ""simultaneously parameter tying and sparsification"", ""group ordered l1 regularization""]",0.45802044903243405,0,7.0,2018, compressing_neural_network simultaneously_parameter_tying_and_sparsification group_ordered_l1_regularization
ryrGawqex,Deep Learning with Dynamic Computation Graphs,3,"[""Deep learning""]",0.48569322248002894,1,7.666666666666667,2017, deep_learning
ryserbZR-,Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach,3,"[""Weakly Supervised Learning"", ""Medical Imaging"", ""Histopathology"", ""Deep Feature Extraction""]",0.5388727896911424,0,5.333333333333333,2018, weakly_supervised_learning medical_imaging histopathology deep_feature_extraction
rytNfI1AZ,Training wide residual networks for deployment using a single bit for each weight,3,"[""wide residual networks"", ""model compression"", ""quantization"", ""1-bit weights""]",0.5355702995514031,0,6.0,2018, wide_residual_networks model_compression quantization 1_bit_weights
rytstxWAW,FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling,3,"[""Graph convolutional networks"", ""importance sampling""]",0.46134357826078115,0,7.0,2018, graph_convolutional_networks importance_sampling
ryup8-WCW,Measuring the Intrinsic Dimension of Objective Landscapes,3,"[""machine learning"", ""neural networks"", ""intrinsic dimension"", ""random subspace"", ""model understanding""]",0.5242153156711495,0,6.666666666666667,2018, machine_learning neural_networks intrinsic_dimension random_subspace model_understanding
ryuxYmvel,HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving,3,[],0.5216651839094207,1,7.0,2017,
ryvxcPeAb,Enhancing the Transferability of Adversarial Examples with Noise Reduced Gradient,2,"[""black-box attack"", ""adversarial example"", ""deep learning"", ""transferability""]",0.374243139815803,0,4.666666666666667,2018, black_box_attack adversarial_example deep_learning transferability
rywDjg-RW,Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples,3,"[""Program synthesis"", ""deductive search"", ""deep learning"", ""program induction"", ""recurrent neural networks""]",0.5488172377610174,0,6.666666666666667,2018, program_synthesis deductive_search deep_learning program_induction recurrent_neural_networks
rywHCPkAW,Noisy Networks For Exploration,3,"[""Deep Reinforcement Learning"", ""Exploration"", ""Neural Networks""]",0.4957535426836336,0,6.0,2018, deep_reinforcement_learning exploration neural_networks
rywUcQogx,Differentiable Canonical Correlation Analysis,3,"[""Multi-modal learning""]",0.46159308806849175,1,3.3333333333333335,2017, multi_modal_learning
ryxB0Rtxx,Identity Matters in Deep Learning,3,[],0.5240180767799141,1,6.333333333333333,2017,
ryykVe-0W,Learning Independent Features with Adversarial Nets for Non-linear ICA,3,"[""adversarial networks"", ""ica"", ""unsupervised"", ""independence""]",0.46290362537439667,0,4.666666666666667,2018, adversarial_networks ica unsupervised independence
ryzm6BATZ,Image Quality Assessment Techniques Improve Training and Evaluation of Energy-Based Generative Adversarial Networks,3,"[""generative adversarial networks"", ""gans"", ""deep learning"", ""image modeling"", ""image generation"", ""energy based models""]",0.4517637057201747,0,5.333333333333333,2018, generative_adversarial_networks gans deep_learning image_modeling image_generation energy_based_models
