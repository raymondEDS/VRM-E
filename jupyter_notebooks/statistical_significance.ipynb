{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3ef0c8",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Setup for getting VRM-E and propensity scores, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a54f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "from tqdm.auto import tqdm\n",
    "import statistics\n",
    "import math\n",
    "import csv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.calibration import calibration_curve\n",
    "from copy import deepcopy\n",
    "import pprint\n",
    "import ast\n",
    "import statistics\n",
    "import math\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import agreement\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5695ce5",
   "metadata": {},
   "source": [
    "## VRM-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2af98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = '../data/raw/df_embeddings.csv'\n",
    "submission_path = '../data/raw/df_submission_rating.csv'\n",
    "\n",
    "\n",
    "df_embeddings = pd.read_csv(embedding_path)\n",
    "df_embeddings = df_embeddings.T\n",
    "df_embeddings.columns=df_embeddings.iloc[0]\n",
    "df_embeddings = df_embeddings.iloc[1: , :]\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "def get_numpy (row):\n",
    "  return ast.literal_eval(row.embedding)\n",
    "\n",
    "df_embeddings['embedding'] = df_embeddings.apply(lambda x: get_numpy(x), axis =1)\n",
    "\n",
    "df_submissions = pd.read_csv(submission_path)\n",
    "df_submission_labels = df_submissions[['id','title','conf_year','keywords','AVG_rating']]\n",
    "\n",
    "df_embeddings_2017 = df_embeddings.merge(df_submission_labels[df_submission_labels['conf_year']==2017], left_on='paper_id',right_on='id')\n",
    "df_embeddings_2018 = df_embeddings.merge(df_submission_labels[df_submission_labels['conf_year']==2018], left_on='paper_id',right_on='id')\n",
    "assert df_submission_labels[df_submission_labels['conf_year']==2017].shape[0] == df_embeddings_2017.shape[0]\n",
    "\n",
    "#Section 3.3 Step 2 agglomerative clustering on cosine distance\n",
    "x = np.array(df_embeddings_2017.embedding.tolist())\n",
    "clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.1, linkage=\"average\", metric = 'cosine').fit(x)\n",
    "df_embeddings_2017['agg_cluster'] = clustering.labels_.tolist()\n",
    "x = np.array(df_embeddings_2017.embedding.tolist())\n",
    "y = np.array(df_embeddings_2017.agg_cluster.tolist())\n",
    "clf = NearestCentroid()\n",
    "clf.fit(x, y)\n",
    "\n",
    "assert df_embeddings_2018.shape[0] == df_submission_labels[df_submission_labels['conf_year']==2018].shape[0]\n",
    "\n",
    "#Section 3.3. Step 3\n",
    "\n",
    "#setting up KNN for 2018\n",
    "neigh = NearestNeighbors( n_neighbors=10, metric = 'cosine', radius = 0.3)\n",
    "non_anchor_embedding_2018 = np.array(df_embeddings_2018.embedding.to_list())\n",
    "neigh.fit(non_anchor_embedding_2018)\n",
    "\n",
    "#setting up closest centroid for anchor group 2017\n",
    "anchor_embedding_2017 = np.array(df_embeddings_2017.embedding.tolist())\n",
    "anchor_agg_clusters_2017 = np.array(df_embeddings_2017.agg_cluster.tolist())\n",
    "clf = NearestCentroid()\n",
    "clf.fit(anchor_embedding_2017, anchor_agg_clusters_2017)\n",
    "\n",
    "\n",
    "\n",
    "#dictionary of all the agg clusters and the 10 KNN from 2018\n",
    "dict_agg_cluster_matches ={}\n",
    "tuning_param_cos_dist = 0.3\n",
    "for cluster_id in np.unique(clustering.labels_):\n",
    "    \n",
    "    distances, indices = neigh.kneighbors([clf.centroids_[cluster_id]])\n",
    "    df_anchor_embedding = pd.concat([pd.DataFrame(data = distances.T,columns =['cos_dist']),pd.DataFrame(indices.T,columns=['indices'])],axis=1)\n",
    "\n",
    "    #get all the specified cosine distance 2018 papers\n",
    "    #tuple of (dataframe of 2018 matched papers, cosine distances)\n",
    "    dict_agg_cluster_matches[cluster_id] = (\n",
    "        df_embeddings_2018.iloc[df_anchor_embedding[df_anchor_embedding['cos_dist']<= tuning_param_cos_dist].indices.to_list(), :],\n",
    "        df_anchor_embedding[df_anchor_embedding['cos_dist']<= tuning_param_cos_dist].cos_dist.to_list()\n",
    "    )\n",
    "\n",
    "\n",
    "def lambda_get_2018_matches(row):\n",
    "    #get embedding matches from 2018 papers\n",
    "    #returning relevant information\n",
    "    df_clustered_papers = dict_agg_cluster_matches[row.agg_cluster]\n",
    "    \n",
    "    lst_paper_titles = df_clustered_papers[0].title.tolist()\n",
    "    lst_paper_ids = df_clustered_papers[0].paper_id.tolist()\n",
    "    ls_paper_keywords = df_clustered_papers[0].keywords.values.tolist()\n",
    "    ls_cos_distances = df_clustered_papers[1]\n",
    "    \n",
    "    return lst_paper_titles, ls_paper_keywords, lst_paper_ids, ls_cos_distances\n",
    "\n",
    "df_embeddings_2017[['titles_2018','keywords_2018','id_2018','cos_dist_2018']]= df_embeddings_2017.apply(lambda x: lambda_get_2018_matches(x),axis=1, result_type ='expand')\n",
    "df_cos_dist_sample = pd.concat([df_embeddings_2017[['agg_cluster']],pd.DataFrame(df_embeddings_2017[\"cos_dist_2018\"].to_list())], axis=1)\n",
    "\n",
    "#tuning charts\n",
    "#get the max number of samples with the lowest possible cosine distance\n",
    "df_tuning = df_cos_dist_sample.drop(['agg_cluster'],axis = 1)\n",
    "\n",
    "data = []\n",
    "for tuning_param_cos_dist in np.linspace(0,0.3 ,1000):\n",
    "    input_row = {}\n",
    "    sample_number_from_2017 = df_tuning[df_tuning<=tuning_param_cos_dist].any(axis=1).sum()\n",
    "    \n",
    "    input_row['sample_number_2017'] = sample_number_from_2017\n",
    "    input_row['cosine_distance'] = tuning_param_cos_dist\n",
    "    if sample_number_from_2017 == df_tuning.shape[0]:\n",
    "        input_row['full_sample_flag'] = 'Full Sample'\n",
    "    else:\n",
    "        input_row['full_sample_flag'] = 'Partial Sample'\n",
    "    data.append(input_row)\n",
    "\n",
    "\n",
    "x = pd.DataFrame(data)\n",
    "\n",
    "#Tune KNN matching based on smallest possible cosine distance\n",
    "\n",
    "tuning_param_knn = 10\n",
    "tuning_param_cos_dist = 0.234535\n",
    "\n",
    "neigh = NearestNeighbors( n_neighbors=tuning_param_knn, metric = 'cosine', radius = 0.3)\n",
    "non_anchor_embedding_2018 = np.array(df_embeddings_2018.embedding.to_list())\n",
    "neigh.fit(non_anchor_embedding_2018)\n",
    "\n",
    "#setting up closest centroid for anchor group 2017\n",
    "anchor_embedding_2017 = np.array(df_embeddings_2017.embedding.tolist())\n",
    "anchor_agg_clusters_2017 = np.array(df_embeddings_2017.agg_cluster.tolist())\n",
    "clf = NearestCentroid()\n",
    "clf.fit(anchor_embedding_2017, anchor_agg_clusters_2017)\n",
    "\n",
    "\n",
    "#dictionary of all the agg clusters and the 20 KNN from 2018\n",
    "dict_agg_cluster_matches ={}\n",
    "for cluster_id in np.unique(clustering.labels_):\n",
    "    \n",
    "    distances, indices = neigh.kneighbors([clf.centroids_[cluster_id]])\n",
    "    df_anchor_embedding = pd.concat([pd.DataFrame(data = distances.T,columns =['cos_dist']),pd.DataFrame(indices.T,columns=['indices'])],axis=1)\n",
    "\n",
    "    #get all the specified cosine distance 2018 papers\n",
    "    #tuple of (dataframe of 2018 matched papers, cosine distances)\n",
    "    dict_agg_cluster_matches[cluster_id] = (\n",
    "        df_embeddings_2018.iloc[df_anchor_embedding[df_anchor_embedding['cos_dist']<= tuning_param_cos_dist].indices.to_list(), :],\n",
    "        df_anchor_embedding[df_anchor_embedding['cos_dist']<= tuning_param_cos_dist].cos_dist.to_list()\n",
    "    )\n",
    "\n",
    "def lambda_get_2018_matches(row):\n",
    "    #get embedding matches from 2018 papers\n",
    "    #returning relevant information\n",
    "    df_clustered_papers = dict_agg_cluster_matches[row.agg_cluster]\n",
    "    \n",
    "    lst_paper_titles = df_clustered_papers[0].title.tolist()\n",
    "    lst_paper_ids = df_clustered_papers[0].paper_id.tolist()\n",
    "    ls_paper_keywords = df_clustered_papers[0].keywords.values.tolist()\n",
    "    ls_cos_distances = df_clustered_papers[1]\n",
    "    \n",
    "    return lst_paper_titles, ls_paper_keywords, lst_paper_ids, ls_cos_distances\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "df_embeddings_2017[['titles_2018','keywords_2018','id_2018','cos_dist_2018']]= df_embeddings_2017.apply(lambda x: lambda_get_2018_matches(x),axis=1, result_type ='expand')\n",
    "\n",
    "def get_num_knn_matches(row):\n",
    "    count = len(row.titles_2018)\n",
    "    return(len(row.titles_2018))\n",
    "\n",
    "df_embeddings_2017['num_knn_matches'] = df_embeddings_2017.apply(lambda x: get_num_knn_matches(x),axis =1)\n",
    "\n",
    "assert df_embeddings_2017.shape[0] == df_submission_labels[df_submission_labels['conf_year']==2017].shape[0]\n",
    "\n",
    "#Matching potential outcome estimator\n",
    "#Keith et al. 2020\n",
    "#https://aclanthology.org/2020.acl-main.474.pdf\n",
    "#equation 7 and 8\n",
    "\n",
    "def lambda_get_match_potential_outcomes(row):\n",
    "    #equation 7 in the paper\n",
    "    paper_ids = row.id_2018\n",
    "    big_m = len(row.id_2018)\n",
    "    if big_m == 0:\n",
    "        return None\n",
    "    ratings = [df_embeddings_2018[df_embeddings_2018['paper_id'] == paper_id].AVG_rating.values[0] for paper_id in paper_ids]\n",
    "    return sum(ratings)/big_m\n",
    "        \n",
    "    \n",
    "\n",
    "df_embeddings_2017['match_ave_rating'] = df_embeddings_2017.apply(lambda row: lambda_get_match_potential_outcomes(row), axis =1)\n",
    "df_embeddings_2017['diff_2018_2017'] = df_embeddings_2017['match_ave_rating'] - df_embeddings_2017['AVG_rating']\n",
    "\n",
    "df_embeddings_2017 = df_embeddings_2017.loc[df_embeddings_2017['match_ave_rating'].notnull(),]\n",
    "\n",
    "assert df_embeddings_2017['match_ave_rating'].shape[0] == df_embeddings_2017['AVG_rating'].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fbd30e",
   "metadata": {},
   "source": [
    "## SPSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e25fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "df_embeddings = pd.read_csv(embedding_path)\n",
    "df_embeddings = df_embeddings.T\n",
    "df_embeddings.columns=df_embeddings.iloc[0]\n",
    "df_embeddings = df_embeddings.iloc[1: , :]\n",
    "\n",
    "def get_numpy (row):\n",
    "  return ast.literal_eval(row.embedding)\n",
    "\n",
    "df_embeddings['embedding'] = df_embeddings.apply(lambda x: get_numpy(x), axis =1)\n",
    "df_submissions = pd.read_csv(submission_path)\n",
    "df_submission_labels = df_submissions[['id','title','conf_year','keywords','AVG_rating']]\n",
    "df_embeddings = df_embeddings.merge(df_submission_labels[df_submission_labels['conf_year'].isin([2017,2018])], left_on='paper_id',right_on='id')\n",
    "df_embeddings['treatment'] = df_embeddings['conf_year'].replace([2017,2018],[1,0])\n",
    "\n",
    "np_embeddings =np.array([np.array(embedding) for embedding in df_embeddings.embedding.to_list()])\n",
    "paper_id = np.array(df_embeddings.id.to_list())\n",
    "treatment_id = np.array(df_embeddings.treatment.to_list())\n",
    "\n",
    "if np_embeddings.shape[0] == treatment_id.shape[0] == df_embeddings.shape[0] == paper_id.shape[0]:\n",
    "    \n",
    "    E= np_embeddings\n",
    "    T = treatment_id\n",
    "    n_total = df_embeddings.shape[0]\n",
    "    docids = paper_id\n",
    "    \n",
    "    if E.shape[0] == T.shape[0] == n_total == docids.shape[0]:\n",
    "        print('pass')\n",
    "    else:\n",
    "        print('error')\n",
    "    \n",
    "else:\n",
    "    print('error')\n",
    "    \n",
    "NUM_CROSSFIT_SPLITS = 2\n",
    "NUM_CROSSVAL_SPLITS = 4 \n",
    "RANDOM_STATE = 42 #for replication \n",
    "\n",
    "CLASSIFIER = Pipeline([(\n",
    "            \"model\",\n",
    "            LogisticRegression(\n",
    "                l1_ratio=0.1,\n",
    "                solver=\"saga\",\n",
    "                max_iter=20000,\n",
    "                tol=1e-3, \n",
    "                penalty=\"elasticnet\",\n",
    "                dual=False,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42,\n",
    "                ),),])\n",
    "\n",
    "CLASSIFIER_GRID = {\n",
    "    \"model__C\": [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1],\n",
    "}\n",
    "\n",
    "#Note: May take awhile to run\n",
    "prob_t_training = np.array([np.nan]*n_total) #only for reporting training acc numbers \n",
    "prob_t_inference = np.array([np.nan]*n_total) #array to save predicted propensity scores \n",
    "# Crossfitting \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "crossfit_split = list(StratifiedKFold(n_splits=NUM_CROSSFIT_SPLITS, shuffle=True, random_state=RANDOM_STATE).split(E, T))\n",
    "for crossfit_number, (train_inds, test_inds) in enumerate(crossfit_split):\n",
    "    #print('Crossfit num=', crossfit_number)\n",
    "    # Training \n",
    "    # Cross validation for the training split \n",
    "    inner_cv = StratifiedShuffleSplit(\n",
    "                n_splits=NUM_CROSSVAL_SPLITS,\n",
    "                test_size=1/NUM_CROSSVAL_SPLITS,\n",
    "                random_state= RANDOM_STATE,\n",
    "            )\n",
    "    \n",
    "    t_model_gridsearch = GridSearchCV(\n",
    "                        estimator=deepcopy(CLASSIFIER),\n",
    "                        param_grid=deepcopy(CLASSIFIER_GRID),\n",
    "                        cv=inner_cv,\n",
    "                        scoring=\"roc_auc\",\n",
    "                        refit=True,\n",
    "                    )\n",
    "    \n",
    "    t_model_gridsearch.fit(E[train_inds], T[train_inds])\n",
    "    prob_t_training[train_inds] = t_model_gridsearch.predict_proba(E[train_inds])[:, 1]\n",
    "        \n",
    "    # Inference\n",
    "    # Probability of T=1\n",
    "    prop_t = t_model_gridsearch.predict_proba(E[test_inds])[:, 1]\n",
    "    prob_t_inference[test_inds] = prop_t\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "#Subtract Start Time from The End Time\n",
    "total_time = end - start\n",
    "assert np.mean(np.isnan(prob_t_training)) == 0.0\n",
    "assert np.mean(np.isnan(prob_t_inference)) == 0.0\n",
    "# Training metrics \n",
    "pred_model_report_out = {}\n",
    "\n",
    "def mean_predictions(dummy, y_pred):\n",
    "    \"\"\"\n",
    "    Helpful for error diagnosing. Returns the mean of the predcted values\n",
    "    Args:\n",
    "        - dummy : we need this arg so that this function looks the same as\n",
    "        sklearn error metrics that take inputs y_true, y_pred\n",
    "        - y_pred : np.array\n",
    "    \"\"\"\n",
    "    return np.mean(y_pred)\n",
    "\n",
    "def calibration_rmse(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Calculates calibration root mean squared error (RMSE). \n",
    "    Calibration is the extent to which a model's probabilistic predictions match their \n",
    "    corresponding empirical frequencies. \n",
    "    See Nguyen and O'Connor 2015's introduction and definitions \n",
    "    https://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP182.pdf\n",
    "    \"\"\"\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=10, strategy='uniform')\n",
    "    rms = mean_squared_error(prob_true, prob_pred, squared=False) #False returns RMSE vs MSE \n",
    "    return rms\n",
    "\n",
    "\n",
    "def mean_truth(y_true, dummy):\n",
    "    \"\"\"\n",
    "    Helpful for error diagnosing. Returns the mean of the true values\n",
    "    Args:\n",
    "        - y_true : np.array\n",
    "        - dummy : we need this arg so that this function looks the same as\n",
    "        sklearn error metrics that take inputs y_true, y_pred\n",
    "    \"\"\"\n",
    "    return np.mean(y_true)\n",
    "\n",
    "# these classification metrics need the \"hard\" predictions, e.g. y=[0, 0, 1, ...]\n",
    "class_hard_name2metric_func = {\n",
    "    \"f1\": f1_score,\n",
    "    \"acc\": accuracy_score,\n",
    "    \"mean_hard_pred\": mean_predictions,\n",
    "    \"mean_true\": mean_truth,  # should be same for hard or soft\n",
    "}\n",
    "\n",
    "# these classification metrics need the \"score\" predictions, e.g. y=[0.6, 0.77, 0.2, ...]\n",
    "class_scores_name2metric_func = {\n",
    "    \"roc_auc\": roc_auc_score,\n",
    "    \"ave_prec\": average_precision_score,\n",
    "    \"calibration_rmse\": calibration_rmse,\n",
    "    \"mean_soft_pred\": mean_predictions,\n",
    "    \"mean_true\": mean_truth,  # should be same for hard or soft\n",
    "}\n",
    "\n",
    "#hard classifications\n",
    "t_pred_hard = (prob_t_training > 0.5).astype(int)\n",
    "\n",
    "assert t_pred_hard.shape == prob_t_training.shape == T.shape\n",
    "\n",
    "str_sep = \"--\"\n",
    "for metric_str, metric_func in class_hard_name2metric_func.items():\n",
    "    pred_model_report_out[\"treatment_model\" + str_sep + metric_str] = metric_func(T, t_pred_hard)\n",
    "for metric_str, metric_func in class_scores_name2metric_func.items():\n",
    "    pred_model_report_out[\"treatment_model\" + str_sep + metric_str] = metric_func(T, prob_t_training)\n",
    "\n",
    "NUM_STRATA = 5 \n",
    "def get_strata(prob_t_score, num_strata): \n",
    "    \"\"\"\n",
    "    Reports the strata given the probability score \n",
    "    \n",
    "    Strata index starts at 1 \n",
    "    \"\"\"\n",
    "    strata = np.arange(0, 1.0, 1.0/num_strata)\n",
    "    return np.digitize(prob_t_score, strata, right=False)\n",
    "docid2strata = {}\n",
    "for docid, prob_t_score in zip(docids, prob_t_inference): \n",
    "    strata_inferred = get_strata(prob_t_score, NUM_STRATA)\n",
    "    docid2strata[docid] = (strata_inferred, prob_t_score)\n",
    "data = []\n",
    "for x in docid2strata.items():\n",
    "    input_row = {}\n",
    "    input_row['paperID'] = x[0]\n",
    "    input_row['strata'] = x[1][0]\n",
    "    input_row['pscore'] = x[1][1]\n",
    "    data.append(input_row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_paper_strata = df_embeddings.merge(pd.DataFrame(data), left_on='paper_id',right_on='paperID')[['paper_id','title','strata','keywords','pscore','treatment','AVG_rating','conf_year']]\n",
    "\n",
    "def strip_char(row):\n",
    "    word_list = ast.literal_eval(row.keywords)\n",
    "    s = ''\n",
    "    for word in word_list:\n",
    "        s += \" \" + word.replace(' ','_').replace('-','_').lower()\n",
    "    return s\n",
    "\n",
    "df_paper_strata['transformed_keywords'] = df_paper_strata.apply(lambda x: strip_char(x), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "boostrap_SPSM = []\n",
    "for n in range(5001):\n",
    "    sample = df_paper_strata[df_paper_strata['treatment'] ==1].sample(n=490, replace = True ,random_state=n)\n",
    "\n",
    "    strata_2_weight = sample[(sample['strata'] ==2) & (sample['treatment'] ==1)].shape[0]/490\n",
    "\n",
    "    strata_3_weight = sample[(sample['strata'] ==3) & (sample['treatment'] ==1)].shape[0]/490\n",
    "\n",
    "    strata_4_weight = sample[(sample['strata'] ==4) & (sample['treatment'] ==1)].shape[0]/490\n",
    "\n",
    "    strat_2_treated = sample[(sample['strata'] ==2) & (sample['treatment'] ==1)]['AVG_rating'].mean()\n",
    "    strat_2_control = df_paper_strata[(df_paper_strata['strata'] ==2) & (df_paper_strata['treatment'] ==0)]['AVG_rating'].mean()\n",
    "    \n",
    "    \n",
    "    strat_3_treated = sample[(sample['strata'] ==3) & (sample['treatment'] ==1)]['AVG_rating'].mean()\n",
    "    strat_3_control = df_paper_strata[(df_paper_strata['strata'] ==3) & (df_paper_strata['treatment'] ==0)]['AVG_rating'].mean()\n",
    "    \n",
    "    strat_4_treated = sample[(sample['strata'] ==4) & (sample['treatment'] ==1)]['AVG_rating'].mean()\n",
    "    strat_4_control = df_paper_strata[(df_paper_strata['strata'] ==4) & (df_paper_strata['treatment'] ==0)]['AVG_rating'].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    ATT = (strat_4_treated - strat_4_control)* strata_4_weight + (strat_3_treated - strat_3_control)* strata_3_weight + (strat_2_treated - strat_2_control)* strata_2_weight\n",
    "    boostrap_SPSM.append(ATT)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d869c4",
   "metadata": {},
   "source": [
    "# Bootstrap with NLP test for statistical significance between methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b6a29",
   "metadata": {},
   "source": [
    "## VRM-E vs Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f564af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value is:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Generate bootstrap samples from 2017 data\n",
    "#step 2: Get ATC from bootstrap samples for VRM-E\n",
    "#step 3: Get ATC for naive bootstrap: Average(Boot_strap 2017 samples) - Average(2018 Empirical Samples\n",
    "#step 4: Follow figure 1 from https://aclanthology.org/D12-1091.pdf\n",
    "#Delta(Bootstrap) = ATC_VRM-E(Bootstrap) - ATC_naive(Boostrap)\n",
    "#Delta(X) = ATC_VRM-E  - ATC_Naive = -0.17 - -0.25 = 0.08\n",
    "\n",
    "average_rating_2018 = df_embeddings_2018.AVG_rating.mean()\n",
    "delta_x = 0.08\n",
    "s = 0\n",
    "B = 5000\n",
    "for n in range(B):\n",
    "    bootstrap_sample = df_embeddings_2017.sample(n=df_embeddings_2017.shape[0], replace = True, random_state=n)\n",
    "    ATC_VRM_E = bootstrap_sample.diff_2018_2017.mean()\n",
    "\n",
    "    ATC_Naive = average_rating_2018 - bootstrap_sample.AVG_rating.mean()\n",
    "\n",
    "    delta_bootstrap = ATC_VRM_E - ATC_Naive\n",
    "\n",
    "    if delta_bootstrap > 2*delta_x:\n",
    "        s += 1\n",
    "\n",
    "print('P-Value for VRM-E vs SPSM is: ',s/B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5207ab3",
   "metadata": {},
   "source": [
    "## VRM-E vs SPSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Generate bootstrap samples from 2017 data\n",
    "#step 2: Get ATC from bootstrap samples for VRM-E\n",
    "#step 3: Get ATC for naive bootstrap: Average(Boot_strap 2017 samples) - Average(2018 Empirical Samples\n",
    "#step 4: Follow figure 1 from https://aclanthology.org/D12-1091.pdf\n",
    "#Delta(Bootstrap) = ATC_VRM-E(Bootstrap) - ATC_SPSM(Boostrap)\n",
    "#Delta(X) = ATC_VRM-E  - ATC_SPSM = -0.17 - -0.26 = 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eef2c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing to get the propensity and strata\n",
    "df_embeddings_2017 = pd.merge(df_embeddings_2017, df_paper_strata[df_paper_strata['treatment']==1][['paper_id','pscore','strata','treatment']], on='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd8aeb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value is:  0.0\n"
     ]
    }
   ],
   "source": [
    "delta_x2 = 0.09\n",
    "s2 = 0\n",
    "B2 = 5000\n",
    "\n",
    "for n in range(B2):\n",
    "    bootstrap_sample = df_embeddings_2017.sample(n=df_embeddings_2017.shape[0], replace = True, random_state=n)\n",
    "    ATC_VRM_E = bootstrap_sample.diff_2018_2017.mean()\n",
    "\n",
    "    strata_2_weight = bootstrap_sample[(bootstrap_sample['strata'] ==2) & (bootstrap_sample['treatment'] ==1)].shape[0]/490\n",
    "    strata_3_weight = bootstrap_sample[(bootstrap_sample['strata'] ==3) & (bootstrap_sample['treatment'] ==1)].shape[0]/490\n",
    "    strata_4_weight = bootstrap_sample[(bootstrap_sample['strata'] ==4) & (bootstrap_sample['treatment'] ==1)].shape[0]/490\n",
    "\n",
    "    strat_2_treated = bootstrap_sample[(bootstrap_sample['strata'] ==2) & (bootstrap_sample['treatment'] ==1)]['AVG_rating'].mean()\n",
    "    strat_2_control = df_paper_strata[(df_paper_strata['strata'] ==2) & (df_paper_strata['treatment'] ==0)]['AVG_rating'].mean()\n",
    "\n",
    "\n",
    "    strat_3_treated = bootstrap_sample[(bootstrap_sample['strata'] ==3) & (bootstrap_sample['treatment'] ==1)]['AVG_rating'].mean()\n",
    "    strat_3_control = df_paper_strata[(df_paper_strata['strata'] ==3) & (df_paper_strata['treatment'] ==0)]['AVG_rating'].mean()\n",
    "\n",
    "    strat_4_treated = bootstrap_sample[(bootstrap_sample['strata'] ==4) & (bootstrap_sample['treatment'] ==1)]['AVG_rating'].mean()\n",
    "    strat_4_control = df_paper_strata[(df_paper_strata['strata'] ==4) & (df_paper_strata['treatment'] ==0)]['AVG_rating'].mean()\n",
    "\n",
    "\n",
    "\n",
    "    ATC_SPSM = (strat_4_treated - strat_4_control)* strata_4_weight + (strat_3_treated - strat_3_control)* strata_3_weight + (strat_2_treated - strat_2_control)* strata_2_weight\n",
    "    #treatment and control were flipped for SPSM procedure\n",
    "    ATC_SPSM = -ATC_SPSM\n",
    "\n",
    "    delta_bootstrap = ATC_VRM_E - ATC_SPSM\n",
    "\n",
    "    if delta_bootstrap > 2 * delta_x2:\n",
    "        s2 += 1\n",
    "    \n",
    "print('P-Value for VRM-E vs SPSM is: ',s2/B2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
